[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Overview\nWelcome! In this course you will learn about the state of the art of Machine Learning and also gain practice implementing and deploying machine learning algorithms.\nThis course is destined for students of Data Science FiliÃ¨re in EFREI Paris engineering school. In Data Science FiliÃ¨re there is the following master programs:\nThe aim of Machine Learning is to build computer systems that can adapt to their environments and learn from experience. Learning techniques and methods from this field are successfully applied to a variety of learning tasks in a broad range of areas, including, for example, spam recognition, text classification, gene discovery, financial forecasting. The course will give an overview of many concepts, techniques, and algorithms in machine learning, beginning with topics such as regression and classification. The course will give you the basic ideas and intuition behind these methods, as well as a more formal statistical and computational understanding. You will have an opportunity to experiment with machine learning techniques in Python and apply them to a selected problem."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Machine Learning",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nSession\nTopic\nSlides\nLab\n\n\n\n\n1\nIntroduction to ML  Regression\nðŸ“–\nðŸ’»\n\n\n2\nClassification: Logistic Regression & Regularization\nðŸ“–\nðŸ’»\n\n\n3\nDecision Trees & Random Forests\nðŸ“–\nðŸ’»\n\n\n4\nIntroduction to Neural Networks & Deep Learning\nðŸ“–\nðŸ’»\n\n\n5\nChallenge\n\nðŸ’»"
  },
  {
    "objectID": "TD1.html#python-environment",
    "href": "TD1.html#python-environment",
    "title": "Lab1: Linear Regression",
    "section": "Python environment",
    "text": "Python environment\n\n\n\n\n\n\nAnaconda\n\n\n\nDuring this course we are going to use Python as programming language. Anaconda is an open-source distribution for Python. It is used for data science, machine learning, deep learning, etc. It comes with more than 300 libraries for data science. Anaconda helps in simplified package management and deployment.\nTo install it, go to Anaconda website.\nRemark: if you have a Mac with M1 ship, you must install the 2022.05 release of Anaconda: (Anaconda Distribution Now Supporting M1).\n\n\n\n\n\n\n\n\nJupyter\n\n\n\nDuring the labs, you must use Jupyter notebooks. The Jupyter Notebook is the original web application for creating and sharing computational documents. It offers a simple, streamlined, document-centric experience. Jupyter is installed by default when you install Anaconda. You can create notebooks using JupyterLab via your browser or using a text editor like VScode."
  },
  {
    "objectID": "TD1.html#predicting-house-value-boston-dataset",
    "href": "TD1.html#predicting-house-value-boston-dataset",
    "title": "Lab1: Linear Regression",
    "section": "Predicting House Value: Boston dataset",
    "text": "Predicting House Value: Boston dataset\nIn this lab we are going to use a dataset called Boston. It records the median value of houses for 506 neighborhoods around Boston. Our task is to predict the median house value.\nLoading Data\n\n\n\n\n\n\nBoston dataset\n\n\n\nThe dataset is available in scikit-learn or also here ðŸ”—. Notice that the format/approach is not the same. You are free to use any of them, it is up to you to adapt your codes correctly.\nThere is mainly two approaches you need to know for instance:\n\nThe features and the target variable are in the same dataframe. In this case you can use the argument formula = target ~ features in certain fitting functions (like in ols(), imitating Râ€™s programming language functions).\nThe features and the target variable are separated in X and y.\n\n\n\n\n1. Load these necessary libraries for this lab (install them if needed).\n\nimport numpy as np\nimport matplotlib.pyplot as plt \n\nimport pandas as pd  \nimport seaborn as sns \n\n# Run the following line to obtain the matplotlib figures in the notebook\n%matplotlib inline\n\n# We will also use sklearn but we will load the necessary modules when needed\n\n2. Load the Boston dataset.\n\nfrom sklearn.datasets import load_boston\nboston_dataset = load_boston()\n\n3. Print the value of the boston_dataset to understand what it contains.\n\nprint(boston_dataset.keys())\n\ndict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])\n\n\n\ndata: contains the information for various houses\ntarget: prices of the house\nfeature_names: names of the features\nDESCR: describes the dataset\n\nTo know more about the features run boston_dataset.DESCR.\nThe prices of the house indicated by the variable MEDV is our target variable and the remaining are the feature variables based on which we will predict the median value of houses in a district.\n3. Load the data into a pandas dataframe using pd.DataFrame. Then print the first 5 rows of the data using head().\n\nboston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\nboston.head()\n\n      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n\n[5 rows x 13 columns]\n\n\nWe can see that the target value MEDV is missing from the data. We create a new column of target values and add it to the dataframe.\n\nboston['MEDV'] = boston_dataset.target\n\nRemark: the previous steps were avoidable if we loaded the data from csv given above using pd.read_csv()."
  },
  {
    "objectID": "TD1.html#data-preprocessing",
    "href": "TD1.html#data-preprocessing",
    "title": "Lab1: Linear Regression",
    "section": "Data preprocessing",
    "text": "Data preprocessing\n4. Check if there are any missing values in the data.\nExploratory Data Analysis\nExploratory Data Analysis is a very important step before training the model. In this section, we will use some visualizations to understand the relationship of the target variable with other features.\n5. Plot the distribution of the target variable MEDV. You can use the distplot() function from the seaborn library.\n6. Calculate the correlation matrix and visualize it (you may use heatmap() from seaborn library). Name the features that are highly correlated with the target variable.\n\n\n\n\n\n\nCorrelation\n\n\n\nThe correlation coefficient ranges from -1 to 1. If the value is close to 1, it means that there is a strong positive correlation (linear tendency) between the two variables. When it is close to -1, the variables have a strong negative correlation.\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor a linear regression model, we select the features which have a high correlation with the target variable. Anyway there is some feature selection techniques you may use, one of them is Backward selection:\nBackward selection:\n\nStart with all variables in the model.\nRemove the variable with the largest p-value â€” that is, the variable that is the least statistically significant.\nThe new \\((p âˆ’ 1)\\)-variable model is fit, and the variable with the largest p-value is removed.\nContinue until a stopping rule is reached. For instance, we may stop when all remaining variables have a significant p-value defined by some significance threshold.\n\n\n\n7. Check for multi-collinearity between the features. More specifically RAD and TAX.\n\n\n\n\n\n\nTip\n\n\n\nWe should not select collinear features together for training the model. Check this link for one explanation.\n\n\nSplitting the data into training and testing sets\nTrain test split is a model validation procedure that allows you to simulate how a model would perform on new/unseen data. Here is how the procedure works:\n\n8. Split the data into training and testing sets. We are going to train the model with 80% of the samples and test with the remaining 20%. Use train_test_split() function provided by scikit-learn library\n\nfrom sklearn.model_selection import train_test_split\n\n# complete the code\nX = ...\nY = ...\n\nX_train, X_test, Y_train, Y_test = ...(, , test_size = ..., random_state=5)\n\n# print the shapes to verify if the splitting has occured properly\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)"
  },
  {
    "objectID": "TD1.html#simple-linear-regression-model",
    "href": "TD1.html#simple-linear-regression-model",
    "title": "Lab1: Linear Regression",
    "section": "\nSimple Linear Regression model",
    "text": "Simple Linear Regression model\nIn this part, we are going to build a simple linear regression model. We will choose LSTAT as a feature.\n9. Plot MEDV in function of LSTAT.\n10. Fit a simple regression model using LinearRegression() from sklearn.linear_model.\n\nfrom sklearn.linear_model import LinearRegression\n\nslm = LinearRegression()\nslm.fit(..., ...)\n\n11. The LinearRegression() module from scikit-learn does not provide a statistical summary of the regression model. To obtain this summary, re-fit a model using ols() from statsmodels. Analyse the p-value from the summary and interpret.\n12. Plot the regression model.\nModel evaluation\n13. Evaluate the model using MSE (Mean Squarred Error) and R2-score.\n\nfrom sklearn.metrics import mean_squared_error\n\n# train error (MSE)\ny_train_predict = slm.predict(...)\nmse_train = ...(..., ...)\n\nprint(\"The model performance for training set\")\n\nprint('MSE is {}'.format(mse_train))\n\n\n# test error\ny_test_predict = slm.predict(...)\nmse_test = mean_squared_error(..., ...)\nr2 = r2_score(..., ...)\n\nprint(\"The model performance for testing set\")\n\nprint('MSE is {}'.format(mse_test))\nprint('R2 score is {}'.format(r2))\n\n14. According to the plot in 9, the relationship between LSTAT and MEDV is not linear. Letâ€™s try a transformation of our explanatory variable LSTAT. Re-do the steps from 9 to 13 but using the log of LSTAT. Do you obtain a better model?"
  },
  {
    "objectID": "TD1.html#multiple-linear-regression-model",
    "href": "TD1.html#multiple-linear-regression-model",
    "title": "Lab1: Linear Regression",
    "section": "Multiple Linear Regression model",
    "text": "Multiple Linear Regression model\n15. Train a new model using all the variables of the dataset. Evalute the performance of the model.\n16. Which features are significant for the model?\n17. Apply backward selection to fit a model with the best subset of features.\n18. Is the new model better than the last one with all the features?\n19. In the last model we didnâ€™t transform LSTAT. Re train the model using log(LSTAT) instead of LSTAT. Does this new model performs better?"
  },
  {
    "objectID": "TD1.html#anova-analysis-of-variances",
    "href": "TD1.html#anova-analysis-of-variances",
    "title": "Lab1: Linear Regression",
    "section": "ANOVA (ANalysis Of VAriances)",
    "text": "ANOVA (ANalysis Of VAriances)\nIn this last part we will apply an analysis of variances (ANOVA) in order to test if there is a significant difference of means between two groups \\(i\\) and \\(j\\) (Consider group \\(i\\) is the suburbs bounding the river and \\(j\\) the suburbs which not). The hypotheses are\n\\[ H_0 : \\mu_i = \\mu_j \\]\n\\[ H_1 : \\mu_i \\neq \\mu_j \\]\nWhere \\(\\mu_i\\) is the mean of MEDV in group \\(i\\).\n\n\n\n\n\n\nAnova\n\n\n\nThis analysis can be conducted during the exploratory data analysis part especially when the target is continuous and a feature is discrete.\n\n\n20. In the Boston data set there is a categorical variable CHAS which corresponds to Charles River (= 1 if a suburb bounds the river; 0 otherwise). How many of the suburbs in this data set bound the Charles river?\n21. Create Boxplots of the median value of houses with respect to the variable CHAS. Do we observe some difference between the median value of houses with respect to the neighborhood to Charles River?\n22. Calculate \\(\\mu_i\\) and \\(\\mu_j\\).\n23. Apply an ANOVA test of MEDV with respect to CHAS. What do you conclude ?"
  },
  {
    "objectID": "TD1.html#extra",
    "href": "TD1.html#extra",
    "title": "Lab1: Linear Regression",
    "section": "Extra",
    "text": "Extra\nFit your chosen multiple linear regression model from scratch, using:\n\nNormal equation\nGradient descent\n\nCompare their performance in term of accuracy and speed. Compare them to Scikit-learnâ€™s algorithm performance."
  }
]