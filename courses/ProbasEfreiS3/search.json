[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilités",
    "section": "",
    "text": "Bienvenu\nCe cours de Probabilités est destiné aux étudiants en Licence 2 à l’EFREI Paris. Ce cours est rédigé par Mohamad Ghassany, enseignant chercheur et responsable de la majeure Data & Artificial Intelligence.\nLes probabilités permettent de modéliser des phénomènes aléatoires et d’y effectuer des calculs théoriques. La théorie des probabilités concerne la modélisation du hasard et le calcul des probabilités, son évaluation. Ces techniques doivent faire partie des connaissances de base de tous les ingénieurs, très souvent confrontés à des systèmes ou des situations de plus en plus complexes et parfois gouvernées en partie par le hasard. Elles jouent par exemple un rôle essentiel dans l’évaluation de la sûreté de fonctionnement des systèmes d’information et de communication. Le cours est divisé en deux parties: une première portant sur les probabilités et les variables aléatoires discrètes; une deuxième sur les variables aléatoires continues. Les deux parties introduisent des lois usuelles de probabilités."
  },
  {
    "objectID": "variables-aleatoires-discretes.html",
    "href": "variables-aleatoires-discretes.html",
    "title": "\n1  Variables Aléatoires Discrètes\n",
    "section": "",
    "text": "Exemple fondamental: Considérons le jeu du lancé d’un dé.\n\nExpérience aléatoire \\(\\varepsilon\\) : “lancer un dé équilibré”.\nUnivers: l’ensemble de tous les résultats possibles de cette expérience aléatoire \\(\\Omega= \\{1,2,3,4,5,6\\}\\)\nEvénements: Dans cette expérience aléatoire, on peut s’intéresser à des événements plus complexes qu’un simple résultat élémentaire.\nL’ensemble de parties de \\(\\Omega\\), appelé \\(\\mathcal{P}(\\Omega)\\), est l’ensemble des sous-ensembles de \\(\\Omega\\).\nUne famille \\(\\mathcal{A}\\) de parties (i.e. de sous ensembles) de \\(\\Omega\\). Ces parties sont appelées des événements. On dit que l’événement \\(A\\) s’est réalisé si et seulement si le résultat \\(\\omega\\) de \\(\\Omega\\) qui s’est produit appartient à \\(A\\).\n\nTribu: On appelle tribu sur \\(\\Omega\\), toute famille \\(\\mathcal{A}\\) de parties de \\(\\Omega\\) vérifiant:\n\n\\(\\Omega \\in \\mathcal{A}\\).\nsi \\(A \\in \\mathcal{A}\\), alors \\(\\bar{A} \\in \\mathcal{A}\\).\nsi \\((A_n)_{n\\in\\mathbb{N}}\\) est une suite d’éléments de \\(\\mathcal{A}\\), alors \\(\\bigcup\\limits_{n\\in\\mathbb{N}} A_n \\in \\mathcal{A}\\).\n\n\n\\((\\Omega,\\mathcal{A})\\) est un espace probibilisable.\n\n\n\nSoit \\((\\Omega,\\mathcal{A})\\) un espace probibilisable:\n\nL’ensemble \\(\\mathcal{A}\\) est appelé tribu des événements. Les éléments de \\(\\mathcal{A}\\) s’appellent les événements.\nL’événement \\(\\Omega\\) est appelé événement certain. L’événement \\(\\emptyset\\) est appelé événement impossible.\n\n\n\nOpérations sur les événements: Soient \\(A\\) et \\(B\\) deux événements:\n\n\n\\(\\bar{A}\\) est l’événement contraire de \\(A\\) (on note aussi \\(A^c\\)). \\(\\bar{A}=\\Omega\\setminus A\\).\n\\(\\bar{A}\\) se réalise si et seulement si \\(A\\) ne se réalise pas.\n\n\n\\(A\\, {\\color{blue}\\cap} \\,B\\) est l’événement \\(A\\) et \\(B\\).\n\\(A\\, {\\color{blue}\\cap} \\,B\\) se réalise lorsque les deux événements se réalisent.\n\n\n\\(A\\, {\\color{blue}\\cup} \\,B\\) est l’événement \\(A\\) ou \\(B\\).\n\\(A\\, {\\color{blue}\\cup} \\,B\\) se réalise lorsque au moins un des deux événements se réalise.\n\n\n\nIncompatibilité: \\(A\\) et \\(B\\) sont incompatibles si leur réalisation simultanée est impossible: \\(A \\cap B = \\emptyset\\).\nImplication: \\(A\\) implique \\(B\\) signifie que si \\(A\\) se réalise, alors \\(B\\) se réalise aussi: \\(A \\subset B\\).\n\n\n\nSoit \\((\\Omega,\\mathcal{A})\\) un espace probabilisable. On appelle probabilité sur \\((\\Omega,\\mathcal{A})\\), toute application \\[P : \\mathcal{A} \\rightarrow \\mathbb{R}\\] vérifiant:\n\n\\(\\forall A \\in \\mathcal{A}, P(A) \\geq 0\\).\n\\(P(\\Omega)=1\\).\n\\(\\forall (A_n)_{n\\in\\mathbb{N}^*} \\in \\mathcal{A}^{\\mathbb{N}^*}\\), une suite d’éléments de \\(\\mathcal{A}\\) deux à deux incompatibles, on a: \\[P(\\bigcup\\limits_{n\\in\\mathbb{N}^*} A_n) = \\sum_{n=1}^{+\\infty} P(A_n)\\]\n\n\nLe triplet \\((\\Omega,\\mathcal{A},P)\\) est appelé espace probabilisé.\n\n\n\\(P(\\emptyset) = 0\\).\n\\(P(A_1 \\cup A_2 ) = P(A_1 ) + P(A_2 )-P(A_1 \\cap A_2 )\\).\nSi \\(A_1\\) et \\(A_2\\) sont incompatibles, \\(A_1 \\cap A_2 = \\emptyset\\), \\(P(A_1 \\cup A_2 ) = P(A_1 ) + P(A_2 )\\).\n\\(\\begin{align} P(A_1 \\cup A_2 \\cup A_3 ) &= P(A_1 ) + P(A_2 ) + P(A_3 ) - P(A_1 \\cap A_2 ) \\\\  &- P(A_1 \\cap A_3 ) - P(A_2 \\cap A_3 )+P(A_1 \\cap A_2 \\cap A_3 )\\end{align}\\).\n\\(P(\\bar{A}) = 1-P(A)\\).\n\\(P(B\\setminus A)=P(B)-P(B\\cap A)\\).\n\\(A \\subset B \\Rightarrow P(A) \\leq P(B)\\).\n\n\n\n\n\n\n\nNote\n\n\n\nProbabilité uniforme sur \\(\\Omega\\) fini\n\nSoit \\(\\Omega\\) un univers fini. On dit que \\(P\\) est la probabilité uniforme sur l’espace probabilisable \\((\\Omega,P(\\Omega))\\) si: \\[\\forall \\omega,\\omega' \\in \\Omega, \\quad \\quad P(\\{\\omega\\})=P(\\{\\omega'\\})\\] On dit aussi qu’il y a équiprobabilité des événements élémentaires.\nSoit \\((\\Omega, \\mathcal{P}(\\Omega), P)\\) un espace probabilisé fini. Si \\(P\\) est la probabilité uniforme, alors \\[\\forall A \\in \\mathcal{A}, \\quad \\quad P(A)=\\frac{Card(A)}{Card(\\Omega)}\\]\n\n\n\n\n\nSoit \\((\\Omega,\\mathcal{A},P)\\) une espace probabilisé et \\(B \\in \\mathcal{A}\\) tel que \\(P(B) > 0\\). L’application \\(P_B\\) définie sur \\(\\mathcal{A}\\) par: \\[P_B(A) = P(A|B) =\\frac{P(A\\cap B)}{P(B)}, \\quad \\quad \\forall A \\in \\mathcal{A}\\] est une probabilité sur \\((\\Omega, \\mathcal{A})\\); elle est appelée la probabilité conditionnelle sachant \\(B\\). C’est la probabilité pour que l’événement \\(A\\) se produise sachant que l’événement \\(B\\) s’est produit.\nRemarque: \\((A|B)\\) n’est pas un événement! On utilise la notation \\(P(A|B)\\) par simplicité, mais c’est \\(P_B (A)\\) qui est correcte.\nFormule des probabilités composées: \\[P(A\\cap B) = P(A|B)P(B) = P(B|A)P(A)\\]\n\nFormule des probabilités totales:\n\n\\(\\forall A \\in \\mathcal{A}, \\quad P(A) = P(A \\cap B) + P(A \\cap \\bar{B} )\\)\nOn appelle système complet d’événements (SCE), toute partition dénombrable de \\(\\Omega\\) formée d’éléments de \\(A\\); c-à-d tout ensemble dénombrable d’événements, deux à deux incompatibles et dont l’union dénombrable est l’événement certain.\nSoit \\((B_n)_{n\\geq 0}\\) un SCE de \\(\\Omega\\). On a: \\[\\forall A \\in \\mathcal{A},\\quad \\quad P(A)=\\sum_{n\\geq 0} P(A \\cap B_n)\\]\n\n\nIndépendance: Les événements \\(A\\) et \\(B\\) sont indépendants ssi \\(P(A\\cap B)=P(A)P(B)\\).\n\nPremière formule de Bayes:\nSoit \\((\\Omega,\\mathcal{A},P)\\) une espace probabilisé. Pour tous événements \\(A\\) et \\(B\\) tels que \\(P(A) \\neq 0\\) et \\(P(B) \\neq 0\\), on a: \\[P(B|A) = \\frac{P(A|B)P(B)}{P(A)}\\]\nDeuxième formule de Bayes:\nSoit \\((\\Omega,\\mathcal{A},P)\\) une espace probabilisé et \\((B_n)_{n\\geq 0}\\) un SCE de \\(\\Omega\\) t.q. pour tout \\(n\\geq 0 \\,\\, P(B_n)\\neq 0\\). On a pour tout \\(A \\in \\mathcal{A}\\) t.q. \\(P(A)\\neq 0\\) \\[P(B_i|A) = \\frac{P(A|B_i) P(B_i)}{\\sum_{n\\geq 0} P(A|B_n) P(B_n)} \\quad \\quad \\forall i \\geq 0\\]"
  },
  {
    "objectID": "variables-aleatoires-discretes.html#notion-de-variable-aléatoire-réelle-v.a.r.",
    "href": "variables-aleatoires-discretes.html#notion-de-variable-aléatoire-réelle-v.a.r.",
    "title": "\n1  Variables Aléatoires Discrètes\n",
    "section": "Notion de variable aléatoire réelle (v.a.r.)",
    "text": "Notion de variable aléatoire réelle (v.a.r.)\nAprès avoir réalisé une expérience aléatoire, il arrive bien souvent qu’on s’intéresse plus à une fonction du résultat qu’au résultat lui-même. Expliquons ceci au moyen des exemples suivants: lorsqu’on joue au dés, certains jeux accordent de l’importance à la somme obtenue sur deux dés, 7 par exemple, plutôt qu’à la question de savoir si c’est la paire (1,6) qui est apparue, ou (2,5), (3,4), (4,3), (5,2) ou plutôt (6,1). Dans le cas du jet d’une pièce, il peut être plus intéressant de connaître le nombre de fois où le côté pile est apparue plutôt que la séquence détaillée des jets pile et face. Ces grandeurs auxquelles on s’intéresse sont en fait des fonctions réelles définies sur l’ensemble fondamental et sont appelées variables aléatoires.\nDu fait que la valeur d’une variable aléatoire est déterminée par le résultat de l’expérience, il est possible d’attribuer une probabilité aux différentes valeurs que la variable aléatoire peut prendre.\nSoient \\(\\varepsilon\\) une expérience aléatoire et \\((\\Omega,\\mathcal{A},P)\\) un espace probabilisé lié à cette expérience. Dans de nombreuses situations, on associe à chaque résultat \\(\\omega \\in \\Omega\\) un nombre réel noté \\(X(\\omega)\\); on construit ainsi une application \\(X : \\Omega \\rightarrow \\mathbb{R}\\). Historiquement, \\(\\varepsilon\\) était un jeu et \\(X\\) représentait le gain du joueur.\n\n\n\n\n\n\n\n\n\nExemple: Un joueur lance un dé équilibré à 6 faces numérotées de 1 à 6, et on observe le numéro obtenu.\n\nSi le joueur obtient 1, 3 ou 5, il gagne 1 euro.\nS’il obtient 2 ou 4, il gagne 5 euros.\nS’il obtient 6, il perd 10 euros.\n\nSelon l’expérience aléatoire (lancer d’un dé équilibré) l’ensemble fondamental est \\(\\Omega = \\{1,2,3,4,5,6\\}\\), \\(\\mathcal{A} = \\mathcal{P}(\\Omega)\\) et \\(P\\) l’équiprobabilité sur \\((\\Omega,\\mathcal{A})\\). Soit \\(X\\) l’application de \\(\\Omega\\) dans \\(\\mathbb{R}\\) qui à tout \\(\\omega \\in \\Omega\\) associe le gain correspondant. On a donc\n\n\\(X(1) = X(3) = X(5) = 1\\)\n\\(X(2) = X(4) = 5\\)\n\\(X(6) = -10\\)\n\nOn dit que \\(X\\) est une variable aléatoire sur \\(\\Omega\\).\nOn peut s’intéresser à la probabilité de gagner 1 euro, c’est-à-dire d’avoir \\(X(\\omega) = 1\\), ce qui se réalise si et seulement si \\(\\omega \\in \\{1,3,5\\}\\). La probabilité cherchée est donc égale à \\(P(\\{1,3,5\\}) = 1/2\\). On écrira aussi \\(P(X=1) = 1/2\\).\nOn pourra donc considérer l’événement : \\[\n\\begin{align}\n\\{X=1\\} &= \\{\\omega \\in \\Omega / X(\\omega) = 1\\}  \\\\\n&= \\{\\omega \\in \\Omega / X(\\omega) \\in \\{1\\}\\} \\\\\n&= X^{-1} (\\{1\\}) \\\\\n&= \\{1,3,5\\}\n\\end{align}\\]\nOn aura du même \\(P(X=5) = 1/3\\) et \\(P(X=-10) = 1/6\\). Ce que l’on peut présenter dans un tableau\n\n\n\\(x_i\\)\n-10\n1\n5\n\n\n\\(p_i=P(X = x_i)\\)\n\\(1/6\\)\n\\(1/2\\)\n\\(1/3\\)\n\n\nCela revient à considérer un nouvel ensemble d’événements élémentaires: \\[\\Omega_X = X(\\Omega)= \\{-10,1,5\\}\\] et à munir cet ensemble de la probabilité \\(P_X\\) définie par le tableau des \\(P(X=x_i)\\) ci dessus. Cette nouvelle probabilité s’appelle loi de la variable aléatoire X.\nRemarquer que \\[P(\\bigcup_{x_i \\in \\Omega_X} \\{X=x_i\\}) = \\sum_{x_i \\in \\Omega_X} P(X=x_i) = 1\\]\nDans ce chapitre, nous traitons le cas où \\(X(\\Omega)\\) est dénombrable. La variable aléatoire est alors dite discrète. Sa loi de probabilité, qui peut être toujours définie par sa fonction de répartition, le sera plutôt par les probabilités individuelles. Nous définirons les deux caractéristiques numériques principales d’une variable aléatoire discrète, l’espérance caractéristique de valeur centrale, et la variance, caractéristique de dispersion. Nous définirons aussi les couples de variables aléatoires."
  },
  {
    "objectID": "variables-aleatoires-discretes.html#définition-loi-de-probabilité",
    "href": "variables-aleatoires-discretes.html#définition-loi-de-probabilité",
    "title": "\n1  Variables Aléatoires Discrètes\n",
    "section": "Définition, loi de probabilité",
    "text": "Définition, loi de probabilité\n\nDéfinition 1.1 On dit qu’une variable aléatoire réelle (v.a.r.) \\(X\\) est discrète (v.a.r.d.) si l’ensemble des valeurs que prend \\(X\\) est fini ou infini dénombrable.\nSi on suppose \\(X(\\Omega)\\) l’ensemble des valeurs de \\(X\\) qui admet un plus petit élément \\(x_1\\). Alors la v.a.r.d. \\(X\\) est entièrement définie par:\n\nL’ensemble \\(X(\\Omega)\\) des valeurs prises par \\(X\\), rangées par ordre croissant: \\(X(\\Omega) = \\{x_1, x_2,\\ldots,x_i,\\ldots\\}\\) avec \\(x_1 \\leq x_2 \\leq \\ldots \\leq x_i \\leq \\ldots\\).\nLa loi de probabilité définie sur \\(X(\\Omega)\\) par \\[p_i = P(X=x_i) \\,\\,\\,\\,\\, \\forall \\,\\, i=1,2,\\ldots\\]\n\n\nRemarques:\n\nSoit \\(B\\) un ensemble de \\(\\mathbb{R}\\), \\[P(X \\in B) = \\sum_{i / x_i \\in B} p(x_i)\\]\nEn particulier \\[P( a < X \\leq b) =  \\sum_{i / a < x_i \\leq b} p(x_i)\\]\nBien sûr tous les \\(p(x_i)\\) sont positives et \\(\\sum_{i=1}^{\\infty} p(x_i) =1\\).\nSi \\(X\\) ne prend qu’un petit nombre de valeurs, cette loi est généralement présentée dans un tableau."
  },
  {
    "objectID": "variables-aleatoires-discretes.html#fonction-de-répartition-dune-variable-aléatoire-discrète",
    "href": "variables-aleatoires-discretes.html#fonction-de-répartition-dune-variable-aléatoire-discrète",
    "title": "\n1  Variables Aléatoires Discrètes\n",
    "section": "Fonction de répartition d’une variable aléatoire discrète",
    "text": "Fonction de répartition d’une variable aléatoire discrète\n\nDéfinition 1.2 On appelle fonction de répartition de la v.a. \\(X\\), qu’on note \\(F(a)\\) de la v.a.r.d. \\(X\\), ou \\(F_X(a)\\), la fonction définie pour tout réel \\(a\\), \\(-\\infty < a < \\infty\\), par\n\\[F(a)=P(X \\leq a)=\\sum_{i / x_{i}\\leq a} P(X=x_{i})\\]\n\nCette valeur représente la probabilité de toutes les réalisations inférieures ou égales au réel \\(a\\).\nPropriétés: Voici quelques propriétés de cette fonction:\n\nC’est une fonction en escalier (constante par morceaux).\n\\(F(a) \\leq 1\\) car c’est une probabilité.\n\\(F(a)\\) est continue à droite.\n\\(\\lim\\limits_{a\\to - \\infty} F(a) = 0\\) et \\(\\lim\\limits_{a\\to\\infty} F(a) = 1\\)\n\nLa fonction de répartition caractérise la loi de \\(X\\), autrement dit: \\(F_{X} = F_{Y}\\) si et seulement si les variables aléatoires \\(X\\) et \\(Y\\) ont la même loi de probabilité."
  },
  {
    "objectID": "variables-aleatoires-discretes.html#fonction-de-répartition-et-probabilités-sur-x",
    "href": "variables-aleatoires-discretes.html#fonction-de-répartition-et-probabilités-sur-x",
    "title": "\n1  Variables Aléatoires Discrètes\n",
    "section": "Fonction de répartition et probabilités sur \\(X\\)\n",
    "text": "Fonction de répartition et probabilités sur \\(X\\)\n\nTous les calculs de probabilité concernant \\(X\\) peuvent être traités en termes de fonction de répartition. Par exemple,\n\\[P(a < X \\leq b) = F(b) - F(a) \\quad \\quad \\text{pour tout } a < b\\]\nOn peut mieux s’en rendre compte en écrivant \\(\\{X \\leq b\\}\\) comme union des deux événements incompatibles \\(\\{X \\leq a\\}\\) et \\(\\{ a < X \\leq b\\}\\), soit\n\\[\\{X \\leq b\\} = \\{X \\leq a\\} \\cup   \\{ a < X \\leq b\\}\\]\net ainsi\n\\[P(X \\leq b) = P(X \\leq a) + P(a < X \\leq b)\\] ce qui établit l’égalité ci dessus.\n\n\n\n\n\n\nAstuce\n\n\n\nOn peut déduire de \\(F\\) les probabilités individuelles par:\n\\[ p_{i}=F(x_{i})-F(x_{i-1})\\quad \\quad \\text{pour  } 1 \\leq i \\leq n \\]\n\n\nExemple: On joue trois fois à pile ou face. Soit \\(X\\) la variable aléatoire “nombre de pile obtenus”. Ici \\(\\Omega=\\{P, F\\}^3\\), et donc \\[X(\\Omega)=\\{0, 1, 2, 3\\}\\]\nOn a \\(card(\\Omega)=2^3=8\\). Calculons par exemple \\(P(X=1)\\), c’est à dire la probabilité d’avoir exactement une pile. \\[X^{-1}(1)=\\{(P, F, F), (F, P, F), (F, F, P) \\}\\] D’où \\(P(X=1)=\\displaystyle \\frac{3}{8}\\).\nEn procédant de la même façon, on obtient la loi de probabilité de \\(X\\):\n\n\n\n\n\n\n\n\n\n\\(k\\)\n0\n1\n2\n3\n\n\n\\(P(X = k)\\)\n\\(\\displaystyle \\frac{1}{8}\\)\n\\(\\displaystyle \\frac{3}{8}\\)\n\\(\\displaystyle \\frac{3}{8}\\)\n\\(\\displaystyle \\frac{1}{8}\\)\n\n\nLa fonction de répartition de \\(X\\) est donc donnée par:\n\\[F(x) = \\left\\{\n\\begin{array}{l l}\n0 & \\quad \\text{si $x<0$}\\\\\n  1/8 & \\quad \\text{si $0 \\leq x < 1$}\\\\\n   1/2 & \\quad \\text{si $1 \\leq x < 2$}\\\\\n    7/8 & \\quad \\text{si $2 \\leq x < 3$}\\\\\n     1 & \\quad \\text{si $x \\geq 3$}\\\\\n\\end{array} \\right.\\]\nLe graphe de cette dernière est représentée dans la figure suivante:\n\n\n\n\n\nExemple: Soit \\(A\\) un événement quelconque. On appelle variable aléatoire indicatrice de cet événement \\(A\\), la variable aléatoire définie par: \\[X(\\omega) = \\left\\{\n\\begin{array}{l l}\n1 & \\quad \\text{si $\\omega \\in A$}\\\\\n0 & \\quad \\text{si $\\omega \\in \\bar{A}$}\\\\   \n  \\end{array} \\right.\\]\net notée \\(X=1_A\\). Ainsi: \\[P(X=1)=P(A)=p\\] \\[P(X=0)=P(\\bar{A})=1-p\\]\nLa fonction de répartition de \\(X\\) est donc donnée par:\n\\[ \\begin{equation}\nF(x) = \\left\\{\n\\begin{array}{l l}\n0 & \\quad \\text{si $x<0$}\\\\\n  1-p & \\quad \\text{si $0 \\leq x < 1$}\\\\\n   1 & \\quad \\text{si $x \\geq 1$}\\\\\n\\end{array} \\right.\n\\end{equation} \\]\nOn peut prendre par exemple le cas d’un tirage d’une boule dans une urne contenant 2 boules blanches et 3 boules noires. Soit \\(A\\):“obtenir une boule blanche” et \\(X\\) la variable indicatrice de \\(A\\). La loi de probabilité de \\(X\\) est alors\n\n\n\\(k\\)\n0\n1\n\n\n\\(P(X = k)\\)\n\\(\\frac{3}{5}\\)\n\\(\\frac{2}{5}\\)\n\n\net sa fonction de répartition est:\n\\[ \\begin{equation}\nF(x) = \\left\\{\n\\begin{array}{l l}\n0 & \\quad \\text{si $x<0$}\\\\\n  3/5 & \\quad \\text{si $0 \\leq x < 1$}\\\\\n   1 & \\quad \\text{si $x \\geq 1$}\\\\\n\\end{array} \\right.\n\\end{equation} \\]"
  },
  {
    "objectID": "variables-aleatoires-discretes.html#moments-dune-variable-aléatoire-discrète",
    "href": "variables-aleatoires-discretes.html#moments-dune-variable-aléatoire-discrète",
    "title": "\n1  Variables Aléatoires Discrètes\n",
    "section": "Moments d’une variable aléatoire discrète",
    "text": "Moments d’une variable aléatoire discrète\nEspérance mathématique\n\nDéfinition 1.3 Pour une variable aléatoire discrète \\(X\\) de loi de probabilité \\(p(.)\\), on définit l’espérance de \\(X\\), notée \\(E(X)\\), par l’expression\n\\[E(X)=\\sum_{i \\in \\mathbb{N}} x_{i} p(x_i)\\]\nEn termes concrets, l’espérance de \\(X\\) est la moyenne pondérée des valeurs que \\(X\\) peut prendre, les poids étant les probabilités que ces valeurs soient prises.\n\nReprenons l’exemple où on joue 3 fois à pile ou face. L’espérance de \\(X=\\)“nombre de pile obtenus” est égal à: \\[E(X)=0 \\times \\frac{1}{8}+1 \\times \\frac{3}{8}+2 \\times \\frac{3}{8}+3 \\times \\frac{1}{8}=1.5\\]\nDans le cas de la loi uniforme sur \\(X(\\Omega)=\\{x_{1},\\ldots, x_{k}\\}\\), c’est à dire avec équiprobabilité de toutes les valeurs \\(p_{i}=1/k\\), on obtient: \\[E(X)=\\frac{1}{k} \\sum_{i=1}^k x_{i}\\] et dans ce cas \\(E(X)\\) se confond avec la moyenne arithmétique simple \\(\\bar{x}\\) des valeurs possibles de \\(X\\).\nPour le jet d’un dé équilibré par exemple: \\[E(X)=\\frac{1}{6} \\sum_{i=1}^6 i=\\frac{7}{2}=3.5\\]\nEspérance d’une fonction d’une variable aléatoire\n\nThéorème 1.1 (Théorème du transfert) Si X est une variable aléatoire discrète pouvant prendre ses valeurs parmi les valeurs \\(x_i\\), \\(i \\geq 1\\), avec des probabilités respectives \\(p(x_i)\\), alors pour toute fonction réelle \\(g\\) on a\n\\[E(g(X)) = \\sum_i g(x_i)p(x_i)\\]\n\n\nExemple 1.1 Soit \\(X\\) une variable aléatoire qui prend une des trois valeurs \\(\\{-1,0,1\\}\\) avec les probabilités respectives\n\\[P(X=-1) = 0.2 \\quad \\quad P(X=0)=0.5 \\quad \\quad P(X=1) = 0.3\\]\nCalculer \\(E(X^2)\\).\n\nPremière approche: Soit \\(Y=X^2\\). La distribution de \\(Y\\) est donnée par\n\\[\n\\begin{align}\nP(Y=1) &= P(X=-1) + P(X=1) = 0.5 \\\\\nP(Y=0) &= P(X=0) = 0.5\n\\end{align}\\]\nDonc \\(E(X^2)=E(Y) = 1(0.5) + 0(0.5) = 0.5\\)\nDeuxième approche: En utilisant le théorème\n\\[\n\\begin{align}\nE(X^2)  &= (-1)^2(0.2) + 0^2(0.5) + 1^2 (0.3) \\\\\n        &= 1(0.2+0.3)+0(0.5)=0.5\n\\end{align}\\]\nRemarquer que \\(0.5=E(X^2) \\neq (E(X))^2 = 0.01\\)\nLinéarité de l’espérance Propriétés de l’espérance\n\n\n\\(E(X+a)=E(X)+a, \\quad a \\in \\mathbb{R}\\). Un résultat qui se déduit de:\n\\[\n\\begin{align}\n\\sum_{i}p_{i}(x_{i}+a) &= \\sum_{i}p_{i}x_{i}+\\sum_{i}ap_{i} \\\\\n& =\\sum_{i}p_{i}x_{i}+a \\sum_{i}p_{i}\\\\\n&=\\sum_{i}p_{i}x_{i}+a\n\\end{align}\\]\n\n\\(E(aX)=aE(X), \\quad a\\in \\mathbb{R}\\)\nil suffit d’écrire: \\[\\sum_{i}p_{i}a x_{i}=a\\sum_{i}p_{i}x_{i}\\]\n\\(E(X+Y)=E(X)+E(Y)\\), \\(X\\) et \\(Y\\) étant deux variables aléatoire.\n\nOn peut résumer ces trois propriétés en disant que l’espérance mathématique est linéaire: \\[E(\\lambda X + \\mu Y)= \\lambda E(X)+\\mu E(Y), \\quad \\forall \\lambda \\in \\mathbb{R}, \\, \\forall \\mu \\in \\mathbb{R}\\]\nVariance\n\nDéfinition 1.4 La variance est un indicateur mesurant la dispersion des valeurs \\(x_{i}\\) que peut prendre la v.a. \\(X\\) et son espérance \\(E(X)\\). On appelle variance de X, que l’on note \\(V(X)\\), la quantité\n\\[V(X)=E\\big[ (X-E(X))^2 \\big]\\] lorsque cette quantité existe.\nC’est l’espérance mathématique du carré de la v.a. centrée \\(X-E(X)\\).\n\nOn peut établir une autre formule pour le calcul de \\(V(X)\\):\n\\[V(X)=E(X^2)-E^2(X)\\]\nOr: \\[\\begin{aligned}\n      V(X)&= E\\left[X^2-2XE(X)+E^2(X)\\right] \\\\\n           &=E(X^2)-E[2XE(X)]+ E[E^2(X)]\\\\\n           &=E(X^2)-2E^2(X)+E^2(X) \\\\\n           &=E(X^2)-E^2(X)\n    \\end{aligned}\\]\nOn cherche \\(V(X)\\) où \\(X\\) est le nombre obtenu lors du jet d’un dé équilibré. On a vu dans l’exemple que \\(E(X) = \\frac{7}{2}\\). De plus,\n\\[\\begin{aligned}\n  E(X^2) &= 1^2 \\bigg(\\frac{1}{6}\\bigg) + 2^2 \\bigg(\\frac{1}{6}\\bigg) + 3^2 \\bigg(\\frac{1}{6}\\bigg) + 4^2 \\bigg(\\frac{1}{6}\\bigg) + 5^2 \\bigg(\\frac{1}{6}\\bigg) + 6^2 \\bigg(\\frac{1}{6}\\bigg) \\\\\n        &=\\bigg(\\frac{1}{6}\\bigg) (91) = \\frac{91}{6}.\\end{aligned}\\] Et donc\n\\[V(X) = \\frac{91}{6} - \\bigg(\\frac{7}{2}\\bigg)^2 = \\frac{35}{12}\\]\nPropriétés de la variance\n\n\\(V(X) \\geq 0\\)\n\\(V(X+a)=V(X)\\)\nen effet: \\[\\begin{aligned}\n   V(X+a)   &= E\\big[\\left[X+a-E(X+a)\\right]^2\\big] \\\\\n        &=E\\big[\\left[X+a-E(X)-a\\right]^2\\big] \\\\\n        &=E\\big[\\left[X-E(X)\\right]^2\\big] \\\\\n        &=V(X).\n   \\end{aligned}\\]\n\\(V(aX)=a^2V(X)\\)\nen effet: \\[\\begin{aligned}\n   V(aX)  &= E\\big[\\left[aX-E(aX)\\right]^2\\big] \\\\\n      &=E\\big[\\left[aX-aE(X)\\right]^2\\big] \\\\\n      &=E\\big[a^2\\left[X-E(X)\\right]^2\\big] \\\\\n      &=a^2\\big[E\\left[X-E(X)\\right]^2\\big] \\\\\n      &= a^2V(X).\n   \\end{aligned}\\]\nEcart-type\n\nDéfinition 1.5 La racine carrée de \\(V(X)\\) est appelée l’écart-type de \\(X\\), qui se note \\(\\sigma_{X}\\). On a\n\\[\\sigma_{X} = \\sqrt{V(X)}\\]\n\\(\\sigma_{X}\\) s’exprime dans les mêmes unités de mesure que la variable aléatoire \\(X\\).\n\nA noter:\n\nL’écart type sert à mesurer la dispersion d’un ensemble de données.\nPlus il est faible, plus les valeurs sont regroupées autour de la moyenne.\nExemple: La répartition des notes d’une classe. Plus l’écart type est faible, plus la classe est homogène.\nL’espérance et l’écart-type sont reliés par l’inégalité de Bienaymé-Tchebychev.\nInégalité de Bienaymé-Tchebychev\n\nThéorème 1.2 Soit \\(X\\) une variable aléatoire d’espérance \\(\\mu\\) et de variance \\(\\sigma^2\\). Pour tout \\(\\varepsilon > 0\\), on a l’inégalité suivante: \\[P\\left(|X-E(X)| \\geq \\varepsilon \\right) \\leq \\frac{\\sigma^2}{\\varepsilon^2}\\]\nOn peut l’écrire autrement. Soit \\(k=\\varepsilon/\\sigma\\). \\[P\\left(|X-E(X)| \\geq k\\sigma \\right) \\leq \\frac{1}{k^2}\\]\n\n\n\n\n\n\n\nNote\n\n\n\nImportance: Cette inégalité relie la probabilité pour \\(X\\) de s’écarter de sa moyenne \\(E(X)\\), à sa variance qui est justement un indicateur de dispersion autour de la moyenne de la loi. Elle montre quantitativement que “plus l’écart type est faible, plus la probabilité de s’écarter de la moyenne est faible”.\n\n\n\nThéorème 1.3 (Inégalité de Markov) Soit \\(X\\) une variable aléatoire à valeur non négatives. Pour tout réel \\(a > 0\\) \\[P(X>a) \\leq \\frac{E(X)}{a}\\]\n\nMoments non centrés et centrés\nOn appelle moment non centré d’ordre \\(r \\in \\mathbb{N^*}\\) de \\(X\\) la quantité, lorsqu’elle existe: \\[m_{r}(X)=\\sum_{i \\in \\mathbb{N} } x_{i}^r p(x_{i})=E(X^r)\\] Le moment centré d’ordre \\(r \\in \\mathbb{N^*}\\) est la quantité, lorsqu’elle existe: \\[\\mu_{r}(X)=\\sum_{i \\in \\mathbb{N} } p_{i}\\left[x_{i}-E(X)\\right]^r=E\\left[X-E(X)\\right]^r\\]\nLes premiers moments sont: \\[m_{1}(X)=E(X), \\quad \\mu_{1}(X)=0\\] \\[\\mu_{2}(X)=V(X)=m_{2}(X)-m_{1}^2(X)\\]"
  },
  {
    "objectID": "variables-aleatoires-discretes.html#couple-de-variables-aléatoires-discrètes",
    "href": "variables-aleatoires-discretes.html#couple-de-variables-aléatoires-discrètes",
    "title": "\n1  Variables Aléatoires Discrètes\n",
    "section": "Couple de variables aléatoires discrètes",
    "text": "Couple de variables aléatoires discrètes\nConsidérons deux variables aléatoires discrètes \\(X\\) et \\(Y\\). Il nous faut pour modéliser le problème une fonction qui nous donne la probabilité que \\((X = x_i )\\) en même temps que \\((Y = y_j )\\). C’est la loi de probabilité conjointe.\nSoit \\(X\\) et \\(Y\\) deux variables aléatoires réelles discrètes, définies sur un espace probabilisé \\((\\Omega,\\mathcal{A},P)\\) et que\n\\[\\begin{aligned}\n  X(\\Omega) &= \\{x_1,x_2,\\ldots,x_{\\ell}\\} \\\\\n  Y(\\Omega) &= \\{y_1,y_2,\\ldots,y_k\\} \\\\\n            & \\quad (\\ell \\text{ et } k \\in \\mathbb{N})\\end{aligned}\\]\nLa loi du couple \\((X,Y)\\), dite loi de probabilité conjointe ou simultanée, est entièrement définie par les probabilités:\n\\[p_{ij} = P(X=x_i;Y=y_j) = P(\\{X=x_i\\}\\cap\\{Y=y_j\\})\\]\nOn a\n\\[p_{ij} \\geq 0 \\quad \\text{et} \\quad \\sum_{i=1}^{\\ell} \\sum_{j=1}^{k} p_{ij} = 1\\]\nLe couple \\((X,Y)\\) s’appelle variable aléatoire à deux dimensions et peut prendre \\(\\ell \\times k\\) valeurs.\nTable de probabilité conjointe\nLes probabilités \\(p_{ij}\\) peuvent être présentées dans un tableau à deux dimensions qu’on appelle table de probabilité conjointe:\n\nTable de probabilité conjointe\n\n\n\n\n\n\n\n\n\n\n\n\\(X\\)\\\\(Y\\)\n\n\\(y_1\\)\n\\(y_2\\)\n\\(\\ldots\\)\n\\(y_j\\)\n\\(\\ldots\\)\n\\(y_k\\)\n\n\n\n\\(x_1\\)\n\\(p_{11}\\)\n\\(p_{12}\\)\n\n\\(p_{1j}\\)\n\n\\(p_{1k}\\)\n\n\n\\(\\vdots\\)\n\n\n\n\n\n\n\n\n\\(x_i\\)\n\\(p_{i1}\\)\n\\(p_{i2}\\)\n\n\\(p_{ij}\\)\n\n\\(p_{ik}\\)\n\n\n\\(\\vdots\\)\n\n\n\n\n\n\n\n\n\\(x_{\\ell}\\)\n\\(p_{\\ell 1}\\)\n\\(p_{\\ell 2}\\)\n\n\\(p_{\\ell j}\\)\n\n\\(p_{\\ell k}\\)\n\n\n\nA la première ligne figure l’ensemble des valeurs de \\(Y\\) et à la première colonne figure l’ensemble des valeurs de \\(X\\). La probabilité \\(p_{ij} = P(X=x_i;Y=y_j)\\) est à l’intersection de la \\(i^{e}\\) et de la \\(j^{e}\\) colonne.\nLois marginales\nLorsqu’on connaît la loi conjointe des variables aléatoires \\(X\\) et \\(Y\\), on peut aussi s’intéresser à la loi de probabilité de \\(X\\) seule et de \\(Y\\) seule. Ce sont les lois de probabilité marginales.\n\nLoi marginale de \\(X\\): \\[p_{i.} = P(X=x_i) = P[\\{X=x_i\\}\\cap \\Omega] = \\sum_{j=1}^k p_{ij} \\quad \\quad \\forall \\, i=1,2,\\ldots,\\ell\\]\nLoi marginale de \\(Y\\): \\[p_{.j} = P(Y=y_j) = P[ \\Omega \\cap \\{Y=y_j\\}] = \\sum_{i=1}^{\\ell} p_{ij} \\quad \\quad \\forall \\, j=1,2,\\ldots,k\\]\n\nOn peut calculer les lois marginales directement depuis la table de la loi conjointe. La loi marginale de \\(X\\) est calculée en faisant les totaux par ligne, tandis que celle de \\(Y\\) l’est en faisant les totaux par colonne.\nC’est le fait que les lois de \\(X\\) et \\(Y\\) individuellement puissent être lues dans les marges du tableau qui leur vaut leur nom de lois marginales.\n\nTable de probabilité conjointe avec les lois marginales\n\n\n\n\n\n\n\n\n\n\n\n\n\\(X\\)\\\\(Y\\)\n\n\\(y_1\\)\n\\(y_2\\)\n\\(\\ldots\\)\n\\(y_j\\)\n\\(\\ldots\\)\n\\(y_k\\)\nMarginale de \\(X\\)\n\n\n\n\n\\(x_1\\)\n\\(p_{11}\\)\n\\(p_{12}\\)\n\n\\(p_{1j}\\)\n\n\\(p_{1k}\\)\n\\(p_{1.}\\)\n\n\n\\(\\vdots\\)\n\n\n\n\n\n\n\n\n\n\\(x_i\\)\n\\(p_{i1}\\)\n\\(p_{i2}\\)\n\n\\(p_{ij}\\)\n\n\\(p_{ik}\\)\n\\(p_{i.}\\)\n\n\n\\(\\vdots\\)\n\n\n\n\n\n\n\n\n\n\\(x_{\\ell}\\)\n\\(p_{\\ell 1}\\)\n\\(p_{\\ell 2}\\)\n\n\\(p_{\\ell j}\\)\n\n\\(p_{\\ell k}\\)\n\\(p_{\\ell .}\\)\n\n\n\n\n\n\n\n\n\n\n\n\nMarginale de \\(Y\\)\n\n\\(p_{.1}\\)\n\\(p_{.2}\\)\n\n\\(p_{. j}\\)\n\n\\(p_{.k}\\)\n1\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nOn tire au hasard 3 boules d’une urne contenant 3 boules rouges, 4 blanches et 5 noires. \\(X\\) et \\(Y\\) désignent respectivement le nombre de boules rouges et celui de boules blanches tirées. Déterminer la loi de probabilité conjointe du couple \\((X,Y)\\) ainsi que les lois marginales de \\(X\\) et de \\(Y\\).\n\n\nLois conditionnelles\nPour chaque valeur \\(y_j\\) de \\(Y\\) telle que \\(p_{.j} = P(Y=y_j) \\neq 0\\) on peut définir la loi conditionnelle de \\(X\\) sachant \\(Y=y_j\\) par\n\\[p_{i/j} = P(X=x_i / Y=y_j) = \\frac{P(X=x_i;Y=y_j)}{P(Y=y_j)} = \\frac{p_{ij}}{p_{.j}} \\quad \\quad \\forall i = 1,2,\\ldots,\\ell\\]\nDe même on définit la loi de \\(Y\\) sachant \\(X=x_i\\) par\n\\[p_{j/i} = P(Y=y_j / X=x_i) = \\frac{P(X=x_i;Y=y_j)}{P(X=x_i)} = \\frac{p_{ij}}{p_{i.}} \\quad \\quad \\forall j = 1,2,\\ldots,k\\]\nIndépendance de variables aléatoires\n\nThéorème 1.4 On dit que deux v.a.r.d sont indépendantes si et seulement si\n\\[P(X=x_i;Y=y_j) = P(X=x_i) P(Y=y_j)\\] \\[\\forall \\, i = 1,2,\\ldots,\\ell \\text{ et }  j = 1,2,\\ldots,k\\]\n\nOn montre que\n\\[P(\\{X\\in A\\} \\cap \\{Y \\in B\\}) = P(\\{X\\in A\\}) P(\\{Y \\in B\\}) \\quad \\quad \\forall \\,\\, A \\text{ et } B \\in \\mathcal{A}\\]\nPropriétés\nSoit deux v.a.r.d. \\(X\\) et \\(Y\\),\n\n\\(E(X+Y)=E(X)+E(Y)\\)\nSi \\(X\\) et \\(Y\\) sont indépendantes alors \\(E(XY)=E(X)E(Y)\\). Mais la réciproque n’est pas toujours vraie.\nCovariance\nSoit \\(X\\) et \\(Y\\) deux v.a.r.d. On appelle covariance de \\(X\\) et de \\(Y\\) la valeur si elle existe de\n\\[\n\\begin{align}\nCov(X,Y) &= E[(X-E(X))(Y-E(Y))] \\\\ &= \\sum_i \\sum_j (x_i-E(X))(y_j-E(Y)) p_{ij}\n\\end{align}\\]\nqu’on peut calculer en utilisant la formule suivante\n\\[Cov(X,Y) = E(XY) - E(X)E(Y)\\]\nPropriétés\n\n\\(Cov(X,Y)=Cov(Y,X)\\)\n\\(Cov(aX_1+bX_2,Y) = a Cov(X_1,Y) + b Cov(X_2,Y)\\)\n\\(V(X+Y)= V(X) + V(Y) + 2 Cov(X,Y)\\)\n\nSi \\(X\\) et \\(Y\\) sont indépendantes alors\n\n\\(Cov(X,Y) = 0\\) (la réciproque n’est pas vraie)\n\\(V(X+Y) = V(X) + V(Y)\\) (la réciproque n’est pas vraie)\n\n\nCoefficient de corrélation linéaire\nOn appelle coefficient de corrélation linéaire de \\(X\\) et de \\(Y\\) la valeur définie par\n\\[\\rho = \\rho(X,Y) = \\frac{Cov(X,Y)}{\\sqrt{V(X)V(Y)}} = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}\\]\nOn peut montrer que \\[-1 \\leq \\rho(X,Y) \\leq 1\\]\nPour le montrer on peut partir du fait que la variance est toujours positive ou nulle. Donc \\(V(\\frac{X}{\\sigma_X} + \\frac{Y}{\\sigma_Y}) \\geq 0\\) et \\(V(\\frac{X}{\\sigma_X} - \\frac{Y}{\\sigma_Y}) \\geq 0\\).\nInterprétation de \\(\\rho\\)\n\nLe coefficient de corrélation est une mesure du degré de linéarité entre \\(X\\) et \\(Y\\).\nLes valeurs de \\(\\rho\\) proches de \\(1\\) ou \\(-1\\) indiquent une linéarité quasiment rigoureuse entre \\(X\\) et \\(Y\\).\nLes valeurs de \\(\\rho\\) proche de 0 indiquent une absence de toute relation linéaire.\nLorsque \\(\\rho(X,Y)\\) est positif, \\(Y\\) a tendance à augmenter si \\(X\\) en fait autant.\nLorsque \\(\\rho(X,Y) < 0\\), \\(Y\\) a tendance à diminuer si \\(X\\) augmente.\nSi \\(\\rho(X,Y) =0\\), on dit que ces deux statistiques sont non corrélées."
  },
  {
    "objectID": "lois-usuelles-discretes.html",
    "href": "lois-usuelles-discretes.html",
    "title": "2  Lois usuelles discrètes",
    "section": "",
    "text": "Définition 2.1 Une distribution de probabilité suit une loi uniforme lorsque toutes les valeurs prises par la variable aléatoire sont équiprobables. Si \\(n\\) est le nombre de valeurs différentes prises par la variable aléatoire alors on a:\n\\[\nP(X=x_i)=\\frac{1}{n} \\qquad \\forall \\, i \\in \\{1,\\ldots, n\\}\n\\tag{2.1}\\]\n\nExemple: La distribution des chiffres obtenus au lancer de dé (si ce dernier est non pipé) suit une loi uniforme dont la loi de probabilité est la suivante :\n\n\n\n\\(x_i\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(P(X = x_i)\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\n\n\nMoments de loi uniforme discrète\nDans le cas particulier d’une loi uniforme discrète où chaque valeur de la variable aléatoire \\(X\\) correspond à son rang, i.e. \\(x_i=i \\, \\, \\forall i \\in \\{1,\\ldots, n\\}\\), on a: \\[E(X)=\\frac{n+1}{2} \\quad \\text{et} \\quad V(X)=\\frac{n^2-1}{12}\\] La démonstration de ces résultats est établie en utilisant les égalités (cf. Annexe) \\[\\sum_{i=1}^n i=\\frac{n(n+1)}{2} \\quad \\text{et} \\quad \\sum_{i=1}^n i^2=\\frac{n(n+1)(2n+1)}{6}\\]\nEn revenant à l’exemple du lancer du dé de cette section, on peut calculer directement les moments de \\(X\\): \\[E(X)=\\frac{6+1}{2}=3.5\\] et \\[V(X)=\\frac{6^2-1}{12}=\\frac{35}{12}\\simeq 2.92\\]"
  },
  {
    "objectID": "lois-usuelles-discretes.html#loi-de-bernoulli-mathcalbp",
    "href": "lois-usuelles-discretes.html#loi-de-bernoulli-mathcalbp",
    "title": "2  Lois usuelles discrètes",
    "section": "Loi de Bernoulli \\(\\mathcal{B}(p)\\)",
    "text": "Loi de Bernoulli \\(\\mathcal{B}(p)\\)\n\nDéfinition 2.2 On réalise une expérience dont le résultat sera interprété soit comme un succès soit comme un échec. On définit alors la variable aléatoire \\(X\\) en lui donnant la valeur 1 lors d’un succès et 0 lors d’un échec (variable indicatrice). La loi de probabilité de \\(X\\) est alors\n\\[\n\\begin{align}\n    &p(1)=P(X=1)=p  \\\\\n    &p(0)=P(X=0)= 1-p=q \\notag\n\\end{align}\n\\tag{2.2}\\]\noù \\(p\\) est la probabilité d’un succès, \\(0 \\leq p \\leq 1\\).\nUne variable aléatoire \\(X\\) est dite de Bernoulli \\(X \\sim \\mathcal{B} \\left({p}\\right)\\) s’il existe un nombre \\(p \\, \\in \\, ]0,1[\\) tel que la loi de probabilité de \\(X\\) soit donnée par (2.2).\n\nLa fonction de répartition est définie par: \\[F(x) =\n       \\left\\{\n       \\begin{array}{ll}\n         0 & \\quad \\text{si $x < 0$} \\\\\n         1 - p & \\quad \\text{si $0 \\leq x < 1$} \\\\\n         1 & \\quad \\text{si $x \\geq 1$}.\n       \\end{array}\n       \\right.\\]\nL’espérance la loi de Bernoulli est \\(p\\), en effet\n\\[E(X) =1 \\times P(X=1)+0 \\times P(X=0)=P(X=1)=p\\]\nLa variance la loi de Bernoulli est \\(np\\), en effet\n\\[V(X) =E(X^2)-E^2(X)=p-p^2=p(1-p)=pq\\] car \\[E(X^2) =1^2\\times P(X=1)+0^2 \\times P(X=0)=P(X=1)=p\\]"
  },
  {
    "objectID": "lois-usuelles-discretes.html#loi-binomiale-mathcalbnp",
    "href": "lois-usuelles-discretes.html#loi-binomiale-mathcalbnp",
    "title": "2  Lois usuelles discrètes",
    "section": "Loi Binomiale \\(\\mathcal{B}(n,p)\\)",
    "text": "Loi Binomiale \\(\\mathcal{B}(n,p)\\)\n\n\n\n\n\n\nNote\n\n\n\nDécrite pour la première fois par Isaac Newton en 1676 et démontrée pour la première fois par le mathématicien suisse Jacob Bernoulli en 1713, la loi binomiale est l’une des distributions de probabilité les plus fréquemment rencontrées en statistique appliquée.\n\n\nSupposons qu’on exécute maintenant \\(n\\) épreuves indépendantes, chacune ayant \\(p\\) pour probabilité de succès et \\(1-p\\) pour probabilité d’échec. La variable aléatoire \\(X\\) qui compte le nombre de succès sur l’ensemble des \\(n\\) épreuves est dite variable aléatoire binomiale de paramètres \\(n\\) et \\(p\\).\n\n\n\n\n\n\nAstuce\n\n\n\nUne variable de Bernoulli n’est donc qu’une variable binomiale de paramètres \\((1,p)\\).\n\n\n\nDéfinition 2.3 Si on effectue \\(n\\) épreuves successives indépendantes où on note à chaque fois la réalisation ou non d’un certain événement \\(A\\), on obtient une suite de la forme \\(AA\\bar{A}A\\bar{A}\\ldots \\bar{A}AA\\). Soit \\(X\\) le nombre de réalisations de \\(A\\). On définit ainsi une v.a. \\(X\\) qui suit une loi binomiale de paramètres \\(n\\) et \\(p=P(A)\\), caractérisée par \\(X(\\Omega)=\\{0, 1,\\ldots, n\\}\\) :\n\\[\nP(X=k)=\\binom{n}{k}p^k (1-p)^{n-k} \\qquad 0\\leq k \\leq n   \n\\tag{2.3}\\]\nOn écrit \\(X \\sim \\mathcal{B} \\left({n, p}\\right)\\). Donc la loi binomiale modélise le nombre de réalisations de \\(A\\) (succès) obtenues lors de la répétition indépendante et identique de \\(n\\) épreuves de Bernoulli.\n\n\n\n\n\n\n\nAstuce\n\n\n\nPour établir (2.3) il faut remarquer que \\(\\binom{n}{k}\\) est le nombre d’échantillons de taille \\(n\\) comportant exactement \\(k\\) événements \\(A\\), de probabilité \\(p^k\\), indépendamment de l’ordre, et donc \\(n-k\\) événements \\(\\bar{A}\\), de probabilité \\((1-p)^{n-k}\\).\n\n\nRemarque: Il est possible d’obtenir aisément les valeurs des combinaisons de la loi binomiale en utilisant le triangle de Pascal.\nEn utilisant la formule du binôme de Newton, on vérifie bien que c’est une loi de probabilité:\n\\[{\\sum_{k=0}^nP(X=k)=\\sum_{k=0}^n\\binom{n}{k} p^{k}(1-p)^{n-k}=[p+(1-p)]^n=1}\\]\nExemple: On jette cinq pièces équilibrées. Les résultats sont supposés indépendants. Donner la loi de probabilité de la variable \\(X\\) qui compte le nombre de piles obtenus.\nMoments de la loi Binomiale\nPour calculer facilement les moments de cette loi, nous allons associer à chaque épreuve \\(i\\), \\(1\\leq i \\leq n\\), une v.a. de Bernoulli (variable indicatrice sur \\(A\\)): \\[{1}_A=X_i = \\left\\{\n\\begin{array}{l l}\n1 & \\quad \\text{si $A$ est réalisé}\\\\\n0 & \\quad \\text{si $\\bar{A}$ est réalisé}\\\\\n  \\end{array} \\right.\\] On peut écrire alors: \\(X=\\sum_{i=1}^nX_i=X_1+X_2+\\ldots+X_n\\), ce qui nous permet de déduire aisément:\n\\[\\begin{aligned}\n    E(X)    &=E\\left(\\sum_{i=1}^nX_i\\right)=\\sum_{i=1}^nE(X_i)=np \\\\\n    \\text{et} \\nonumber \\\\\n    V(X)    &=V\\left(\\sum_{i=1}^nX_i\\right) \\\\\n            &=\\sum_{i=1}^nV(X_i)=np(1-p) \\quad \\text{car les v.a. $X_i$ sont indépendantes.}\n  \\end{aligned}\\]\nLe calcul direct des moments de \\(X\\) peut s’effectuer à partir de la définition générale, mais de façon beaucoup plus laborieuse:\n\\[\\begin{aligned}\nE(X)   &= \\sum_{k=0}^nk \\binom{n}{k} p^{k}(1-p)^{n-k} \\\\\n        &=\\sum_{k=1}^nk \\frac{n!}{k!(n-k)!} p^{k}(1-p)^{n-k} \\\\\n        &= \\sum_{k=1}^n\\frac{n!}{(k-1)!(n-k)!} p^{k}(1-p)^{n-k} \\\\\n        &= np \\sum_{k=1}^n\\frac{(n-1)!}{(k-1)!(n-k)!} p^{k-1}(1-p)^{n-k} \\\\\n        &= np \\sum_{j=0}^{n-1}\\frac{(n-1)!}{j!(n-1-j)!}p^j (1-p)^{n-1-j} \\\\\n        &=np \\sum_{j=0}^{n-1}\\binom{n-1}{j} p^{j}(1-p)^{n-1-j} \\\\\n        &= np [p+(1-p)]^{n-1}=np\n\\end{aligned}\\]\nPour obtenir \\(E(X^2)\\) par un procédé de calcul identique, on passe par l’intermédiaire du moment factoriel \\(E[X(X-1)]=E(X^2)-E(X)\\): \\[\\begin{aligned}\n  E[X(X-1)]&= \\sum_{k=0}^nk(k-1) \\frac{n!}{k!(n-k)!} p^{k}(1-p)^{n-k} \\\\\n  &= n(n-1)p^2 \\sum_{k=2}^{n}\\frac{(n-2)!}{(k-2)!(n-k)!} p^{k-2}(1-p)^{n-k} \\\\ &= n(n-1)p^2 \\sum_{j=0}^{n-2}\\binom{n-2}{j} p^{j}(1-p)^{n-2-j} \\\\\n  &= n(n-1)p^2[p+(1-p)]^{n-2}= n(n-1)p^2\n   \\end{aligned}\\]\nOn en déduit alors:\n\\[E(X^2)=E[X(X-1)]+E(X)= n(n-1)p^2+np,\\]\npuis:\n\\[\\begin{aligned}\n   V(X) &=n(n-1)p^2+np-(np)^2 \\\\\n        &=n^2p^2+np(1-p)-n^2p^2 \\\\\n        &=np(1-p)\n  \\end{aligned}\\]\nLe nombre de résultats pile apparus au cours de \\(n\\) jets d’une pièce de monnaie suit une loi binomiale \\(\\mathcal{B} \\left({n, 1/2}\\right)\\): \\[P(X=k)=\\binom{n}{k}\\left(\\frac{1}{2}\\right)^k \\left(\\frac{1}{2}\\right)^{n-k}=\\frac{\\binom{n}{k}}{2^n}, \\quad 0\\leq k \\leq n\\] avec \\(E(X)=n/2\\) et \\(V(X)=n/4\\).\nLe nombre \\(N\\) de boules rouges apparues au cours de \\(n\\) tirages avec remise dans une urne contenant deux rouges, trois vertes et une noire suit une loi binomiale \\(\\mathcal{B} \\left({n, 1/3}\\right)\\): \\[P(N=k)=\\binom{n}{k}\\left(\\frac{1}{3}\\right)^k \\left(\\frac{2}{3}\\right)^{n-k}=\\binom{n}{k} \\frac{2^{n-k}}{3^n}, \\quad 0\\leq k \\leq n\\] avec \\(E(X)=n/3\\) et \\(V(X)=2n/9\\).\n\nThéorème 2.1 Si \\(X_1 \\sim \\mathcal{B} \\left({n_1, p}\\right)\\) et \\(X_2 \\sim \\mathcal{B} \\left({n_2, p}\\right)\\), les v.a. \\(X_1\\) et \\(X_2\\) étant indépendantes, alors \\(X_1+X_2 \\sim \\mathcal{B} \\left({n_1+n_2, p}\\right)\\). Ceci résulte de la définition d’une loi binomiale puisqu’on totalise ici le résultat de \\(n_1+n_2\\) épreuves indépendantes."
  },
  {
    "objectID": "lois-usuelles-discretes.html#loi-de-poisson-mathcalplambda",
    "href": "lois-usuelles-discretes.html#loi-de-poisson-mathcalplambda",
    "title": "2  Lois usuelles discrètes",
    "section": "Loi de Poisson \\(\\mathcal{P}(\\lambda)\\)",
    "text": "Loi de Poisson \\(\\mathcal{P}(\\lambda)\\)\n\n\n\n\n\n\nNote\n\n\n\nLa loi de Poisson est découverte au début du XIX\\(^e\\) siècle par le magistrat français Siméon-Denis Poisson. Les variables aléatoires de Poisson ont un champ d’application fort vaste, en particulier du fait qu’on peut les utiliser pour approximer des variables aléatoires binomiales de paramètres \\((n,p)\\) pour autant que \\(n\\) soit grand et \\(p\\) assez petit pour que \\(np\\) soit d’ordre de grandeur moyen.\n\n\n\nDéfinition 2.4 Une v.a. \\(X\\) suit une loi de Poisson de paramètre \\(\\lambda>0\\) si c’est une variable à valeurs entières, \\(X(\\Omega)=\\mathbb{N}\\), donc avec une infinité de valeurs possibles, de probabilité:\n\\[\nP(X=k)=e^{-\\lambda} \\frac{\\lambda^k}{k!}, \\quad k \\in \\mathbb{N}\n\\tag{2.4}\\]\nCette loi ne dépend qu’un seul paramètre réel positif \\(\\lambda\\), avec l’écriture symbolique \\(X \\sim \\mathcal{P}(\\lambda)\\).\n\nLe développement en série entière de l’exponentielle \\(e^\\lambda=\\displaystyle \\sum_{k=0}^{+\\infty} \\frac{\\lambda^k}{k!}\\) permet de vérifier qu’il s’agit bien d’une loi de probabilité:\n\\[\\sum_{k=0}^{\\infty} P(X=k)=\\sum_{k=0}^{\\infty} e^{-\\lambda} \\frac{\\lambda^k}{k!}=e^{-\\lambda}\\sum_{k=0}^{\\infty} \\frac{\\lambda^k}{k!}=e^{-\\lambda}e^{\\lambda}=1\\]\nMoments de loi de Poisson\nLe calcul de l’espérance mathématique se déduit du développement en série entière de l’exponentielle: \\[\\begin{aligned}\n    E(X)&=\\sum_{k=0}^{\\infty} k P(X=k)=\\sum_{k=1}^{\\infty} k e^{-\\lambda} \\frac{\\lambda^k}{k!} \\\\\n        &=e^{-\\lambda} \\sum_{k=1}^{\\infty}  \\frac{\\lambda^k}{(k-1)!}=\\lambda e^{-\\lambda} \\sum_{k=1}^{\\infty}  \\frac{\\lambda^{k-1}}{(k-1)!} \\\\\n        &= \\lambda e^{-\\lambda} \\sum_{j=0}^{\\infty}  \\frac{\\lambda^{j}}{j!}= \\lambda e^{-\\lambda}  e^{\\lambda} \\\\\n        &= \\lambda.\\end{aligned}\\] Pour calculer la variance nous n’allons pas calculer \\(E(X^2)\\) mais le moment factoriel \\(E[X(X-1)]\\) qui s’obtient plus facilement, selon la méthode précédente:\n\\[\\begin{aligned}\n    E[X(X-1)] &=\\sum_{k=0}^{\\infty} k(k-1)P(X=k)=\\sum_{k=2}^{\\infty} k(k-1)  \\,e^{-\\lambda} \\frac{\\lambda^k}{k!} \\\\\n        &=e^{-\\lambda} \\sum_{k=2}^{\\infty}  \\frac{\\lambda^k}{(k-2)!}=\\lambda^2 e^{-\\lambda} \\sum_{k=2}^{\\infty}  \\frac{\\lambda^{k-2}}{(k-2)!} \\\\\n        &= \\lambda^2 e^{-\\lambda} \\sum_{j=0}^{\\infty}  \\frac{\\lambda^{j}}{j!}= \\lambda^2 e^{-\\lambda}  e^{\\lambda} = \\lambda^2.\\end{aligned}\\] On en déduit: \\[\\begin{aligned}\n    V(X)&=E(X^2)-E^2(X)=E[X(X-1)]+E(X)-E^2(X) \\\\\n        &=\\lambda^2+\\lambda-\\lambda^2=\\lambda.\\end{aligned}\\]\n\nThéorème 2.2 Si \\(X\\) et \\(Y\\) sont deux variables indépendantes suivant des lois de Poisson \\[X \\sim \\mathcal{P}(\\lambda) \\quad \\text{et} \\quad Y \\sim \\mathcal{P}(\\mu)\\] alors leur somme suit aussi une loi de Poisson: \\[X+Y \\sim \\mathcal{P}(\\lambda+\\mu)\\]\n\nExemple: Soit \\(X\\) la variable aléatoire associée au nombre de micro-ordinateurs vendus chaque jour dans le magasin. On suppose que \\(X\\) suit une loi de Poisson de paramètre \\(\\lambda=5\\). On écrit alors \\(X \\sim \\mathcal{P}(5).\\)\nLa probabilité associée à la vente de 5 micro-ordinateurs se détermine par : \\[P(X=5)=e^{-5} \\frac{5^5}{5!}=e^{-5}\\simeq 0.1755\\] La probabilité de vendre au moins 2 micro-ordinateurs est égal à:\n\\[\\begin{aligned}\nP(X \\geq 2)&=1-\\left(e^{-5} \\frac{5^0}{0!}+e^{-5} \\frac{5^1}{1!}\\right)\\simeq 0.9596\\end{aligned}\\]\nLe nombre moyen de micro-ordinateurs vendus chaque jour dans le magasin est égal à 5 puisque \\(E(X)=\\lambda=5\\)."
  },
  {
    "objectID": "lois-usuelles-discretes.html#approximation-dune-loi-binomiale",
    "href": "lois-usuelles-discretes.html#approximation-dune-loi-binomiale",
    "title": "2  Lois usuelles discrètes",
    "section": "Approximation d’une loi binomiale",
    "text": "Approximation d’une loi binomiale\nLe théorème de Poisson nous montre que si \\(n\\) est suffisamment grand et \\(p\\) assez petit, alors on peut approcher la distribution d’une loi binomiale de paramètres \\(n\\) et \\(p\\) par celle d’une loi de Poisson de paramètre \\(\\lambda=np\\), en effet \\[\\text{si} \\; n \\rightarrow \\infty \\; \\text{et}\\; p \\rightarrow 0 \\; \\text{alors} \\; X: \\mathcal{B}(n, p) \\rightarrow \\mathcal{P}(\\lambda)\\]\nUne bonne approximation est obtenue si \\(n \\geq 50\\) et \\(np \\leq 5\\).\nDans ce contexte, la loi de Poisson est souvent utilisée pour modéliser le nombre de succès lorsqu’on répète un très grand nombre de fois une expérience ayant une chance très faible de réussir par une loi de Poisson (nombre de personnes dans la population française atteints d’une maladie rare, par exemple).\nOn cherche la probabilité de trouver au moins un centenaire parmi 200 personnes dans une population où une personne sur cent est un centenaire.\nLa probabilité \\(p=1/100=0.01\\) étant faible et \\(n=200\\) étant suffisamment grand, on peut modéliser le nombre \\(X\\) de centenaires pris parmi 200 personnes par la loi de Poisson de paramètre \\(\\lambda=200 \\times 0.01=2\\). Donc on a: \\[P(X\\geq 1)=1-P(X=0)=1-e^{-2}\\simeq 0.86\\]\nSoit une v.a. \\(X\\) telle que \\(X \\sim \\mathcal{B}(100, 0.01)\\), les valeurs des probabilités pour \\(k\\) de 0 à 5 ainsi que leur approximation à \\(10^{-3}\\) avec une loi de Poisson de paramètre \\(\\lambda= np =1\\) sont données dans le tableau ci-dessous :\n\n\n\n\\(k\\)\n0\n1\n2\n3\n4\n5\n\n\n\n\n\\(P(X = k)\\)\n0.366\n0.370\n0.185\n0.061\n0.015\n0.000\n\n\nApproximation\n0.368\n0.368\n0.184\n0.061\n0.015\n0.003\n\n\n\nDans le cas de cet exemple où \\(n =100\\) et \\(np =1\\), l’approximation de la loi binomiale par une loi de poisson donne des valeurs de probabilités identiques à \\(10^{-3}\\) près."
  },
  {
    "objectID": "lois-usuelles-discretes.html#loi-géométrique-ou-de-pascal-mathcalgp",
    "href": "lois-usuelles-discretes.html#loi-géométrique-ou-de-pascal-mathcalgp",
    "title": "2  Lois usuelles discrètes",
    "section": "Loi Géométrique ou de Pascal \\(\\mathcal{G}(p)\\)",
    "text": "Loi Géométrique ou de Pascal \\(\\mathcal{G}(p)\\)\nOn effectue des épreuves successives indépendantes jusqu’à la réalisation d’un événement particulier \\(A\\) de probabilité \\(p=P(A)\\) et on note \\(X\\) le nombre aléatoire d’épreuves effectuées. On définit ainsi une v.a. à valeurs entières de loi géométrique, ou de Pascal. A chaque épreuve est associé l’ensemble fondamental \\(\\Omega=\\{A, \\bar{A}\\}\\) et l’événement \\(\\{X=k\\}\\) pour \\(k\\in \\mathbb{N^*}\\) est représenté par une suite de \\(k-1\\) événements \\(\\bar{A}\\), terminée par l’événement \\(A\\): \\[\\underbrace{\\bar{A}\\bar{A}\\ldots \\bar{A}}_{k-1}A\\] D’où:\n\\[\nP(X=k)=(1-p)^{k-1}p \\quad \\forall \\, k \\in \\mathbb{N^*}\n\\tag{2.5}\\]\nCette loi peut servir à modéliser des temps de vie, ou des temps d’attente, lorsque le temps est mesuré de manière discrète (nombre de jours par exemple).\nEn utilisant la série entière\n\\[\n\\sum_{k=0}^\\infty x^k = 1/(1-x) \\quad \\text{pour} \\quad |x|<1\n\\tag{2.6}\\]\non vérifie bien que c’est une loi de probabilité:\n\\[\\begin{aligned}\n\\sum_{k=1}^\\infty P(X=k)&= \\sum_{k=1}^\\infty (1-p)^{k-1}p = p \\sum_{j=0}^\\infty (1-p)^{j} \\\\\n&= p \\frac{1}{1-(1-p)}=1\\end{aligned}\\]\nMoments de loi Géométrique\nEn dérivant la série entière (2.5) ci-dessus, on obtient \\(\\sum_{k=1}^\\infty k x^{k-1}=1/(1-x)^2\\). Ceci permet d’obtenir l’espérance:\n\\[E(X)=\\sum_{k=1}^\\infty kp(1-p)^{k-1}=\\frac{p}{[1-(1-p)]^2}=\\frac{1}{p}\\]\nEn d’autres termes, si des épreuves indépendantes ayant une probabilité \\(p\\) d’obtenir un succès sont réalisés jusqu’à ce que le premier succès se produise, le nombre espéré d’essais nécessaires est égal à \\(1/p\\). Par exemple, le nombre espéré de jets d’un dé équilibré qu’il faut pour obtenir la valeur 1 est 6.\nLe calcul de la variance se fait à partir du moment factoriel et en utilisant la dérivée seconde de la série entière (2.5): \\(\\sum_{k=2}^\\infty k(k-1) x^{k-2} = 2/(1-x)^3\\), Donc\n\\[\\begin{aligned}\nE[X(X-1)]   &=\\sum_{k=2}^\\infty k(k-1)p(1-p)^{k-1} \\\\\n            &= p(1-p)\\sum_{k=2}^\\infty k(k-1)(1-p)^{k-2} \\\\\n            &= \\frac{2p(1-p)}{[1-(1-p)]^3}=\\frac{2(1-p)}{p^2}\n            \\end{aligned}\\]\nd’où on déduit: \\[V(X)=E[X(X-1)]+E(X)-E^2(X)=\\frac{1-p}{p^2}\\]\nSi l’on considère la variable aléatoire \\(X\\) “nombre de naissances observées jusqu’à l’obtention d’une fille” avec p = 1/2 (même probabilité de naissance d’une fille ou d’un garçon), alors X suit une loi géométrique et on a pour tout \\(k\\in \\mathbb{N^*}\\):\n\\[P(X=k)=(1-1/2)^{k-1}(1/2)=1/2^k\\]\navec \\(E(X)=2\\) et \\(V(X)=2\\)."
  },
  {
    "objectID": "lois-usuelles-discretes.html#loi-binomiale-négative-mathcalbnrp",
    "href": "lois-usuelles-discretes.html#loi-binomiale-négative-mathcalbnrp",
    "title": "2  Lois usuelles discrètes",
    "section": "Loi Binomiale Négative \\(\\mathcal{BN}(r,p)\\)",
    "text": "Loi Binomiale Négative \\(\\mathcal{BN}(r,p)\\)\n\n\\(\\varepsilon\\): “On répéte l’épreuve de Bernoulli jusqu’à obtenir un total de \\(r\\) succès”.\nExemple avec : \\[\\bar{A} \\quad  {A} \\quad  \\bar{A} \\quad  \\bar{A} \\quad  \\bar{A} \\quad  {A} \\quad \\bar{A} \\quad  \\bar{A} \\quad  {A}\\] \\[{E} \\quad  {S} \\quad  {E} \\quad  {E} \\quad  {E} \\quad  {S} \\quad {E} \\quad  {E} \\quad  {S}\\]\nMais on peut obtenir d’autres façons: \\[{S} \\quad  {E} \\quad  {E} \\quad  {E} \\quad  {E} \\quad  {E} \\quad {S} \\quad  {E} \\quad  {S}\\] \\[{E} \\quad  {E} \\quad  {E} \\quad  {E} \\quad  {S} \\quad  {E} \\quad {S} \\quad  {E} \\quad  {S}\\]\nChaque épreuve a \\({p}\\) pour probabilité de succès et \\({1-p}\\) pour probabilité d’échec.\nDésignons \\(X=\\)“le nombre d’épreuves nécessaires pour atteindre ce résultat”. \\[\\underbrace{\\overbrace{{E} \\quad  {S} \\quad  {E} \\quad  {E} \\quad  {E} \\quad  {S} \\quad {E} \\quad  {E}}^{ {r-1 \\, succès}\\, et \\, {k-r \\, échecs}} \\quad  {S}}_{X=k}\\]\n\\(X(\\Omega)=\\{r,r+1,r+2,\\ldots\\}\\). On dit \\(X \\sim \\mathcal{BN}(r,p)\\).\n\\(\\forall \\, k \\in X(\\Omega),\\) \\[P(X=k) = \\binom{{k-1}}{{r-1}} {p^r} {(1-p)^{k-r}}\\]\n\n\n\\(\\mathcal{G}(p)=\\mathcal{BN}(1,p)\\)\n\n\\(\\varepsilon\\): “On répéte l’épreuve de Bernoulli jusqu’à obtenir un total de \\(r\\) succès”.\nSoit, \\[{E} \\quad \\ldots \\quad {E} \\quad {S} \\quad  {E} \\quad  \\ldots \\quad  {E} \\quad  {S} \\ldots \\quad {E} \\ldots \\quad  {E} \\quad  {S}\\]\nSoit, \\(Y_1\\) le nombre d’épreuves nécessaires jusqu’au premier succès, \\(Y_2\\) le nombre d’épreuves supplémentaires nécessaires pour obtenir un deuxième succès, \\(Y_3\\) celui menant au 3ème et ainsi de suite.\nCàd, \\[\\underbrace{{E} \\quad \\ldots \\quad {E} \\quad {S}}_{Y_1} \\quad  \\underbrace{{E} \\quad  \\ldots \\quad  {E} \\quad  {S}}_{Y_2} \\quad \\underbrace{\\ldots}_{\\ldots} \\quad \\underbrace{{E} \\quad \\ldots \\quad  {E} \\quad  {S}}_{Y_r}\\]\nLes tirages étants indépendantes et ayant toujours la même probabilité de succès, chacune des variables \\(Y_1,Y_2,\\ldots,Y_r\\) est géométrique \\(\\mathcal{G}(p)\\).\n\\(X=\\)“le nombre d’épreuves nécessaires à l’obtention de \\(r\\) succès”\\(=Y_1 + Y_2 + \\ldots + Y_r\\).\nDonc, \\[E(X)= E(Y_1) + E(Y_2) + \\ldots + E(Y_r) = \\sum_{i=1}^r \\frac{1}{p} = \\frac{r}{p}\\] et \\[V(X)= \\sum_{i=1}^r V(Y_i) = \\frac{r(1-p)}{p^2}\\] car les \\(Y_i\\) sont indépendantes."
  },
  {
    "objectID": "exos1.html",
    "href": "exos1.html",
    "title": "Feuille d’exercices 1",
    "section": "",
    "text": "Exercice 1 Questions diverses:\n\nEn informatique, on utilise le système binaire pour coder les caractères. Un bit (binary digit : chiffre binaire) est un élément qui prend la valeur 0 ou la valeur 1. Avec 8 chiffres binaires (un octet), combien de caractères peut-on coder?\n\n\n\n\n\nA l’occasion d’une compétition sportive groupant 18 athlètes, on attribue une médaille d’or, une d’argent, une de bronze. Combien y-a-t-il de distributions possibles (avant la compétition, bien sûr…) ?\n\n\n\n\n\nUn tournoi sportif compte 8 équipes engagées. Chaque équipe doit rencontrer toutes les autres une seule fois. Combien doit-on organiser de matchs ?\n\n\n\n\n\n\nExercice 2 On jette un dé 🎲 équilibré 3 fois de suite, et on s’intéresse au total des points obtenus. De combien de façons peut-on obtenir:\n\nun total égale à 16.\nun total égale à 15.\nun total au moins égale à 15.\n\n\n\nExercice 3 Dans une entreprise, on compte 12 célibataires parmi les 30 employés. On désire faire un sondage : pour cela on choisit un échantillon de quatre personnes dans ce service.\n\nQuel est le nombre d’échantillons différents possibles ?\nQuel est le nombre d’échantillons ne contenant aucun célibataire ?\nQuel est le nombre d’échantillons contenant au moins un célibataire ?\n\n\n\nExercice 4 On tire simultanément 5 cartes d’un jeu de 52 cartes.\n\nCombien de tirages différents peut-on obtenir?\n\nCombien de tirages peut-on obtenir ? contenant:\n\n5 carreaux ou 5 coeurs;\n2 coeurs et 3 piques;\nau moins 1 roi;\nau plus 1 roi."
  },
  {
    "objectID": "exos1.html#événements",
    "href": "exos1.html#événements",
    "title": "Feuille d’exercices 1",
    "section": "Événements",
    "text": "Événements\n\nExercice 5 Soit \\(A\\),\\(B\\) et \\(C\\) trois événements d’un espace probabilisable \\((\\Omega,\\mathcal{A})\\). Exprimer en fonction de \\(A\\),\\(B\\) et \\(C\\) et des opérations ensemblistes (réunion, intersection et complémentaire) les événements ci-après:\n\n\\(A\\) seul (parmi les 3 événements) se produit.\n\\(A\\) et \\(C\\) se produisent, mais non \\(B\\).\nLes trois événements se produisent.\nL’un au moins des 3 événements se produit.\nAucun des trois événements ne se produit."
  },
  {
    "objectID": "exos1.html#probabilité",
    "href": "exos1.html#probabilité",
    "title": "Feuille d’exercices 1",
    "section": "Probabilité",
    "text": "Probabilité\n\nExercice 6 Soit les événements \\(A\\) et \\(B\\) t.q. \\(P(A) = x, P(B) = y\\) et \\(P(A \\cup B) = z\\). Trouver les probabilités suivantes: \\(P(A \\cap B), P(\\bar{A} \\cup \\bar{B})\\), et \\(P(A \\cap \\bar{B})\\).\n\n\nExercice 7 Soit \\((\\Omega,\\mathcal{A},P)\\) un espace probabilisé. Soient \\(A\\),\\(B\\) et \\(C\\) trois événements quelconques. On pose : \\(E = A \\cap \\bar{B} \\cap \\bar{C}\\) et \\(F = A \\cap (B \\cup C)\\).\n\nMontrer que \\(E\\) et \\(F\\) sont incompatibles.\nMontrer que \\(E \\cup F = A\\).\nSachant que \\(P(A)=0.6; \\, P(A\\cap B)=0.2; \\, P(A\\cap C)=0.1\\) et \\(P(A\\cap B \\cap C)=0.05\\): Calculer \\(P(F)\\) et \\(P(E)\\).\n\n\n\n\nExercice 8 \n\nUne urne contient 13 boules dont 6 noires, 3 blanches et 4 rouges. On pioche 4 boules. On pose\n\nE: « obtenir exactement 2 blanches »\nF: « obtenir exactement 2 rouges »\n\n\nOn suppose qu’ il n’ y a pas remise. Calculer les probabilités suivantes : \\(P(E \\cap F), P_F (E), P_E(F)\\). Les évènements E et F sont-ils indépendants?\nRecommencer l’ exercice en supposant que l’on pioche avec remise.\n\n\n\nExercice 9 Une urne contient dix boules (6 blanches et 4 rouges). On tire au hasard et successivement deux boules de cette urne. Calculer, dans le cas où le tirage est effectué sans remise, puis dans le cas où le tirage est effectué avec remise, les probabilités suivantes:\n\nprobabilité pour que les deux boules soient blanches.\nprobabilité pour que les deux boules soient de même couleur.\nprobabilité pour que l’une au moins des boules tirées soit blanche."
  },
  {
    "objectID": "exos1.html#bayes",
    "href": "exos1.html#bayes",
    "title": "Feuille d’exercices 1",
    "section": "Bayes",
    "text": "Bayes\n\n\nExercice 10 \n\nUn nouveau vaccin a été testé sur 12500 personnes. 75 d’entre elles, dont 35 femmes enceintes, ont eu des réactions secondaires nécessitant une hospitalisation.\n\nSachant que ce vaccin a été administré à 680 femmes enceintes, quelle est la probabilité qu’une femme enceinte ait eu ne réaction secondaire si elle reçoit le vaccin?\nQuelle est la probabilité qu’une personne non enceinte ait une réaction secondaire ?\nUne personne a présonté des réactions secondaire, quelle est la probabilité qu’il s’agit d’une femme enceinte?\n\n\n\n\nExercice 11 \n\nPour se rendre au lycée, un élève a le choix entre 4 itinéraires: A, B, C et D. La probabilité qu’il a de choisir A (respectivement B, C) est \\(\\frac{1}{3}\\) (respectivement \\(\\frac{1}{4}\\), \\(\\frac{1}{12}\\)). La probabilité d’arriver en retard en empruntant A (respectivement B, C) est \\(\\frac{1}{20}\\) (respectivement \\(\\frac{1}{10}\\), \\(\\frac{1}{5}\\)). En empruntant D, il n’est jamais en retard.\n\nQuelle est la probabilité que l’élève choisisse l’itinéraire D?\nL’élève arrive en retard. Quelle est la probabilité qu’il ait emprunté l’itinéraire C?"
  },
  {
    "objectID": "exos1.html#variables-aléatoires-discrètes",
    "href": "exos1.html#variables-aléatoires-discrètes",
    "title": "Feuille d’exercices 1",
    "section": "Variables aléatoires discrètes",
    "text": "Variables aléatoires discrètes\n\nExercice 12 Soit \\(X\\) une variable aléatoire qui prend ses valeurs dans l’ensemble \\(\\{- 4, 2, 3, 4, 6, 7, 10\\}\\) et dont la distribution est donnée par:\n\n\n\\(x_i\\)\n-4\n2\n3\n4\n6\n7\n10\n\n\n\\(P(X=x_i)\\)\n0.1\n0.2\n0.2\n0.1\n0.05\n0.2\n\\(k\\)\n\n\n\nCalculer \\(k\\).\nReprésenter graphiquement la loi de \\(X\\).\nCalculer les probabilités suivantes:\n\n\n\\(P(X >3)\\)\n\\(P(X \\geq 3)\\)\n\\(P(3 \\leq X \\leq 7)\\)\n\\(P(3 < X < 9)\\)\n\\(P(X+2 > 3)\\)\n\\(P(X^2 > 4)\\)\n\n\n\nExercice 13 On choisit deux boules au hasard dans une urne contenant 8 boules blanches, 4 boules noires et 2 boules oranges. Supposons que l’on reçoive 2 euros pour chaque boule noire tirée et que l’on perde 1 euro pour chaque boule blanche tirée. Désignons les gains nets par \\(X\\).\n\nQuelles sont les valeurs possibles pour X et les probabilités associées à ces valeurs ?\nQuelle est l’espérance de X ?\n\n\n\nExercice 14 Une urne contient une boule qui porte le numéro 0, deux qui portent le numéro 1 et quatre qui portent le numéro 3. On extrait simultanément deux boules dans cette urne.\n\nDéterminer la loi de probabilité de la variable aléatoire \\(X\\) qui représente la somme des nombres obtenus.\nDéterminer la fonction de répartition de \\(X\\).\nCalculer \\(E(X)\\), \\(V(X)\\) et \\(\\sigma(X)\\).\n\n\n\nExercice 15 Soit \\(X\\) une v.a. qui suit la loi uniforme (e.g. équiprobabilité de valeurs de \\(X\\)) sur l’ensemble \\(X(\\Omega) = \\{-3, -2, 1, 4\\}\\).\n\nDonner la loi de \\(X\\).\n\nCalculer \\(E(X)\\) et \\(V(X)\\).\nOn définit la variable aléatoire \\(Y=(X+1)^2\\).\n\nDonner \\(Y(\\Omega)\\) et la loi de \\(Y\\).\nCalculer \\(E(Y)\\) de deux façons différents.\n\n\n\nExercice 16 Soit la fonction de répartition \\(F\\) de la variable aléatoire \\(X\\) définie par:\n\\[F(x) = \\left\\{\n\\begin{array}{l l}\n0 & \\quad \\text{si $x<0$}\\\\\n  1/4 & \\quad \\text{si $0 \\leq x < 1$}\\\\\n   1/2 & \\quad \\text{si $1 \\leq x < 4$}\\\\\n    c & \\quad \\text{si $x \\geq 4$}\\\\\n  \\end{array} \\right.\\]\n\nDéterminer en justifiant la constante \\(c\\).\nCalculer \\(P (1 \\leq X < 5)\\).\nCalculer \\(P(X=1)+P(X=2)\\).\nDéteminer la loi de probabilité de \\(X\\).\n\n\n\nExercice 17 Soient X et Y des variables aléatoires discrètes dont la loi jointe est donnée par le tableau suivant:\n\n\n\n\\(X\\)\\\\(Y\\)\n\n-1\n0\n2\n5\n\n\n\n0\n0.10\n0.05\n0.15\n0.05\n\n\n1\n0.15\n0.20\n0.25\n0.05\n\n\n\n\nQuelle est la loi marginale de X ?\nQuelle est la loi marginale de Y ?\nCalculer \\(P(Y \\geq 0 / X = 1)\\).\nCalculer \\(E(X)\\), \\(E(Y)\\), et \\(cov(X,Y)\\).\nLes variables \\(X\\) et \\(Y\\) sont elles indépendantes ?\n\n\n\nExercice 18 Soit \\((X,Y)\\) un couple de variables aléatoires à valeurs dans \\(\\mathbb{N}^2\\) tel que\n\\[\\forall (p,q) \\in \\mathbb{N}^2, \\quad P(X=p,Y=q) = \\lambda \\frac{p+q}{p! q! 2^{p+q}}\\]\n\nDéterminer \\(\\lambda\\).\nCalculer les lois marginales.\nLes variables \\(X\\) et \\(Y\\) sont elles indépendantes ?"
  },
  {
    "objectID": "exos1_en.html",
    "href": "exos1_en.html",
    "title": "Feuille d’exercices 1",
    "section": "",
    "text": "Exercice 1 Separated questions:\n\nIn computing, the binary system is used to code characters. A bit (binary digit) is an element that takes the value 0 or the value 1. With 8 binary digits (one byte), how many characters can we code?\n\n\n\n\n\nIn a sports competition grouping 18 athletes, one gold, one silver and one bronze medal are awarded. How many distributions are there possible (before the competition, of course…)?\n\n\n\n\n\nA sports tournament has 8 participating teams. Each team must meet all the others once. How many games must we organize?\n\n\n\n\n\n\nExercice 2 A die 🎲 is rolled 3 times in a row, and we are interested in the total of the points obtained. In how many ways can we get:\n\na total of 16.\na total of 15.\nat least 15.\n\n\n\nExercice 3 In a company, there are 12 singles among the 30 employees. We wish to make a survey: for that we choose a sample of four people in this department.\n\nHow many different samples can we obtain?\nWhat is the number of samples containing no single person?\nWhat is the number of samples containing at least one single?\n\n\n\nExercice 4 Five cards are drawn simultaneously from a deck of 52 cards.\n\nHow many different draws can we get?\n\nHow many different draws can we get? containing:\n\n5 diamonds or 5 hearts;\n2 hearts and 3 spades;\nat least 1 king\nat most 1 king."
  },
  {
    "objectID": "exos1_en.html#events",
    "href": "exos1_en.html#events",
    "title": "Feuille d’exercices 1",
    "section": "Events",
    "text": "Events\n\nExercice 5 Let \\(A\\),\\(B\\) and \\(C\\) be three events of a measurable space \\((\\Omega,\\mathcal{A})\\). Express in terms of \\(A\\),\\(B\\) and \\(C\\) and the operations (Union, intersection and complementary) the following events below:\n\n\\(A\\) alone (among the 3 events) occurs.\n\\(A\\) and \\(C\\) occur, but not \\(B\\).\nAll three events occur.\nAt least one of the 3 events occurs.\nNone of the three events occur."
  },
  {
    "objectID": "exos1_en.html#probability",
    "href": "exos1_en.html#probability",
    "title": "Feuille d’exercices 1",
    "section": "Probability",
    "text": "Probability\n\nExercice 6 Let the events \\(A\\) et \\(B\\) such that \\(P(A) = x, P(B) = y\\) and \\(P(A \\cup B) = z\\). Find the following probabilities: \\(P(A \\cap B), P(\\bar{A} \\cup \\bar{B})\\), and \\(P(A \\cap \\bar{B})\\).\n\n\nExercice 7 Let \\((\\Omega,\\mathcal{A},P)\\) a probability space. Let \\(A\\),\\(B\\) et \\(C\\) three events. Let: \\(E = A \\cap \\bar{B} \\cap \\bar{C}\\) and \\(F = A \\cap (B \\cup C)\\).\n\nShow that \\(E\\) and \\(F\\) are mutually exclusive.\nShow that \\(E \\cup F = A\\).\nKnowing that \\(P(A)=0.6; P(A\\cap B)=0.2; P(A\\cap C)=0.1\\) and \\(P(A\\cap B \\cap C)=0.05\\): Compute \\(P(F)\\) and \\(P(E)\\).\n\n\n\n\nExercice 8 \n\nAn urn contains 13 balls, 6 black, 3 white and 4 red. We draw 4 balls. Let\n\nE: ” get exactly 2 white “.\nF: ” get exactly 2 red “.\n\n\nWe suppose that we draw without replacement. Calculate the following probabilities: \\(P(E \\cap F), P_F (E), P_E(F)\\). Are the events E and F independent?\nRepeat the exercise, assuming that the draw is made with replacement.\n\n\n\nExercice 9 An urn contains ten balls (6 white and 4 red). Two balls are drawn at random and successively from this urn. Calculate, in the case where the draw is made without replacement, then in the case where the draw is made with replacement, the following probabilities:\n\nprobability that the two balls are white.\nprobability that the two balls are of the same color.\nprobability that at least one of the balls drawn is white."
  },
  {
    "objectID": "exos1_en.html#bayes",
    "href": "exos1_en.html#bayes",
    "title": "Feuille d’exercices 1",
    "section": "Bayes",
    "text": "Bayes\n\n\nExercice 10 \n\nA new vaccine was tested on 12,500 people. 75 of them, including 35 pregnant women, had adverse reactions requiring hospitalization.\n\nKnowing that this vaccine was administered to 680 pregnant women, what is the probability that a pregnant woman will have a secondary reaction if she receives the vaccine?\nWhat is the probability that a non-pregnant person would have a secondary reaction?\nA persone had adverse reactions. What is the probability that this person is a pregnant woman?\n\n\n\n\nExercice 11 \n\nTo go to high school, a student has the choice between 4 routes: A, B, C and D. The probability that he chooses A (respectively B, C) is \\(\\frac{1}{3}\\) (respectively \\(\\frac{1}{4}\\), \\(\\frac{1}{12}\\)). The probability to arrive late by taking A (respectively B, C) is \\(\\frac{1}{20}\\) (respectively \\(\\frac{1}{10}\\), \\(\\frac{1}{5}\\)). By borrowing D, he is never late.\n\nWhat is the probability that the student chooses route D?\nThe student arrives late. What is the probability that he took route C?"
  },
  {
    "objectID": "exos1_en.html#discrete-random-variables",
    "href": "exos1_en.html#discrete-random-variables",
    "title": "Feuille d’exercices 1",
    "section": "Discrete random variables",
    "text": "Discrete random variables\n\nExercice 12 Let \\(X\\) be a random variable which takes its values in the set \\(\\{- 4, 2, 3, 4, 6, 7, 10\\}\\) and whose distribution is given by:\n\n\n\\(x_i\\)\n-4\n2\n3\n4\n6\n7\n10\n\n\n\\(P(X=x_i)\\)\n0.1\n0.2\n0.2\n0.1\n0.05\n0.2\n\\(k\\)\n\n\n\nCalculate \\(k\\).\nPlot the law of \\(X\\).\nCalculate the following probabilities:\n\n\n\\(P(X >3)\\)\n\\(P(X \\geq 3)\\)\n\\(P(3 \\leq X \\leq 7)\\)\n\\(P(3 < X < 9)\\)\n\\(P(X+2 > 3)\\)\n\\(P(X^2 > 4)\\)\n\n\n\nExercice 13 Two balls are chosen randomly from an urn containing 8 white balls, 4 black balls and 2 orange balls. Assume we receive 2 euros for each black ball drawn and we lose 1 euro for each white ball drawn. Let’s refer to the net gains by \\(X\\).\n\nWhat are the possible values for \\(X\\) and the probabilities associated with these values ?\nWhat is the expected value of \\(X\\)?\n\n\n\nExercice 14 An urn contains a ball with number 0, two with number 1 and four with number 3. Two balls are simultaneously extracted from this urn.\n\nDetermine the probability law of the random variable \\(X\\) which represents the sum of the numbers obtained.\nDetermine the distribution function of \\(X\\).\nCalculate \\(E(X)\\), \\(V(X)\\) and \\(\\sigma(X)\\).\n\n\n\nExercice 15 et \\(X\\) be a random variable that follows the uniform distribution (e.g. equiprobability of values of \\(X\\)) on the set \\(X(\\Omega) = \\{-3, -2, 1, 4\\}\\).\n\nGive the law of \\(X\\).\n\nCalculate \\(E(X)\\) and \\(V(X)\\).\nWe define the random variable \\(Y=(X+1)^2\\).\n\nGive \\(Y(\\Omega)\\) and the law of \\(Y\\).\nCalculate \\(E(Y)\\) using two different methods.\n\n\n\nExercice 16 Let \\(F\\) be the distribution function of the random variable \\(X\\) defined by:\n\\[F(x) = \\left\\{\n\\begin{array}{l l}\n0 & \\quad \\text{si $x<0$}\\\\\n  1/4 & \\quad \\text{si $0 \\leq x < 1$}\\\\\n   1/2 & \\quad \\text{si $1 \\leq x < 4$}\\\\\n    c & \\quad \\text{si $x \\geq 4$}\\\\\n  \\end{array} \\right.\\]\n\nDetermine with justification the constant value \\(c\\).\nCalculate \\(P (1 \\leq X < 5)\\).\nCalculate \\(P(X=1)+P(X=2)\\).\nDetermine the probability distribution of \\(X\\).\n\n\n\nExercice 17 Let X and Y be discrete random variables whose joint distribution is given by the following table:\n\n\n\n\\(X\\)\\\\(Y\\)\n\n-1\n0\n2\n5\n\n\n\n0\n0.10\n0.05\n0.15\n0.05\n\n\n1\n0.15\n0.20\n0.25\n0.05\n\n\n\n\nWhat is the marginal distribution of X?\nWhat is the marginal distribution of Y?\nCalculate \\(P(Y \\geq 0 / X = 1)\\).\nCompute \\(E(X)\\), \\(E(Y)\\), and \\(cov(X,Y)\\).\nAre the variables \\(X\\) and \\(Y\\) independent?\n\n\n\nExercice 18 Let \\((X,Y)\\) be a pair of random variables with values in \\(\\mathbb{N}^2\\) such that\n\\[\\forall (p,q) \\in \\mathbb{N}^2, \\quad P(X=p,Y=q) = \\lambda \\frac{p+q}{p! q! 2^{p+q}}\\]\n\nDetermine \\(\\lambda\\).\nCalculate the marginal distributions.\nAre the variables \\(X\\) and \\(Y\\) independent?"
  },
  {
    "objectID": "variables-aleatoires-continues.html",
    "href": "variables-aleatoires-continues.html",
    "title": "\n3  Variables Aléatoires Continues\n",
    "section": "",
    "text": "Dans les chapitres précédents nous avons traité des variables aléatoires discrètes, c’est-à-dire de variables dont l’univers est fini ou infini dénombrable. Il existe cependant des variables dont l’univers est infini non dénombrable. On peut citer par exemple, l’heure d’arrivée d’un train à une gare donnée ou encore la durée de vie d’un transistor. Désignons par \\(X\\) une telle variable.\n\nDéfinition 3.1 \\(X\\) est une variable aléatoire continue s’il existe une fonction \\(f\\) non négative définie pour tout \\(x \\in \\mathbb{R}\\) et vérifiant pour tout ensemble \\(B\\) de nombres réels la propriété\n\\[\nP(X \\in B) = \\int_B f(x)dx\n\\tag{3.1}\\]\nLa fonction \\(f\\) est appelée densité de probabilité de la variable aléatoire \\(X\\).\n\nTous les problèmes de probabilité relatifs à \\(X\\) peuvent être traités grâce à \\(f\\). Par exemple pour \\(B=[a,b]\\), on obtient grâce à l’équation (3.1)\n\\[\nP(a\\le X \\le b) = \\int_a^bf(x)dx\n\\tag{3.2}\\]\nGraphiquement, \\(P(a\\le X \\le b)\\) est l’aire de la surface entre l’axe de \\(x\\), la courbe correspondante à \\(f(x)\\) et les droites \\(x=a\\) et \\(x=b\\). Voire Figure Figure 3.1) et Figure Figure 3.2).\n\n\n\n\nFigure 3.1: \\(P(a \\leq X \\leq B)=\\) surface grisée\n\n\n\n\n\n\n\n\nFigure 3.2: L’aire hachurée correspond à des probabilités. \\(f(x)\\) étant une fonction densité de probabilité\n\n\n\n\n\nDéfinition 3.2 Pour toute variable aléatoire continue \\(X\\) de densité \\(f\\):\n\n\\(f(x) \\ge 0 \\quad \\forall \\, x \\in \\mathbb{R}\\)\n\\(\\int_{-\\infty}^{+\\infty}f(x)dx = 1\\)\nSi l’on pose \\(a=b\\) dans (3.2), il résulte \\[P(X=a)=\\int_a^a f(x)dx = 0\\]\n\nCeci siginifie que la probabilité qu’une variable aléatoire continue prenne une valeur isolée fixe est toujours nulle. Aussi on peut écrire\n\\[P(X < a) = P( X \\le a)  = \\int_{-\\infty}^a f(x)dx\\]\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nSoit \\(X\\) la variable aléatoire réelle de densité de probabilité\n\\[f(x)= \\left\\lbrace\n      \\begin{array}{ll}\n      kx  & \\mbox{si} \\quad 0\\le x \\le 5\\\\\n      0 & \\mbox{sinon}\n      \\end{array}\n  \\right.\\]\n\nCalculer \\(k\\).\nCalculer: \\(P(1 \\le X \\le 3), P(2 \\le X \\le 4)\\) et \\(P(X < 3)\\).\n\n\n\n\n\n\n\n\n\nExercice\n\n\n\nSoit \\(X\\) une variable aléatoire réelle continue ayant pour densité de probabilité \\[f(x)= \\left\\lbrace\n      \\begin{array}{ll}\n      \\frac{1}{6} x + k  & \\mbox{si} \\quad 0\\le x \\le 3\\\\\n      0 & \\mbox{sinon}\n      \\end{array}\n  \\right.\\]\n\nCalculer \\(k\\).\nCalculer \\(P(1 \\le X \\le 2)\\)"
  },
  {
    "objectID": "variables-aleatoires-continues.html#fonction-de-répartition-dune-v.a.c",
    "href": "variables-aleatoires-continues.html#fonction-de-répartition-dune-v.a.c",
    "title": "\n3  Variables Aléatoires Continues\n",
    "section": "Fonction de répartition d’une v.a.c",
    "text": "Fonction de répartition d’une v.a.c\n\nDéfinition 3.3 Si comme pour les variables aléatoires discrètes, on définit la fonction de répartition de \\(X\\) par:\n\\[\\begin{aligned}\n    F_X \\colon  \\mathbb{R} &\\longrightarrow \\mathbb{R} \\\\\n                x &\\longmapsto F_X(a) = P(X \\le a)\\end{aligned}\\]\nalors la relation entre la fonction de répartition \\(F_X\\) et la fonction densité de probabilité \\(f(x)\\) est la suivante:\n\\[\\forall \\quad a \\in \\mathbb{R} \\quad F_X(a)= P(X \\le a) = \\int_{-\\infty}^a f(x)dx\\]\n\nLa fonction de répartition \\(F_X(a)\\) est la primitive de la fonction densité de probabilité \\(f(x)\\) (donc la densité d’une v.a.c est la dérivée de la fonction de répartition), et permet d’obtenir les probabilités associées à la variable aléatoire \\(X\\), en effet:\nPropriétés: Pour une variable aléatoire continue X:\n\n\\(F'_X(x) = \\frac{\\text{d}}{\\text{d} x} F_X(x) = f(x)\\).\nPour tous réels \\(a \\le b\\), \\[\\begin{aligned}\n      P(a < X < b)      & = P(a < X \\le b) \\\\\n                        & = P(a \\le X < b) \\\\\n                        & = P( a \\le X \\le b) \\\\\n                        & = F_X(b) - F_X(a) = \\int_a^bf(x)dx\n    \\end{aligned}\\]\n\nLa fonction de répartition correspond aux probabilités cumulées associées à la variable aléatoire continue sur l’intervalle d’étude (Figure Figure 3.3)).\n\n\n\n\nFigure 3.3: L’aire hachurée en vert sous la courbe de la fonction densité de probabilité correspond à la probabilité \\(P ( X < a ) = F_X ( a )\\) et vaut 0.5 car ceci correspond exactement à la moitié de l’aire totale sous la courbe\n\n\n\n\nPropriétés: Les propriétés associées à la fonction de répartition sont les suivantes:\n\n\\(F_X\\) est continue sur \\(\\mathbb{R}\\), dérivable en tout point où \\(f\\) est continue.\n\\(F_X\\) est croissante sur \\(\\mathbb{R}\\).\n\\(F_X\\) est à valeurs dans \\([0,1]\\).\n\\(\\lim\\limits_{x\\to - \\infty} F_X(x) = 0\\) et \\(\\lim\\limits_{x\\to +\\infty} F_X(x) = 1\\)."
  },
  {
    "objectID": "variables-aleatoires-continues.html#fonction-dune-variable-aléatoire-continue",
    "href": "variables-aleatoires-continues.html#fonction-dune-variable-aléatoire-continue",
    "title": "\n3  Variables Aléatoires Continues\n",
    "section": "Fonction d’une variable aléatoire continue",
    "text": "Fonction d’une variable aléatoire continue\nSoit \\(X\\) une variable aléatoire continue de densité \\(f_X\\) et de fonction de répartition \\(F_X\\). Soit \\(h\\) une fonction continue définie sur \\(X(\\Omega)\\), alors \\(Y=h(X)\\) est une variable aléatoire.\nPour déterminer la densité de \\(Y\\), notée \\(f_Y\\), on commence par calculer la fonction de répartition de \\(Y\\), notée \\(F_Y\\), ensuite nous dérivons pour déterminer \\(f_Y\\).\nCalcul de densités pour \\(h(X)=aX+b\\)\n\n\\(\\forall \\quad y \\in \\mathbb{R}\\),\n\\[F_Y(y) = P(Y\\leq y)=P(h(X) \\le y) = P(aX+b \\le y)\\] si \\(a>0\\), \\[F_Y(y) = P(aX+b \\le y) = P(X\\leq \\frac{y-b}{a})=F_X(\\frac{y-b}{a})\\] si \\(a<0\\), \\[F_Y(y) = P(aX+b \\le y) =P(X\\geq \\frac{y-b}{a})=1-F_X(\\frac{y-b}{a})\\]\nEn dérivant on obtient la densité de \\(Y\\) \\[f_Y(y)=\\frac{1}{|a|}f_X(\\frac{y-b}{a})\\]\nCalcul de densités pour \\(h(X)=X^2\\)\n\nSi \\(y<0\\), \\(F_Y(y) =P(Y\\leq y)=0\\).\nSi \\(y>0\\),\n\\[\n\\begin{align}\nF_Y(y)  &=P(Y\\leq y)=P(X^2 \\le y)\\\\\n        &=P(-\\sqrt{y}\\leq X \\leq \\sqrt{y}) \\\\\n        &=F_X(\\sqrt{y})-F_X(-\\sqrt{y})\n\\end{align}\\]\nEn dérivant on obtient la densité de \\(Y\\),\n\\[f_Y(y)= \\left\\lbrace\n      \\begin{array}{ll}\n      \\displaystyle \\frac{1}{2\\sqrt{y}}\\big[f_X(\\sqrt{y})+f_X(-\\sqrt{y})\\big]  & \\mbox{si} \\quad y \\ge 0\\\\\n      0 & \\mbox{sinon}\n      \\end{array}\n  \\right.\\]\nCalcul de densités pour \\(h(X)=e^X\\)\n\nSi \\(y<0\\), \\(F_Y(y) = P(Y\\leq y)=0\\).\nSi \\(y>0\\), \\(F_Y(y) = P(Y\\leq y)=P(e^X \\le y)=P( X \\leq \\ln (y))=F_X(\\ln(y))\\).\nEn dérivant on obtient la densité de \\(Y\\)\n\\[f_Y(y)= \\left\\lbrace\n      \\begin{array}{ll}\n      \\displaystyle \\frac{1}{y} f\\big(\\ln (y)\\big)  & \\mbox{si} \\quad y \\ge 0\\\\\n      0 & \\mbox{sinon}\n      \\end{array}\n  \\right.\\]\n\n\n\n\n\n\nExercice\n\n\n\nSoit la v.a.c \\(X\\) ayant la fonction de densité\n\\[f_X(x)= \\left\\lbrace\n      \\begin{array}{ll}\n      2 x   & \\mbox{si} \\quad 0 \\le x \\le 1\\\\\n      0 & \\mbox{sinon}\n      \\end{array}\n  \\right.\\]\nDéterminer la densité de: \\(Y=3X+1\\), \\(Z=X^2\\) et \\(T=e^X\\)."
  },
  {
    "objectID": "variables-aleatoires-continues.html#espérance-et-variance-de-variables-aléatoires-continues",
    "href": "variables-aleatoires-continues.html#espérance-et-variance-de-variables-aléatoires-continues",
    "title": "\n3  Variables Aléatoires Continues\n",
    "section": "Espérance et variance de variables aléatoires continues",
    "text": "Espérance et variance de variables aléatoires continues\nEspérance d’une v.a.c\n\nDéfinition 3.4 Si \\(X\\) est une variable aléatoire absolument continue de densité \\(f\\), on appelle espérance de X, le réel \\(E(X)\\), défini par:\n\\[E(X)= \\int_{-\\infty}^{+\\infty}x f(x) dx\\] si cette intégrale est convergente.\n\nLes propriétés de l’espérance d’une variable aléatoire continue sont les mêmes que pour une variable aléatoire discrète.\nPropriétés: Soit \\(X\\) une variable aléatoire continue,\n\n\\(E(aX+b)=aE(X)+b \\quad \\quad a \\ge 0 \\,\\, \\text{et} \\,\\, b \\in \\mathbb{R}\\).\nSi \\(X \\ge 0\\) alors \\(E(X) \\ge 0\\).\nSi \\(X\\) et \\(Y\\) sont deux variables aléatoires définies sur un même univers \\(\\Omega\\) alors \\[E(X+Y)=E(X)+E(Y)\\]\n\n\nThéorème 3.1 (Théorème du transfert) Si \\(X\\) est une variable aléatoire de densité \\(f(x)\\), alors pour toute fonction réelle \\(g\\) on aura\n\\[E[g(X)] = \\int_{-\\infty}^{+\\infty}g(x) f(x) dx\\]\n\n\n\n\n\n\n\nExercice\n\n\n\nSoit la v.a.c \\(X\\) ayant la fonction de densité\n\\[f_X(x)= \\left\\lbrace\n      \\begin{array}{ll}\n      2 x   & \\mbox{si} \\quad 0 \\le x \\le 1\\\\\n      0 & \\mbox{sinon}\n      \\end{array}\n  \\right.\\]\nCalculer l’espérance des variables aléatoires \\(Y=3X+1\\), \\(Z=X^2\\) et \\(T=e^X\\).\n\n\nVariance d’une v.a.c\nLa variance d’une variable aléatoire \\(V(X)\\) est l’espérance mathématique du carré de l’écart à l’espérance mathématique. C’est un paramètre de dispersion qui correspond au moment centré d’ordre 2 de la variable aléatoire \\(X\\).\n\nDéfinition 3.5 Si \\(X\\) est une variable aléatoire ayant une espérance \\(E(X)\\), on appelle variance de \\(X\\) le réel\n\\[V(X)=E\\big([X-E(X)]^2\\big) = E(X^2) - [E(X)]^2\\] Si \\(X\\) est une variable aléatoire continue, on calcule \\(E(X^2)\\) en utilisant le théorème @ref(thm:transfert),\n\\[E(X^2) = \\int_{-\\infty}^{+\\infty}x^2 f(x)dx\\]\n\nPropriétés: Si \\(X\\) est une variable aléatoire admettant une variance alors:\n\n\\(V(X) \\ge 0\\), si elle existe.\n\\(\\forall \\quad a \\in \\mathbb{R}, V(aX) = a^2 V(X)\\)\n\\(\\forall \\quad (a,b) \\in \\mathbb{R}, V(aX+b) = a^2 V(X)\\)\nSi \\(X\\) et \\(Y\\) sont deux variables aléatoires indépendantes, \\(V(X+Y)=V(X)+V(Y)\\)\n\n\nDéfinition 3.6 (Ecart-type) Si \\(X\\) est une variable aléatoire ayant une variance \\(V(X)\\), on appelle écart-type de \\(X\\), le réel:\n\\[\\sigma_X = \\sqrt{V(X)}\\]"
  },
  {
    "objectID": "lois-usuelles-continues.html",
    "href": "lois-usuelles-continues.html",
    "title": "\n4  Lois usuelles continues\n",
    "section": "",
    "text": "La loi uniforme est la loi exacte de phénomènes continus uniformément répartis sur un intervalle.\n\nDéfinition 4.1 La variable aléatoire \\(X\\) suit une loi uniforme sur le segment \\([a,b]\\) avec \\(a < b\\) si sa densité de probabilité est donnée par \\[f(x)= \\left\\lbrace\n      \\begin{array}{ll}\n      \\frac{1}{b-a}   & \\mbox{si} \\quad x \\in [a,b]\\\\\n      0 & \\mbox{si} \\quad x \\notin [a,b]\n      \\end{array}\n  \\right. = \\frac{1}{b-a} {1}_{[a,b]}(x)\\]\n\n\n\n\n\nFigure 4.1: Fonction de densité de \\(U([a,b]\\))\n\n\n\n\nQuelques commentaires:\n\nLa loi uniforme continue étant une loi de probabilité, l’aire hachurée en bleu sur la Figure Figure 4.1) vaut \\(1\\).\nLa fonction de répartition associée à la loi uniforme continue est \\[F_X(x)= \\left\\lbrace\n       \\begin{array}{ll}\n       0 & \\mbox{si} \\quad x < a \\\\\n       \\displaystyle \\frac{x-a}{b-a}   & \\mbox{si} \\quad  a \\le x \\le b \\\\\n       1 & \\mbox{si} \\quad x > b\n       \\end{array}\n   \\right.\\]\n\nPropriétés: Si \\(X\\) est une v.a.c qui suit la loi uniforme sur \\([a,b]\\):\n\n\\(E(X) = \\displaystyle \\frac{b+a}{2}\\)\n\\(V(X) = \\displaystyle \\frac{(b-a)^2}{12}\\)\n\n\n\n\n\n\n\nExercice\n\n\n\nSoit \\(X \\thicksim U(0,10)\\). Calculer:\n\n\\(P(X <3)\\)\n\\(P(X\\ge 6)\\)\n\\(P(3 < X < 8)\\)"
  },
  {
    "objectID": "lois-usuelles-continues.html#loi-exponentielle-mathcalelambda",
    "href": "lois-usuelles-continues.html#loi-exponentielle-mathcalelambda",
    "title": "\n4  Lois usuelles continues\n",
    "section": "Loi exponentielle \\(\\mathcal{E}(\\lambda)\\)\n",
    "text": "Loi exponentielle \\(\\mathcal{E}(\\lambda)\\)\n\n\nDéfinition 4.2 On dit qu’une variable aléatoire \\(X\\) est exponentielle (ou suit la loi exponentielle) de paramètre \\(\\lambda\\) si sa densité est donnée par\n\\[f(x)= \\left\\lbrace\n      \\begin{array}{ll}\n      \\lambda e^{- \\lambda x}   & \\mbox{si} \\quad x \\ge 0\\\\\n      0 & \\mbox{si} \\quad x < 0\n      \\end{array}\n  \\right. = \\lambda e^{- \\lambda x} {1}_{\\mathbb{R}^{+}}(x)\\]\nOn dit \\(X \\thicksim \\mathcal{E}(\\lambda)\\)\n\nLa fonction de répartition \\(F\\) d’une variable aléatoire exponentielle est donnée par\n\\[\\begin{align}\n\\mbox{Si}\\,\\, x \\ge 0 \\quad F(x) &= P(X \\le x) = \\int_0^x f(t)dt \\\\\n     &= \\int_0^x \\lambda e^{- \\lambda t} dt  \\\\\n     &= \\big[ -e^{- \\lambda t} \\big]_0^x = 1-e^{- \\lambda x}\n\\end{align}\\]\nPropriétés: Si \\(X \\thicksim \\mathcal{E}(\\lambda)\\)\n\n\\(E(X) = \\displaystyle \\frac{1}{\\lambda}\\)\n\\(V(X)= \\displaystyle \\frac{1}{\\lambda^2}\\)\n\n\n\n\n\n\n\nNote\n\n\n\nCas d’utilisations de la loi exponentielle : Dans la pratique, on rencontre souvent la distribution exponentielle lorsqu’il s’agit de représenter le temps d’attente avant l’arrivée d’un événement spécifié. Une loi exponentielle modélise la durée de vie d’un phénomène sans mémoire, ou sans vieillissement, ou sans usure. En d’autres termes, le fait que le phénomène ait duré pendant un temps \\(t\\) ne change rien à son espérance de vie à partir du temps \\(t\\). On dit qu’une variable aléatoire non négative \\(X\\) est sans mémoire lorsque\n\\[P(X > t+h | X > t) = P(X > h) \\quad \\quad \\forall \\quad t,h \\ge 0\\]\nPar exemple, la durée de vie de la radioactivité ou d’un composant électronique, le temps qui nous sépare d’un prochain tremblement de terre ou du prochain appel téléphonique mal aiguillé sont toutes des variables aléatoires dont les distributions tendent en pratique à se rapprocher de distributions exponentielles."
  },
  {
    "objectID": "lois-usuelles-continues.html#loi-normale-ou-de-laplace-gauss-mathcalnmusigma2",
    "href": "lois-usuelles-continues.html#loi-normale-ou-de-laplace-gauss-mathcalnmusigma2",
    "title": "\n4  Lois usuelles continues\n",
    "section": "Loi Normale ou de Laplace-Gauss \\(\\mathcal{N}(\\mu,\\sigma^2)\\)\n",
    "text": "Loi Normale ou de Laplace-Gauss \\(\\mathcal{N}(\\mu,\\sigma^2)\\)\n\n\nDéfinition 4.3 Une variable aléatoire \\(X\\) est dite normale avec paramètres \\(\\mu\\) et \\(\\sigma^2\\) si la densité de \\(X\\) est donnée par\n\\[f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{ \\displaystyle -(x - \\mu)^2/2\\sigma^2} \\quad \\quad \\forall \\,\\, x \\in \\mathbb{R}\\]\nAvec \\(\\mu \\in \\mathbb{R}\\) et \\(\\sigma \\in \\mathbb{R}^{+}\\). On dit que \\(X \\thicksim \\mathcal{N}(\\mu,\\sigma^2)\\).\n\nRemarque: On admet que \\(\\int_{-\\infty}^{+\\infty}f(x)dx = 1\\) dans la mesure où l’intégration analytique est impossible.\nÉtude de la densité de la loi Normale\n\nLa fonction \\(f\\) est paire autour d’un axe de symétrie \\(x = \\mu\\) car \\(f(x + \\mu ) = f(\\mu - x)\\).\n\\(f'(x)=0\\) pour \\(x=\\mu\\), \\(f'(x) < 0\\) pour \\(x < \\mu\\) et \\(f'(x) > 0\\) pour \\(x > \\mu\\)\n\n\n\n\n\nFigure 4.2: Représentation graphique de la densité d’une loi normale. Remarque: Le paramètre \\(\\mu\\) représente l’axe de symétrie et σ le degré d’aplatissement de la courbe de la loi normale dont la forme est celle d’une courbe en cloche\n\n\n\n\nPropriétés: Soit \\(X \\thicksim \\mathcal{N}(\\mu,\\sigma^2)\\), on a:\n\n\\(E(X)=\\mu\\)\n\\(V(X)=\\sigma^2\\)\n\n\nThéorème 4.1 (Stabilité de la loi normale) Soit \\(X_1\\) et \\(X_2\\) deux variables aléatoires normales et indépendantes de paramètres respectifs \\((\\mu_1,\\sigma_1^2)\\) et \\((\\mu_2,\\sigma_2^2)\\), alors leur somme \\(X_1+X_2\\) est une variable aléatoire normale de paramètres \\((\\mu_1 + \\mu_2,\\sigma_1^2+\\sigma_2^2)\\)."
  },
  {
    "objectID": "lois-usuelles-continues.html#loi-normale-centrée-réduite-mathcaln01",
    "href": "lois-usuelles-continues.html#loi-normale-centrée-réduite-mathcaln01",
    "title": "\n4  Lois usuelles continues\n",
    "section": "Loi Normale centrée réduite \\(\\mathcal{N}(0,1)\\)\n",
    "text": "Loi Normale centrée réduite \\(\\mathcal{N}(0,1)\\)\n\n\nDéfinition 4.4 Une variable aléatoire continue \\(X\\) suit une loi normale centrée réduite si sa densité de probabilité est donnée par\n\\[\nf(x) =  \\frac{1}{{\\sqrt {2\\pi } }}e^{\\displaystyle - \\frac{1}{2} x^2} \\quad \\quad \\forall \\,\\, x \\in \\mathbb{R}\n\\]\nOn dit \\(X \\thicksim \\mathcal{N}(0,1)\\).\n\nRemarque: \\(E(X)=0\\) et \\(V(X)=1\\).\n\n\n\n\nFigure 4.3: Densité d’une loi normale centrée réduite \\(\\mathcal{N}(0,1)\\)\n\n\n\n\n\n\n\n\nFigure 4.4: Fonction de répartition de \\(\\mathcal{N}(0,1)\\)"
  },
  {
    "objectID": "lois-usuelles-continues.html#relation-entre-loi-normale-et-loi-normale-centrée-réduite",
    "href": "lois-usuelles-continues.html#relation-entre-loi-normale-et-loi-normale-centrée-réduite",
    "title": "\n4  Lois usuelles continues\n",
    "section": "Relation entre loi normale et loi normale centrée réduite",
    "text": "Relation entre loi normale et loi normale centrée réduite\n\nThéorème 4.2 (Relation avec la loi normale) Si \\(X\\) suit une loi normale \\(\\mathcal{N}(\\mu,\\sigma^2)\\), alors \\(\\displaystyle Z= \\frac{X-\\mu}{\\sigma}\\) est une variable centrée réduite qui suit la loi normale centrée réduite \\(\\mathcal{N}(0,1)\\)."
  },
  {
    "objectID": "lois-usuelles-continues.html#calcul-des-probabilités-dune-loi-normale",
    "href": "lois-usuelles-continues.html#calcul-des-probabilités-dune-loi-normale",
    "title": "\n4  Lois usuelles continues\n",
    "section": "Calcul des probabilités d’une loi normale",
    "text": "Calcul des probabilités d’une loi normale\nLa fonction de répartition de la loi normale réduite permet d’obtenir les probabilités associées à toutes variables aléatoires normales \\(\\mathcal{N}(\\mu,\\sigma^2)\\) après transformation en variable centrée réduite.\n\nDéfinition 4.5 On appelle fonction \\(\\Phi\\), la fonction de répartition de la loi normale centrée réduite \\(\\mathcal{N}(0,1)\\), telle que\n\\[\\forall \\,\\, x \\in \\mathbb{R} \\quad \\Phi(x) = P(X \\le x) =  \\frac{1}{{\\sqrt {2\\pi}}} \\int_{-\\infty}^x f(t)dt\\]\n\nPropriétés: Les propriétés associées à la fonction de répartition \\(\\Phi\\) sont:\n\n\n\\(\\Phi\\) est croissante, continue et dérivable sur \\(\\mathbb{R}\\) et vérifie:\n\\(\\lim\\limits_{x\\to - \\infty} \\Phi(x) = 0\\) et \\(\\lim\\limits_{x\\to\\infty} \\Phi(x) = 1\\)\n\n\\(\\forall \\,\\, x \\in \\mathbb{R} \\quad \\Phi(x) + \\Phi(-x) = 1\\)\n\\(\\forall \\,\\, x \\in \\mathbb{R} \\quad \\Phi(x) - \\Phi(-x) = 2\\Phi(x) -1\\)\n\nUne application directe de la fonction \\(\\Phi\\) est la lecture des probabilités de la loi normale sur la table de la loi normale centrée réduite.\n\n\n\n\n\n\nExercice\n\n\n\nSoit \\(X\\) une variable aléatoire normale de paramètres \\(\\mu =3\\) et \\(\\sigma^2=4\\). Calculer:\n\n\\(P(X > 0)\\)\n\\(P(2 < X < 5)\\)\n\\(P(|X-3| > 4)\\)"
  },
  {
    "objectID": "lois-usuelles-continues.html#approximation-normale-dune-répartition-binomiale",
    "href": "lois-usuelles-continues.html#approximation-normale-dune-répartition-binomiale",
    "title": "\n4  Lois usuelles continues\n",
    "section": "Approximation normale d’une répartition binomiale",
    "text": "Approximation normale d’une répartition binomiale\nUn résultat important de la théorie de probabilité est connu sous le nom de théorème limite de Moivre-Laplace. Il dit que pour \\(n\\) grand, une variable binomiale \\(\\mathcal{B}(n,p)\\) suivra approximativement la même loi qu’une variable aléatoire normale avec même moyenne et même variance. Ce théorème énonce que si “on standardise” une variable aléatoire binomiale \\(\\mathcal{B}(n,p)\\) en soustrayant d’abord sa moyenne \\(np\\) puis en divisant le résultat par son écart-type \\(\\sqrt{np(1-p)}\\), alors la variable aléatoire standardisée (de moyenne 0 et variance 1) suivra approximativement, lorsque \\(n\\) est grand, une distribution normale standard. Ce résultat fut ensuite progressivement généralisé par Laplace, Gauss et d’autres pour devenir le théorème actuellement connu comme théorème centrale limite qui est un des deux résultats les plus importants de la théorie de probabilités. Ce théorème sert de base théorique pour expliquer un fait empirique souvent relevé, à savoir qu’en pratique de très nombreux phénomènes aléatoires suivent approximativement une distribution normale.\nOn remarquera qu’à ce stade deux approximations de la répartition binomiale ont été proposées: l’approximation de Poisson, satisfaisante lorsque \\(n\\) est grand et lorsque \\(np\\) n’est pas extrême; l’approximation normale pour laquelle on peut montrer qu’elle est de bonne qualité lorsque \\(np(1-p)\\) est grand (dès que \\(np(1-p)\\) dépasse 10).\n\n\n\n\nFigure 4.5: La loi de probabilité d’une variable aléatoire \\(B( n,p )\\) devient de plus en plus normale à mesure que \\(n\\) augmente."
  },
  {
    "objectID": "lois-usuelles-continues.html#loi-de-chi2-de-pearson",
    "href": "lois-usuelles-continues.html#loi-de-chi2-de-pearson",
    "title": "\n4  Lois usuelles continues\n",
    "section": "Loi de \\(\\chi^{2}\\) de Pearson",
    "text": "Loi de \\(\\chi^{2}\\) de Pearson\n\nDéfinition 4.6 Soit \\(X_1,X_2,\\ldots,X_n\\), \\(n\\) variables normales centrées réduites, et \\(Y\\) la variable aléatoire définie par\n\\[Y = X_1^2 + X_2^2 + \\ldots + X_i^2 + \\ldots + X_n^2 = \\sum_{i=1}^n X_i^2\\] On dit que \\(Y\\) suit la loi de \\(\\chi^2\\) (ou loi de Pearson) à \\(n\\) degrés de liberté, \\(Y \\thicksim \\chi^2 (n)\\)\n\n\n\n\n\n\n\nNote\n\n\n\nLa loi de \\(\\chi^2\\) trouve de nombreuses applications dans le cadre de la comparaison de proportions, des tests de conformité d’une distribution observée à une distribution théorique et le test d’indépendance de deux caractères qualitatifs. Ce sont les tests du khi-deux.\n\n\nRemarque: Si \\(n=1\\), la variable du \\(\\chi^2\\) correspond au carré d’une variable normale centrée réduite \\(\\mathcal{N}(0,1)\\).\nPropriétés: Si \\(Y \\thicksim \\chi^2 (n)\\), alors:\n\n\\(E(Y)= n\\)\n\\(V(Y) = 2n\\)"
  },
  {
    "objectID": "lois-usuelles-continues.html#loi-de-student-stn",
    "href": "lois-usuelles-continues.html#loi-de-student-stn",
    "title": "\n4  Lois usuelles continues\n",
    "section": "Loi de Student \\(St(n)\\)\n",
    "text": "Loi de Student \\(St(n)\\)\n\n\nDéfinition 4.7 Soit \\(U\\) une variable aléatoire suivant une loi normale centrée réduite \\(\\mathcal{N}(0,1)\\) et \\(V\\) une variable aléatoire suivant une loi de \\(\\chi^2(n)\\), \\(U\\) et \\(V\\) étant indépendantes, on dit alors que \\(\\displaystyle T_n = \\frac{U}{\\sqrt{\\frac{V}{n}}}\\) suit une loi de Student à \\(n\\) degrés de liberté. \\(T_n \\thicksim St(n)\\)\n\n\n\n\n\n\n\nNote\n\n\n\nLa loi de Student est utilisée lors des tests de comparaison de paramètres comme la moyenne et dans l’estimation de paramètres de la population à partir de données sur un échantillon (Test de Student)."
  },
  {
    "objectID": "lois-usuelles-continues.html#loi-de-fisher-snedecor-mathcalfnm",
    "href": "lois-usuelles-continues.html#loi-de-fisher-snedecor-mathcalfnm",
    "title": "\n4  Lois usuelles continues\n",
    "section": "Loi de Fisher-Snedecor \\(\\mathcal{F}(n,m)\\)\n",
    "text": "Loi de Fisher-Snedecor \\(\\mathcal{F}(n,m)\\)\n\n\nDéfinition 4.8 Soit \\(U\\) et \\(V\\) deux variables aléatoires indépendantes suivant une loi de \\(\\chi^2\\) respectivement à \\(n\\) et \\(m\\) degrés de liberté.\nOn dit que \\(\\displaystyle F= \\frac{U/n}{V/m}\\) suit une loi de Fisher-Snedecor à \\((n,m)\\) degrés de liberté. \\(F \\thicksim \\mathcal{F}(n,m)\\)\n\n\n\n\n\n\n\nNote\n\n\n\nLa loi de Fisher-Snedecor est utilisée pour comparer deux variances observées et sert surtout dans les très nombreux tests d’analyse de variance et de covariance."
  },
  {
    "objectID": "appendix.html",
    "href": "appendix.html",
    "title": "Appendix A — Table de la loi Normale centrée réduite",
    "section": "",
    "text": "0 \n    0.01 \n    0.02 \n    0.03 \n    0.04 \n    0.05 \n    0.06 \n    0.07 \n    0.08 \n    0.09 \n  \n\n\n 0 \n    0.5000 \n    0.5040 \n    0.5080 \n    0.5120 \n    0.5160 \n    0.5199 \n    0.5239 \n    0.5279 \n    0.5319 \n    0.5359 \n  \n\n 0.1 \n    0.5398 \n    0.5438 \n    0.5478 \n    0.5517 \n    0.5557 \n    0.5596 \n    0.5636 \n    0.5675 \n    0.5714 \n    0.5753 \n  \n\n 0.2 \n    0.5793 \n    0.5832 \n    0.5871 \n    0.5910 \n    0.5948 \n    0.5987 \n    0.6026 \n    0.6064 \n    0.6103 \n    0.6141 \n  \n\n 0.3 \n    0.6179 \n    0.6217 \n    0.6255 \n    0.6293 \n    0.6331 \n    0.6368 \n    0.6406 \n    0.6443 \n    0.6480 \n    0.6517 \n  \n\n 0.4 \n    0.6554 \n    0.6591 \n    0.6628 \n    0.6664 \n    0.6700 \n    0.6736 \n    0.6772 \n    0.6808 \n    0.6844 \n    0.6879 \n  \n\n 0.5 \n    0.6915 \n    0.6950 \n    0.6985 \n    0.7019 \n    0.7054 \n    0.7088 \n    0.7123 \n    0.7157 \n    0.7190 \n    0.7224 \n  \n\n 0.6 \n    0.7257 \n    0.7291 \n    0.7324 \n    0.7357 \n    0.7389 \n    0.7422 \n    0.7454 \n    0.7486 \n    0.7517 \n    0.7549 \n  \n\n 0.7 \n    0.7580 \n    0.7611 \n    0.7642 \n    0.7673 \n    0.7704 \n    0.7734 \n    0.7764 \n    0.7794 \n    0.7823 \n    0.7852 \n  \n\n 0.8 \n    0.7881 \n    0.7910 \n    0.7939 \n    0.7967 \n    0.7995 \n    0.8023 \n    0.8051 \n    0.8078 \n    0.8106 \n    0.8133 \n  \n\n 0.9 \n    0.8159 \n    0.8186 \n    0.8212 \n    0.8238 \n    0.8264 \n    0.8289 \n    0.8315 \n    0.8340 \n    0.8365 \n    0.8389 \n  \n\n 1 \n    0.8413 \n    0.8438 \n    0.8461 \n    0.8485 \n    0.8508 \n    0.8531 \n    0.8554 \n    0.8577 \n    0.8599 \n    0.8621 \n  \n\n 1.1 \n    0.8643 \n    0.8665 \n    0.8686 \n    0.8708 \n    0.8729 \n    0.8749 \n    0.8770 \n    0.8790 \n    0.8810 \n    0.8830 \n  \n\n 1.2 \n    0.8849 \n    0.8869 \n    0.8888 \n    0.8907 \n    0.8925 \n    0.8944 \n    0.8962 \n    0.8980 \n    0.8997 \n    0.9015 \n  \n\n 1.3 \n    0.9032 \n    0.9049 \n    0.9066 \n    0.9082 \n    0.9099 \n    0.9115 \n    0.9131 \n    0.9147 \n    0.9162 \n    0.9177 \n  \n\n 1.4 \n    0.9192 \n    0.9207 \n    0.9222 \n    0.9236 \n    0.9251 \n    0.9265 \n    0.9279 \n    0.9292 \n    0.9306 \n    0.9319 \n  \n\n 1.5 \n    0.9332 \n    0.9345 \n    0.9357 \n    0.9370 \n    0.9382 \n    0.9394 \n    0.9406 \n    0.9418 \n    0.9429 \n    0.9441 \n  \n\n 1.6 \n    0.9452 \n    0.9463 \n    0.9474 \n    0.9484 \n    0.9495 \n    0.9505 \n    0.9515 \n    0.9525 \n    0.9535 \n    0.9545 \n  \n\n 1.7 \n    0.9554 \n    0.9564 \n    0.9573 \n    0.9582 \n    0.9591 \n    0.9599 \n    0.9608 \n    0.9616 \n    0.9625 \n    0.9633 \n  \n\n 1.8 \n    0.9641 \n    0.9649 \n    0.9656 \n    0.9664 \n    0.9671 \n    0.9678 \n    0.9686 \n    0.9693 \n    0.9699 \n    0.9706 \n  \n\n 1.9 \n    0.9713 \n    0.9719 \n    0.9726 \n    0.9732 \n    0.9738 \n    0.9744 \n    0.9750 \n    0.9756 \n    0.9761 \n    0.9767 \n  \n\n 2 \n    0.9772 \n    0.9778 \n    0.9783 \n    0.9788 \n    0.9793 \n    0.9798 \n    0.9803 \n    0.9808 \n    0.9812 \n    0.9817 \n  \n\n 2.1 \n    0.9821 \n    0.9826 \n    0.9830 \n    0.9834 \n    0.9838 \n    0.9842 \n    0.9846 \n    0.9850 \n    0.9854 \n    0.9857 \n  \n\n 2.2 \n    0.9861 \n    0.9864 \n    0.9868 \n    0.9871 \n    0.9875 \n    0.9878 \n    0.9881 \n    0.9884 \n    0.9887 \n    0.9890 \n  \n\n 2.3 \n    0.9893 \n    0.9896 \n    0.9898 \n    0.9901 \n    0.9904 \n    0.9906 \n    0.9909 \n    0.9911 \n    0.9913 \n    0.9916 \n  \n\n 2.4 \n    0.9918 \n    0.9920 \n    0.9922 \n    0.9925 \n    0.9927 \n    0.9929 \n    0.9931 \n    0.9932 \n    0.9934 \n    0.9936 \n  \n\n 2.5 \n    0.9938 \n    0.9940 \n    0.9941 \n    0.9943 \n    0.9945 \n    0.9946 \n    0.9948 \n    0.9949 \n    0.9951 \n    0.9952 \n  \n\n 2.6 \n    0.9953 \n    0.9955 \n    0.9956 \n    0.9957 \n    0.9959 \n    0.9960 \n    0.9961 \n    0.9962 \n    0.9963 \n    0.9964 \n  \n\n 2.7 \n    0.9965 \n    0.9966 \n    0.9967 \n    0.9968 \n    0.9969 \n    0.9970 \n    0.9971 \n    0.9972 \n    0.9973 \n    0.9974 \n  \n\n 2.8 \n    0.9974 \n    0.9975 \n    0.9976 \n    0.9977 \n    0.9977 \n    0.9978 \n    0.9979 \n    0.9979 \n    0.9980 \n    0.9981 \n  \n\n 2.9 \n    0.9981 \n    0.9982 \n    0.9982 \n    0.9983 \n    0.9984 \n    0.9984 \n    0.9985 \n    0.9985 \n    0.9986 \n    0.9986 \n  \n\n 3 \n    0.9987 \n    0.9987 \n    0.9987 \n    0.9988 \n    0.9988 \n    0.9989 \n    0.9989 \n    0.9989 \n    0.9990 \n    0.9990 \n  \n\n\n\n\n\nPar exemple, pour \\(x = 1.23\\) (intersection de la ligne 1.2 et de la colonne 0.03), on obtient : \\(\\Phi(1.23) \\approx 0.8907\\)."
  },
  {
    "objectID": "index.html#plan",
    "href": "index.html#plan",
    "title": "Probabilités",
    "section": "Plan",
    "text": "Plan\n\n\n\nChapitre\nTitre\nDocument\nSlides [Fr]\nSlides [En]\nAnnotated Slides\nExercices [Fr]\nExercices [En]\n\n\n\n\n1\nVariables aléatoires discrètes\n📖\n📋\n📋\n📋✍️\n\n\n\n\n2\nLois ususelles discrètes\n📖\n📋\n📋\n\n\n\n\n\n\nFeuille d’exercices 1\n\n\n\n\n✍️\n✍️\n\n\n3\nVariables aléatoires continues\n📖\n📋\n📋\n\n\n\n\n\n4\nLois usuelles continues\n📖\n📋\n📋\n\n\n\n\n\n\nFeuille d’exercices 2\n\n\n\n\n✍️\n✍️"
  },
  {
    "objectID": "lois-usuelles-discretes.html#loi-uniforme-discrète-mathcalun",
    "href": "lois-usuelles-discretes.html#loi-uniforme-discrète-mathcalun",
    "title": "2  Lois usuelles discrètes",
    "section": "Loi uniforme discrète \\(\\mathcal{U}(n)\\)",
    "text": "Loi uniforme discrète \\(\\mathcal{U}(n)\\)\n\nDéfinition 2.1 Une distribution de probabilité suit une loi uniforme lorsque toutes les valeurs prises par la variable aléatoire sont équiprobables. Si \\(n\\) est le nombre de valeurs différentes prises par la variable aléatoire alors on a:\n\\[\nP(X=x_i)=\\frac{1}{n} \\qquad \\forall \\, i \\in \\{1,\\ldots, n\\}\n\\tag{2.1}\\]\n\nExemple: La distribution des chiffres obtenus au lancer de dé (si ce dernier est non pipé) suit une loi uniforme dont la loi de probabilité est la suivante :\n\n\n\n\\(x_i\\)\n1\n2\n3\n4\n5\n6\n\n\n\n\n\\(P(X = x_i)\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\\(\\frac{1}{6}\\)\n\n\n\nMoments de loi uniforme discrète\nDans le cas particulier d’une loi uniforme discrète où chaque valeur de la variable aléatoire \\(X\\) correspond à son rang, i.e. \\(x_i=i \\, \\, \\forall i \\in \\{1,\\ldots, n\\}\\), on a: \\[E(X)=\\frac{n+1}{2} \\quad \\text{et} \\quad V(X)=\\frac{n^2-1}{12}\\] La démonstration de ces résultats est établie en utilisant les égalités (cf. Annexe) \\[\\sum_{i=1}^n i=\\frac{n(n+1)}{2} \\quad \\text{et} \\quad \\sum_{i=1}^n i^2=\\frac{n(n+1)(2n+1)}{6}\\]\nEn revenant à l’exemple du lancer du dé de cette section, on peut calculer directement les moments de \\(X\\): \\[E(X)=\\frac{6+1}{2}=3.5\\] et \\[V(X)=\\frac{6^2-1}{12}=\\frac{35}{12}\\simeq 2.92\\]"
  },
  {
    "objectID": "exos1.html#combinatoire",
    "href": "exos1.html#combinatoire",
    "title": "Feuille d’exercices 1",
    "section": "Combinatoire",
    "text": "Combinatoire\n\nExercice 1 Questions diverses:\n\nEn informatique, on utilise le système binaire pour coder les caractères. Un bit (binary digit : chiffre binaire) est un élément qui prend la valeur 0 ou la valeur 1. Avec 8 chiffres binaires (un octet), combien de caractères peut-on coder?\n\n\n\n\n\nA l’occasion d’une compétition sportive groupant 18 athlètes, on attribue une médaille d’or, une d’argent, une de bronze. Combien y-a-t-il de distributions possibles (avant la compétition, bien sûr…) ?\n\n\n\n\n\nUn tournoi sportif compte 8 équipes engagées. Chaque équipe doit rencontrer toutes les autres une seule fois. Combien doit-on organiser de matchs ?\n\n\n\n\n\n\nExercice 2 On jette un dé 🎲 équilibré 3 fois de suite, et on s’intéresse au total des points obtenus. De combien de façons peut-on obtenir:\n\nun total égale à 16.\nun total égale à 15.\nun total au moins égale à 15.\n\n\n\nExercice 3 Dans une entreprise, on compte 12 célibataires parmi les 30 employés. On désire faire un sondage : pour cela on choisit un échantillon de quatre personnes dans ce service.\n\nQuel est le nombre d’échantillons différents possibles ?\nQuel est le nombre d’échantillons ne contenant aucun célibataire ?\nQuel est le nombre d’échantillons contenant au moins un célibataire ?\n\n\n\nExercice 4 On tire simultanément 5 cartes d’un jeu de 52 cartes.\n\nCombien de tirages différents peut-on obtenir?\n\nCombien de tirages peut-on obtenir ? contenant:\n\n5 carreaux ou 5 coeurs;\n2 coeurs et 3 piques;\nau moins 1 roi;\nau plus 1 roi."
  },
  {
    "objectID": "exos1_en.html#counting-combinatorics",
    "href": "exos1_en.html#counting-combinatorics",
    "title": "Feuille d’exercices 1",
    "section": "Counting (Combinatorics)",
    "text": "Counting (Combinatorics)\n\nExercice 1 Separated questions:\n\nIn computing, the binary system is used to code characters. A bit (binary digit) is an element that takes the value 0 or the value 1. With 8 binary digits (one byte), how many characters can we code?\n\n\n\n\n\nIn a sports competition grouping 18 athletes, one gold, one silver and one bronze medal are awarded. How many distributions are there possible (before the competition, of course…)?\n\n\n\n\n\nA sports tournament has 8 participating teams. Each team must meet all the others once. How many games must we organize?\n\n\n\n\n\n\nExercice 2 A die 🎲 is rolled 3 times in a row, and we are interested in the total of the points obtained. In how many ways can we get:\n\na total of 16.\na total of 15.\nat least 15.\n\n\n\nExercice 3 In a company, there are 12 singles among the 30 employees. We wish to make a survey: for that we choose a sample of four people in this department.\n\nHow many different samples can we obtain?\nWhat is the number of samples containing no single person?\nWhat is the number of samples containing at least one single?\n\n\n\nExercice 4 Five cards are drawn simultaneously from a deck of 52 cards.\n\nHow many different draws can we get?\n\nHow many different draws can we get? containing:\n\n5 diamonds or 5 hearts;\n2 hearts and 3 spades;\nat least 1 king\nat most 1 king."
  },
  {
    "objectID": "variables-aleatoires-discretes.html#rappel-probabilités",
    "href": "variables-aleatoires-discretes.html#rappel-probabilités",
    "title": "\n1  Variables Aléatoires Discrètes\n",
    "section": "Rappel probabilités",
    "text": "Rappel probabilités\nEspace Probabilisable\nExemple fondamental: Considérons le jeu du lancé d’un dé.\n\nExpérience aléatoire \\(\\varepsilon\\) : “lancer un dé équilibré”.\nUnivers: l’ensemble de tous les résultats possibles de cette expérience aléatoire \\(\\Omega= \\{1,2,3,4,5,6\\}\\)\nEvénements: Dans cette expérience aléatoire, on peut s’intéresser à des événements plus complexes qu’un simple résultat élémentaire.\nL’ensemble de parties de \\(\\Omega\\), appelé \\(\\mathcal{P}(\\Omega)\\), est l’ensemble des sous-ensembles de \\(\\Omega\\).\nUne famille \\(\\mathcal{A}\\) de parties (i.e. de sous ensembles) de \\(\\Omega\\). Ces parties sont appelées des événements. On dit que l’événement \\(A\\) s’est réalisé si et seulement si le résultat \\(\\omega\\) de \\(\\Omega\\) qui s’est produit appartient à \\(A\\).\n\nTribu: On appelle tribu sur \\(\\Omega\\), toute famille \\(\\mathcal{A}\\) de parties de \\(\\Omega\\) vérifiant:\n\n\\(\\Omega \\in \\mathcal{A}\\).\nsi \\(A \\in \\mathcal{A}\\), alors \\(\\bar{A} \\in \\mathcal{A}\\).\nsi \\((A_n)_{n\\in\\mathbb{N}}\\) est une suite d’éléments de \\(\\mathcal{A}\\), alors \\(\\bigcup\\limits_{n\\in\\mathbb{N}} A_n \\in \\mathcal{A}\\).\n\n\n\\((\\Omega,\\mathcal{A})\\) est un espace probibilisable.\nNotions sur les Evénements\n\n\nSoit \\((\\Omega,\\mathcal{A})\\) un espace probibilisable:\n\nL’ensemble \\(\\mathcal{A}\\) est appelé tribu des événements. Les éléments de \\(\\mathcal{A}\\) s’appellent les événements.\nL’événement \\(\\Omega\\) est appelé événement certain. L’événement \\(\\emptyset\\) est appelé événement impossible.\n\n\n\nOpérations sur les événements: Soient \\(A\\) et \\(B\\) deux événements:\n\n\n\\(\\bar{A}\\) est l’événement contraire de \\(A\\) (on note aussi \\(A^c\\)). \\(\\bar{A}=\\Omega\\setminus A\\).\n\\(\\bar{A}\\) se réalise si et seulement si \\(A\\) ne se réalise pas.\n\n\n\\(A\\, {\\color{blue}\\cap} \\,B\\) est l’événement \\(A\\) et \\(B\\).\n\\(A\\, {\\color{blue}\\cap} \\,B\\) se réalise lorsque les deux événements se réalisent.\n\n\n\\(A\\, {\\color{blue}\\cup} \\,B\\) est l’événement \\(A\\) ou \\(B\\).\n\\(A\\, {\\color{blue}\\cup} \\,B\\) se réalise lorsque au moins un des deux événements se réalise.\n\n\n\nIncompatibilité: \\(A\\) et \\(B\\) sont incompatibles si leur réalisation simultanée est impossible: \\(A \\cap B = \\emptyset\\).\nImplication: \\(A\\) implique \\(B\\) signifie que si \\(A\\) se réalise, alors \\(B\\) se réalise aussi: \\(A \\subset B\\).\nEspace Probabilisé\n\n\nSoit \\((\\Omega,\\mathcal{A})\\) un espace probabilisable. On appelle probabilité sur \\((\\Omega,\\mathcal{A})\\), toute application \\[P : \\mathcal{A} \\rightarrow \\mathbb{R}\\] vérifiant:\n\n\\(\\forall A \\in \\mathcal{A}, P(A) \\geq 0\\).\n\\(P(\\Omega)=1\\).\n\\(\\forall (A_n)_{n\\in\\mathbb{N}^*} \\in \\mathcal{A}^{\\mathbb{N}^*}\\), une suite d’éléments de \\(\\mathcal{A}\\) deux à deux incompatibles, on a: \\[P(\\bigcup\\limits_{n\\in\\mathbb{N}^*} A_n) = \\sum_{n=1}^{+\\infty} P(A_n)\\]\n\n\nLe triplet \\((\\Omega,\\mathcal{A},P)\\) est appelé espace probabilisé.\nProbabilité: Propriétés\n\n\\(P(\\emptyset) = 0\\).\n\\(P(A_1 \\cup A_2 ) = P(A_1 ) + P(A_2 )-P(A_1 \\cap A_2 )\\).\nSi \\(A_1\\) et \\(A_2\\) sont incompatibles, \\(A_1 \\cap A_2 = \\emptyset\\), \\(P(A_1 \\cup A_2 ) = P(A_1 ) + P(A_2 )\\).\n\\(\\begin{align} P(A_1 \\cup A_2 \\cup A_3 ) &= P(A_1 ) + P(A_2 ) + P(A_3 ) - P(A_1 \\cap A_2 ) \\\\  &- P(A_1 \\cap A_3 ) - P(A_2 \\cap A_3 )+P(A_1 \\cap A_2 \\cap A_3 )\\end{align}\\).\n\\(P(\\bar{A}) = 1-P(A)\\).\n\\(P(B\\setminus A)=P(B)-P(B\\cap A)\\).\n\\(A \\subset B \\Rightarrow P(A) \\leq P(B)\\).\n\n\n\n\n\n\n\nNote\n\n\n\nProbabilité uniforme sur \\(\\Omega\\) fini\n\nSoit \\(\\Omega\\) un univers fini. On dit que \\(P\\) est la probabilité uniforme sur l’espace probabilisable \\((\\Omega,P(\\Omega))\\) si: \\[\\forall \\omega,\\omega' \\in \\Omega, \\quad \\quad P(\\{\\omega\\})=P(\\{\\omega'\\})\\] On dit aussi qu’il y a équiprobabilité des événements élémentaires.\nSoit \\((\\Omega, \\mathcal{P}(\\Omega), P)\\) un espace probabilisé fini. Si \\(P\\) est la probabilité uniforme, alors \\[\\forall A \\in \\mathcal{A}, \\quad \\quad P(A)=\\frac{Card(A)}{Card(\\Omega)}\\]\n\n\n\nProbabilité conditionnelle\n\nSoit \\((\\Omega,\\mathcal{A},P)\\) une espace probabilisé et \\(B \\in \\mathcal{A}\\) tel que \\(P(B) > 0\\). L’application \\(P_B\\) définie sur \\(\\mathcal{A}\\) par: \\[P_B(A) = P(A|B) =\\frac{P(A\\cap B)}{P(B)}, \\quad \\quad \\forall A \\in \\mathcal{A}\\] est une probabilité sur \\((\\Omega, \\mathcal{A})\\); elle est appelée la probabilité conditionnelle sachant \\(B\\). C’est la probabilité pour que l’événement \\(A\\) se produise sachant que l’événement \\(B\\) s’est produit.\nRemarque: \\((A|B)\\) n’est pas un événement! On utilise la notation \\(P(A|B)\\) par simplicité, mais c’est \\(P_B (A)\\) qui est correcte.\nFormule des probabilités composées: \\[P(A\\cap B) = P(A|B)P(B) = P(B|A)P(A)\\]\n\nFormule des probabilités totales:\n\n\\(\\forall A \\in \\mathcal{A}, \\quad P(A) = P(A \\cap B) + P(A \\cap \\bar{B} )\\)\nOn appelle système complet d’événements (SCE), toute partition dénombrable de \\(\\Omega\\) formée d’éléments de \\(A\\); c-à-d tout ensemble dénombrable d’événements, deux à deux incompatibles et dont l’union dénombrable est l’événement certain.\nSoit \\((B_n)_{n\\geq 0}\\) un SCE de \\(\\Omega\\). On a: \\[\\forall A \\in \\mathcal{A},\\quad \\quad P(A)=\\sum_{n\\geq 0} P(A \\cap B_n)\\]\n\n\nIndépendance: Les événements \\(A\\) et \\(B\\) sont indépendants ssi \\(P(A\\cap B)=P(A)P(B)\\).\nFormule de Bayes\nPremière formule de Bayes:\nSoit \\((\\Omega,\\mathcal{A},P)\\) une espace probabilisé. Pour tous événements \\(A\\) et \\(B\\) tels que \\(P(A) \\neq 0\\) et \\(P(B) \\neq 0\\), on a: \\[P(B|A) = \\frac{P(A|B)P(B)}{P(A)}\\]\nDeuxième formule de Bayes:\nSoit \\((\\Omega,\\mathcal{A},P)\\) une espace probabilisé et \\((B_n)_{n\\geq 0}\\) un SCE de \\(\\Omega\\) t.q. pour tout \\(n\\geq 0 \\,\\, P(B_n)\\neq 0\\). On a pour tout \\(A \\in \\mathcal{A}\\) t.q. \\(P(A)\\neq 0\\) \\[P(B_i|A) = \\frac{P(A|B_i) P(B_i)}{\\sum_{n\\geq 0} P(A|B_n) P(B_n)} \\quad \\quad \\forall i \\geq 0\\]"
  }
]