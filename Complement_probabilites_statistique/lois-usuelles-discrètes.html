<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Lois usuelles discrètes | Complément de formation en Probabilités et Statistique</title>
  <meta name="description" content="Cours de Probabilités et Statistique A3 ESILV" />
  <meta name="generator" content="bookdown 0.19 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Lois usuelles discrètes | Complément de formation en Probabilités et Statistique" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Cours de Probabilités et Statistique A3 ESILV" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Lois usuelles discrètes | Complément de formation en Probabilités et Statistique" />
  
  <meta name="twitter:description" content="Cours de Probabilités et Statistique A3 ESILV" />
  

<meta name="author" content="Mohamad Ghassany" />


<meta name="date" content="2020-10-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/favicon.ico" type="image/x-icon" />
<link rel="prev" href="couple-de-variables-aléatoires-discrètes.html"/>
<link rel="next" href="feuille-dexercices-1.html"/>
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="book_assets/font-awesome-5.3.1/css/fontawesome-all.min.css" rel="stylesheet" />
<script src="book_assets/kePrint-0.0.1/kePrint.js"></script>



<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class='beforeimg'>            
   <a href="https://www.esilv.fr/">
       <img src="img/Logo_ESILV_new_blanc.png" style="width:50%; padding:0px 0; display:block; margin: 0 auto;" alt="ESILV logo">
    </a>
</li>
<li class='before'><a href="./">Probabilités et Statistique</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="part"><span><b>V.A.Discrètes</b></span></li>
<li class="chapter" data-level="1" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html"><i class="fa fa-check"></i><b>1</b> Variables Aléatoires Discrètes</a><ul>
<li class="chapter" data-level="" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#notion-de-variable-aléatoire-réelle-v.a.r."><i class="fa fa-check"></i>Notion de variable aléatoire réelle (v.a.r.)</a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#définition-loi-de-probabilité"><i class="fa fa-check"></i>Définition, loi de probabilité</a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#fonction-de-répartition-dune-variable-aléatoire-discrète"><i class="fa fa-check"></i>Fonction de répartition d’une variable aléatoire discrète</a></li>
<li><a href="variables-aléatoires-discrètes.html#fonction-de-répartition-et-probabilités-sur-x">Fonction de répartition et probabilités sur <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#moments-dune-variable-aléatoire-discrète"><i class="fa fa-check"></i>Moments d’une variable aléatoire discrète</a><ul>
<li class="chapter" data-level="" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#espérance-mathématique"><i class="fa fa-check"></i>Espérance mathématique</a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#espérance-dune-fonction-dune-variable-aléatoire"><i class="fa fa-check"></i>Espérance d’une fonction d’une variable aléatoire</a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#variance"><i class="fa fa-check"></i>Variance</a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#ecart-type"><i class="fa fa-check"></i>Ecart-type</a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-discrètes.html"><a href="variables-aléatoires-discrètes.html#moments-non-centrés-et-centrés"><i class="fa fa-check"></i>Moments non centrés et centrés</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="couple-de-variables-aléatoires-discrètes.html"><a href="couple-de-variables-aléatoires-discrètes.html"><i class="fa fa-check"></i><b>2</b> Couple de variables aléatoires discrètes</a><ul>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-discrètes.html"><a href="couple-de-variables-aléatoires-discrètes.html#table-de-probabilité-conjointe"><i class="fa fa-check"></i>Table de probabilité conjointe</a></li>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-discrètes.html"><a href="couple-de-variables-aléatoires-discrètes.html#lois-marginales"><i class="fa fa-check"></i>Lois marginales</a></li>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-discrètes.html"><a href="couple-de-variables-aléatoires-discrètes.html#lois-conditionnelles"><i class="fa fa-check"></i>Lois conditionnelles</a></li>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-discrètes.html"><a href="couple-de-variables-aléatoires-discrètes.html#indépendance-de-variables-aléatoires"><i class="fa fa-check"></i>Indépendance de variables aléatoires</a></li>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-discrètes.html"><a href="couple-de-variables-aléatoires-discrètes.html#covariance"><i class="fa fa-check"></i>Covariance</a></li>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-discrètes.html"><a href="couple-de-variables-aléatoires-discrètes.html#coefficient-de-corrélation-linéaire"><i class="fa fa-check"></i>Coefficient de corrélation linéaire</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="lois-usuelles-discrètes.html"><a href="lois-usuelles-discrètes.html"><i class="fa fa-check"></i><b>3</b> Lois usuelles discrètes</a><ul>
<li><a href="lois-usuelles-discrètes.html#loi-uniforme-discrète-mathcalun">Loi uniforme discrète <span class="math inline">\(\mathcal{U}(n)\)</span></a></li>
<li><a href="lois-usuelles-discrètes.html#loi-de-bernoulli-mathcalbp">Loi de Bernoulli <span class="math inline">\(\mathcal{B}(p)\)</span></a></li>
<li><a href="lois-usuelles-discrètes.html#loi-binomiale-mathcalbnp">Loi Binomiale <span class="math inline">\(\mathcal{B}(n,p)\)</span></a></li>
<li><a href="lois-usuelles-discrètes.html#loi-de-poisson-mathcalplambda">Loi de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span></a></li>
<li class="chapter" data-level="" data-path="lois-usuelles-discrètes.html"><a href="lois-usuelles-discrètes.html#approximation-dune-loi-binomiale"><i class="fa fa-check"></i>Approximation d’une loi binomiale</a></li>
<li><a href="lois-usuelles-discrètes.html#loi-géométrique-ou-de-pascal-mathcalgp">Loi Géométrique ou de Pascal <span class="math inline">\(\mathcal{G}(p)\)</span></a></li>
<li><a href="lois-usuelles-discrètes.html#loi-binomiale-négative-mathcalbnrp">Loi Binomiale Négative <span class="math inline">\(\mathcal{BN}(r,p)\)</span></a><ul>
<li><a href="lois-usuelles-discrètes.html#mathcalgpmathcalbn1p"><span class="math inline">\(\mathcal{G}(p)=\mathcal{BN}(1,p)\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="feuille-dexercices-1.html"><a href="feuille-dexercices-1.html"><i class="fa fa-check"></i>Feuille d’exercices 1</a><ul>
<li class="chapter" data-level="" data-path="feuille-dexercices-1.html"><a href="feuille-dexercices-1.html#combinatoire"><i class="fa fa-check"></i>Combinatoire</a></li>
<li class="chapter" data-level="" data-path="feuille-dexercices-1.html"><a href="feuille-dexercices-1.html#événements"><i class="fa fa-check"></i>Événements</a></li>
<li class="chapter" data-level="" data-path="feuille-dexercices-1.html"><a href="feuille-dexercices-1.html#probabilité"><i class="fa fa-check"></i>Probabilité</a></li>
<li class="chapter" data-level="" data-path="feuille-dexercices-1.html"><a href="feuille-dexercices-1.html#variables-aléatoires-discrètes-1"><i class="fa fa-check"></i>Variables aléatoires discrètes</a></li>
<li class="chapter" data-level="" data-path="feuille-dexercices-1.html"><a href="feuille-dexercices-1.html#exercices-supplémentaires"><i class="fa fa-check"></i>Exercices supplémentaires</a></li>
</ul></li>
<li class="part"><span><b>V.A.Continues</b></span></li>
<li class="chapter" data-level="4" data-path="variables-aléatoires-continues.html"><a href="variables-aléatoires-continues.html"><i class="fa fa-check"></i><b>4</b> Variables Aléatoires Continues</a><ul>
<li class="chapter" data-level="" data-path="variables-aléatoires-continues.html"><a href="variables-aléatoires-continues.html#densité-dune-variable-aléatoire-continue"><i class="fa fa-check"></i>Densité d’une variable aléatoire continue</a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-continues.html"><a href="variables-aléatoires-continues.html#fonction-de-répartition-dune-v.a.c"><i class="fa fa-check"></i>Fonction de répartition d’une v.a.c</a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-continues.html"><a href="variables-aléatoires-continues.html#fonction-dune-variable-aléatoire-continue"><i class="fa fa-check"></i>Fonction d’une variable aléatoire continue</a><ul>
<li><a href="variables-aléatoires-continues.html#calcul-de-densités-pour-hxaxb">Calcul de densités pour <span class="math inline">\(h(X)=aX+b\)</span></a></li>
<li><a href="variables-aléatoires-continues.html#calcul-de-densités-pour-hxx2">Calcul de densités pour <span class="math inline">\(h(X)=X^2\)</span></a></li>
<li><a href="variables-aléatoires-continues.html#calcul-de-densités-pour-hxex">Calcul de densités pour <span class="math inline">\(h(X)=e^X\)</span></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-continues.html"><a href="variables-aléatoires-continues.html#espérance-et-variance-de-variables-aléatoires-continues"><i class="fa fa-check"></i>Espérance et variance de variables aléatoires continues</a><ul>
<li class="chapter" data-level="" data-path="variables-aléatoires-continues.html"><a href="variables-aléatoires-continues.html#espérance-dune-v.a.c"><i class="fa fa-check"></i>Espérance d’une v.a.c</a></li>
<li class="chapter" data-level="" data-path="variables-aléatoires-continues.html"><a href="variables-aléatoires-continues.html#variance-dune-v.a.c"><i class="fa fa-check"></i>Variance d’une v.a.c</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="lois-usuelles-de-v-a-c.html"><a href="lois-usuelles-de-v-a-c.html"><i class="fa fa-check"></i><b>5</b> Lois usuelles de v.a.c</a><ul>
<li><a href="lois-usuelles-de-v-a-c.html#loi-uniforme-uab">Loi uniforme <span class="math inline">\(U(a,b)\)</span></a></li>
<li><a href="lois-usuelles-de-v-a-c.html#loi-exponentielle-mathcalelambda">Loi exponentielle <span class="math inline">\(\mathcal{E}(\lambda)\)</span></a></li>
<li><a href="lois-usuelles-de-v-a-c.html#loi-normale-ou-de-laplace-gauss-mathcalnmusigma2">Loi Normale ou de Laplace-Gauss <span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span></a><ul>
<li class="chapter" data-level="" data-path="lois-usuelles-de-v-a-c.html"><a href="lois-usuelles-de-v-a-c.html#étude-de-la-densité-de-la-loi-normale"><i class="fa fa-check"></i>Étude de la densité de la loi Normale</a></li>
</ul></li>
<li><a href="lois-usuelles-de-v-a-c.html#loi-normale-centrée-réduite-mathcaln01">Loi Normale centrée réduite <span class="math inline">\(\mathcal{N}(0,1)\)</span></a></li>
<li class="chapter" data-level="" data-path="lois-usuelles-de-v-a-c.html"><a href="lois-usuelles-de-v-a-c.html#relation-entre-loi-normale-et-loi-normale-centrée-réduite"><i class="fa fa-check"></i>Relation entre loi normale et loi normale centrée réduite</a></li>
<li class="chapter" data-level="" data-path="lois-usuelles-de-v-a-c.html"><a href="lois-usuelles-de-v-a-c.html#calcul-des-probabilités-dune-loi-normale"><i class="fa fa-check"></i>Calcul des probabilités d’une loi normale</a></li>
<li class="chapter" data-level="" data-path="lois-usuelles-de-v-a-c.html"><a href="lois-usuelles-de-v-a-c.html#approximation-normale-dune-répartition-binomiale"><i class="fa fa-check"></i>Approximation normale d’une répartition binomiale</a></li>
<li><a href="lois-usuelles-de-v-a-c.html#loi-de-chi2-de-pearson">Loi de <span class="math inline">\(\chi^{2}\)</span> de Pearson</a></li>
<li><a href="lois-usuelles-de-v-a-c.html#loi-de-student-stn">Loi de Student <span class="math inline">\(St(n)\)</span></a></li>
<li><a href="lois-usuelles-de-v-a-c.html#loi-de-fisher-snedecor-mathcalfnm">Loi de Fisher-Snedecor <span class="math inline">\(\mathcal{F}(n,m)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="couple-de-variables-aléatoires-continues.html"><a href="couple-de-variables-aléatoires-continues.html"><i class="fa fa-check"></i><b>6</b> Couple de variables aléatoires continues</a><ul>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-continues.html"><a href="couple-de-variables-aléatoires-continues.html#densité-conjointe"><i class="fa fa-check"></i>Densité conjointe</a></li>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-continues.html"><a href="couple-de-variables-aléatoires-continues.html#densités-marginales"><i class="fa fa-check"></i>Densités marginales</a></li>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-continues.html"><a href="couple-de-variables-aléatoires-continues.html#espérance-dune-fonction-du-couple"><i class="fa fa-check"></i>Espérance d’une fonction du couple</a></li>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-continues.html"><a href="couple-de-variables-aléatoires-continues.html#indépendance"><i class="fa fa-check"></i>Indépendance</a></li>
<li class="chapter" data-level="" data-path="couple-de-variables-aléatoires-continues.html"><a href="couple-de-variables-aléatoires-continues.html#distribution-conditionnelle"><i class="fa fa-check"></i>Distribution conditionnelle</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="feuille-dexercices-2.html"><a href="feuille-dexercices-2.html"><i class="fa fa-check"></i>Feuille d’exercices 2</a><ul>
<li class="chapter" data-level="" data-path="feuille-dexercices-2.html"><a href="feuille-dexercices-2.html#variables-alétoires-continues"><i class="fa fa-check"></i>Variables alétoires continues</a></li>
<li class="chapter" data-level="" data-path="feuille-dexercices-2.html"><a href="feuille-dexercices-2.html#couple-de-variables-aléatoires-continues-1"><i class="fa fa-check"></i>Couple de variables aléatoires continues</a></li>
<li class="chapter" data-level="" data-path="feuille-dexercices-2.html"><a href="feuille-dexercices-2.html#exercices-supplémentaires-1"><i class="fa fa-check"></i>Exercices supplémentaires</a></li>
</ul></li>
<li class="appendix"><span><b>Annexe</b></span></li>
<li class="chapter" data-level="A" data-path="tab-normale.html"><a href="tab-normale.html"><i class="fa fa-check"></i><b>A</b> Table de la loi Normale centrée réduite</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Complément de formation en Probabilités et Statistique</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lois-usuelles-discrètes" class="section level1">
<h1><span class="header-section-number">3</span> Lois usuelles discrètes</h1>
<div id="loi-uniforme-discrète-mathcalun" class="section level2 unnumbered">
<h2>Loi uniforme discrète <span class="math inline">\(\mathcal{U}(n)\)</span></h2>

<div class="definition">
<p><span id="def:unnamed-chunk-18" class="definition"><strong>Définition 3.1  </strong></span>Une distribution de probabilité suit une loi uniforme lorsque toutes les
valeurs prises par la variable aléatoire sont équiprobables. Si <span class="math inline">\(n\)</span> est
le nombre de valeurs différentes prises par la variable aléatoire alors
on a:</p>
<span class="math display">\[\label{eq:unif}
    P(X=x_i)=\frac{1}{n} \qquad \forall \, i \in \{1,\ldots, n\}\]</span>
</div>

<p><strong>Exemple:</strong> La distribution des chiffres obtenus au lancer de dé (si ce dernier est
non pipé) suit une loi uniforme dont la loi de probabilité est la
suivante :</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(x_i\)</span></th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
<th align="center">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(P(X = x_i)\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{6}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{6}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{6}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{6}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{6}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{6}\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Moments de loi uniforme discrète</strong></p>
<p>Dans le <strong>cas particulier</strong> d’une loi uniforme discrète où chaque valeur
de la variable aléatoire <span class="math inline">\(X\)</span> correspond à son rang, i.e.
<span class="math inline">\(x_i=i \, \, \forall i \in \{1,\ldots, n\}\)</span>, on a:
<span class="math display">\[E(X)=\frac{n+1}{2} \quad \text{et} \quad V(X)=\frac{n^2-1}{12}\]</span> La
démonstration de ces résultats est établie en utilisant les égalités
(cf. Annexe)
<span class="math display">\[\sum_{i=1}^n i=\frac{n(n+1)}{2} \quad \text{et} \quad \sum_{i=1}^n i^2=\frac{n(n+1)(2n+1)}{6}.\]</span></p>
<p>En revenant à l’exemple du lancer du dé de cette section, on peut
calculer directement les moments de <span class="math inline">\(X\)</span>: <span class="math display">\[E(X)=\frac{6+1}{2}=3.5\]</span> et
<span class="math display">\[V(X)=\frac{6^2-1}{12}=\frac{35}{12}\simeq 2.92.\]</span></p>
</div>
<div id="loi-de-bernoulli-mathcalbp" class="section level2 unnumbered">
<h2>Loi de Bernoulli <span class="math inline">\(\mathcal{B}(p)\)</span></h2>

<div class="definition">
<p><span id="def:unnamed-chunk-19" class="definition"><strong>Définition 3.2  </strong></span>On réalise une expérience dont le résultat sera interprété soit comme un
succès soit comme un échec. On définit alors la variable aléatoire <span class="math inline">\(X\)</span>
en lui donnant la valeur 1 lors d’un succès et 0 lors d’un échec
(variable indicatrice). La loi de probabilité de <span class="math inline">\(X\)</span> est alors</p>
<p><span class="math display" id="eq:bern">\[\begin{align}
    &amp;p(1)=P(X=1)=p \tag{3.1} \\ 
    &amp;p(0)=P(X=0)= 1-p=q \notag
\end{align}\]</span></p>
<p>où <span class="math inline">\(p\)</span> est la probabilité d’un succès, <span class="math inline">\(0 \leq p \leq 1\)</span>.</p>
Une variable aléatoire <span class="math inline">\(X\)</span> est dite de <strong>Bernoulli</strong>
<span class="math inline">\(X \sim \mathcal{B} \left({p}\right)\)</span> s’il existe un nombre
<span class="math inline">\(p \, \in \, ]0,1[\)</span> tel que la loi de probabilité de <span class="math inline">\(X\)</span> soit donnée par <a href="lois-usuelles-discrètes.html#eq:bern">(3.1)</a>.
</div>

<p>La fonction de répartition est définie par: <span class="math display">\[F(x) = 
       \left\{
       \begin{array}{ll}
         0 &amp; \quad \text{si $x &lt; 0$} \\
         1 - p &amp; \quad \text{si $0 \leq x &lt; 1$} \\
         1 &amp; \quad \text{si $x \geq 1$}.
       \end{array}
       \right.\]</span></p>
<p>L’espérance la loi de Bernoulli est <span class="math inline">\(p\)</span>, en effet</p>
<p><span class="math display">\[E(X) =1 \times P(X=1)+0 \times P(X=0)=P(X=1)=p\]</span></p>
<p>La variance la loi de Bernoulli est <span class="math inline">\(np\)</span>, en effet</p>
<p><span class="math display">\[V(X) =E(X^2)-E^2(X)=p-p^2=p(1-p)=pq\]</span> car
<span class="math display">\[E(X^2) =1^2\times P(X=1)+0^2 \times P(X=0)=P(X=1)=p\]</span></p>
</div>
<div id="loi-binomiale-mathcalbnp" class="section level2 unnumbered">
<h2>Loi Binomiale <span class="math inline">\(\mathcal{B}(n,p)\)</span></h2>

<div class="rmdtip">
Décrite pour la première fois par <em>Isaac Newton</em> en 1676 et démontrée pour la première fois par le mathématicien suisse <em>Jacob Bernoulli</em> en 1713, la loi binomiale est l’une des distributions de probabilité les plus fréquemment rencontrées en statistique appliquée.
</div>

<p>Supposons qu’on exécute maintenant <span class="math inline">\(n\)</span> épreuves <strong>indépendantes</strong>,
chacune ayant <span class="math inline">\(p\)</span> pour probabilité de succès et <span class="math inline">\(1-p\)</span> pour probabilité
d’échec. La variable aléatoire <span class="math inline">\(X\)</span> qui compte <strong>le nombre de succès</strong>
sur l’ensemble des <span class="math inline">\(n\)</span> épreuves est dite variable aléatoire
<strong>binomiale</strong> de paramètres <span class="math inline">\(n\)</span> et <span class="math inline">\(p\)</span>.</p>

<div class="rmdinsight">
Une variable de Bernoulli n’est donc qu’une variable binomiale de paramètres <span class="math inline">\((1,p)\)</span>.
</div>


<div class="definition">
<p><span id="def:unnamed-chunk-22" class="definition"><strong>Définition 3.3  </strong></span>Si on effectue <span class="math inline">\(n\)</span> épreuves successives indépendantes où on note à
chaque fois la réalisation ou non d’un certain événement <span class="math inline">\(A\)</span>, on obtient une suite de la forme <span class="math inline">\(AA\bar{A}A\bar{A}\ldots \bar{A}AA\)</span>. Soit <span class="math inline">\(X\)</span> le nombre de réalisations de <span class="math inline">\(A\)</span>. On définit ainsi une v.a. <span class="math inline">\(X\)</span> qui suit une loi binomiale de paramètres <span class="math inline">\(n\)</span> et <span class="math inline">\(p=P(A)\)</span>, caractérisée par
<span class="math inline">\(X(\Omega)=\{0, 1,\ldots, n\}\)</span> :</p>
<p><span class="math display" id="eq:binom">\[\begin{equation}
    P(X=k)=\binom{n}{k}p^k (1-p)^{n-k} \qquad 0\leq k \leq n
    \tag{3.2}
\end{equation}\]</span></p>
On écrit <span class="math inline">\(X \sim \mathcal{B} \left({n, p}\right)\)</span>. Donc la loi binomiale modélise le nombre de réalisations de <span class="math inline">\(A\)</span> (succès) obtenues lors de la répétition indépendante et identique de <span class="math inline">\(n\)</span> épreuves de Bernoulli.
</div>


<div class="rmdinsight">
Pour établir <a href="lois-usuelles-discrètes.html#eq:binom">(3.2)</a> il faut remarquer que <span class="math inline">\(\binom{n}{k}\)</span> est le nombre d’échantillons de taille <span class="math inline">\(n\)</span> comportant exactement <span class="math inline">\(k\)</span> événements <span class="math inline">\(A\)</span>, de probabilité <span class="math inline">\(p^k\)</span>, indépendamment de l’ordre, et donc <span class="math inline">\(n-k\)</span> événements <span class="math inline">\(\bar{A}\)</span>, de probabilité <span class="math inline">\((1-p)^{n-k}\)</span>.
</div>

<p><strong>Remarque:</strong> Il est possible d’obtenir aisément les valeurs des combinaisons de la loi binomiale en utilisant le triangle de Pascal.</p>
<p>En utilisant la formule du binôme de Newton, on vérifie
bien que c’est une loi de probabilité:</p>
<p><span class="math display">\[{\sum_{k=0}^nP(X=k)=\sum_{k=0}^n\binom{n}{k} p^{k}(1-p)^{n-k}=[p+(1-p)]^n=1}\]</span></p>
<p><strong>Exemple:</strong> On jette cinq pièces équilibrées. Les résultats sont supposés
indépendants. Donner la loi de probabilité de la variable <span class="math inline">\(X\)</span> qui compte
le nombre de piles obtenus.</p>
<p><strong>Moments de la loi Binomiale</strong></p>
<p>Pour calculer facilement les moments de cette loi, nous allons associer
à chaque épreuve <span class="math inline">\(i\)</span>, <span class="math inline">\(1\leq i \leq n\)</span>, une v.a. de Bernoulli (variable
indicatrice sur <span class="math inline">\(A\)</span>): <span class="math display">\[{1}_A=X_i = \left\{ 
\begin{array}{l l}
 1 &amp; \quad \text{si $A$ est réalisé}\\
 0 &amp; \quad \text{si $\bar{A}$ est réalisé}\\ 
  \end{array} \right.\]</span> On peut écrire alors:
<span class="math inline">\(X=\sum_{i=1}^nX_i=X_1+X_2+\ldots+X_n\)</span>, ce qui nous permet de déduire
aisément: <span class="math display">\[\begin{aligned}
    E(X)&amp;=E\left(\sum_{i=1}^nX_i\right)=\sum_{i=1}^nE(X_i)=np \\
    \text{et} \nonumber \\
    V(X)&amp;=V\left(\sum_{i=1}^nX_i\right)=\sum_{i=1}^nV(X_i)=np(1-p) \quad \text{car les v.a. $X_i$ sont indépendantes.}
  \end{aligned}\]</span></p>
<p>Le calcul direct des moments de <span class="math inline">\(X\)</span> peut s’effectuer à partir de la
définition générale, mais de façon beaucoup plus laborieuse:
<span class="math display">\[\begin{aligned}
 E(X)&amp;= \sum_{k=0}^nk \binom{n}{k} p^{k}(1-p)^{n-k}=\sum_{k=1}^nk \frac{n!}{k!(n-k)!} p^{k}(1-p)^{n-k} \\
 &amp;= \sum_{k=1}^n\frac{n!}{(k-1)!(n-k)!} p^{k}(1-p)^{n-k}= np \sum_{k=1}^n\frac{(n-1)!}{(k-1)!(n-k)!} p^{k-1}(1-p)^{n-k} \\ 
 &amp;= np \sum_{j=0}^{n-1}\frac{(n-1)!}{j!(n-1-j)!}p^j (1-p)^{n-1-j} =np \sum_{j=0}^{n-1}\binom{n-1}{j} p^{j}(1-p)^{n-1-j} \\
 &amp;= np [p+(1-p)]^{n-1}=np
 \end{aligned}\]</span></p>
<p>Pour obtenir <span class="math inline">\(E(X^2)\)</span> par un procédé de calcul identique, on passe par
l’intermédiaire du moment factoriel <span class="math inline">\(E[X(X-1)]=E(X^2)-E(X)\)</span>:
<span class="math display">\[\begin{aligned}
  E[X(X-1)]&amp;= \sum_{k=0}^nk(k-1) \frac{n!}{k!(n-k)!} p^{k}(1-p)^{n-k} \\ 
  &amp;= n(n-1)p^2 \sum_{k=2}^{n}\frac{(n-2)!}{(k-2)!(n-k)!} p^{k-2}(1-p)^{n-k} \\ &amp;= n(n-1)p^2 \sum_{j=0}^{n-2}\binom{n-2}{j} p^{j}(1-p)^{n-2-j} \\
  &amp;= n(n-1)p^2[p+(1-p)]^{n-2}= n(n-1)p^2
   \end{aligned}\]</span> On en déduit alors:
<span class="math display">\[E(X^2)=E[X(X-1)]+E(X)= n(n-1)p^2+np,\]</span> puis: <span class="math display">\[\begin{aligned}
   V(X)&amp;=n(n-1)p^2+np-(np)^2 \\ &amp;=n^2p^2+np(1-p)-n^2p^2 \\ &amp;=np(1-p).
  \end{aligned}\]</span></p>
<p>Le nombre de résultats pile apparus au cours de <span class="math inline">\(n\)</span> jets d’une pièce de
monnaie suit une loi binomiale <span class="math inline">\(\mathcal{B} \left({n, 1/2}\right)\)</span>:
<span class="math display">\[P(X=k)=\binom{n}{k}\left(\frac{1}{2}\right)^k \left(\frac{1}{2}\right)^{n-k}=\frac{\binom{n}{k}}{2^n}, \quad 0\leq k \leq n\]</span>
avec <span class="math inline">\(E(X)=n/2\)</span> et <span class="math inline">\(V(X)=n/4\)</span>.</p>
<p>Le nombre <span class="math inline">\(N\)</span> de boules rouges apparues au cours de <span class="math inline">\(n\)</span> tirages avec
remise dans une urne contenant deux rouges, trois vertes et une noire
suit une loi binomiale <span class="math inline">\(\mathcal{B} \left({n, 1/3}\right)\)</span>:
<span class="math display">\[P(N=k)=\binom{n}{k}\left(\frac{1}{3}\right)^k \left(\frac{2}{3}\right)^{n-k}=\binom{n}{k} \frac{2^{n-k}}{3^n}, \quad 0\leq k \leq n\]</span>
avec <span class="math inline">\(E(X)=n/3\)</span> et <span class="math inline">\(V(X)=2n/9\)</span>.</p>

<div class="theorem">
<span id="thm:unnamed-chunk-24" class="theorem"><strong>Théorème 3.1  </strong></span>Si <span class="math inline">\(X_1 \sim \mathcal{B} \left({n_1, p}\right)\)</span> et
<span class="math inline">\(X_2 \sim \mathcal{B} \left({n_2, p}\right)\)</span>, les v.a. <span class="math inline">\(X_1\)</span> et <span class="math inline">\(X_2\)</span>
étant indépendantes, alors
<span class="math inline">\(X_1+X_2 \sim \mathcal{B} \left({n_1+n_2, p}\right)\)</span>. Ceci résulte de la
définition d’une loi binomiale puisqu’on totalise ici le résultat de
<span class="math inline">\(n_1+n_2\)</span> épreuves indépendantes.
</div>

</div>
<div id="loi-de-poisson-mathcalplambda" class="section level2 unnumbered">
<h2>Loi de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span></h2>

<div class="rmdtip">
La loi de Poisson est découverte au début du XIX<span class="math inline">\(^e\)</span> siècle par le
magistrat français <em>Siméon-Denis Poisson</em>. Les variables aléatoires
de Poisson ont un champ d’application fort vaste, en particulier du
fait qu’on peut les utiliser pour approximer des variables
aléatoires binomiales de paramètres <span class="math inline">\((n,p)\)</span> pour autant que <span class="math inline">\(n\)</span> soit
grand et <span class="math inline">\(p\)</span> assez petit pour que <span class="math inline">\(np\)</span> soit d’ordre de grandeur
moyen.
</div>


<div class="definition">
<span id="def:unnamed-chunk-26" class="definition"><strong>Définition 3.4  </strong></span>Une v.a. <span class="math inline">\(X\)</span> suit une loi de Poisson de paramètre <span class="math inline">\(\lambda&gt;0\)</span> si c’est
une variable à valeurs entières, <span class="math inline">\(X(\Omega)=\mathbb{N}\)</span>, donc avec une
infinité de valeurs possibles, de probabilité: <span class="math display">\[\label{eq:poisson}
    P(X=k)=e^{-\lambda} \frac{\lambda^k}{k!}, \quad k \in \mathbb{N}\]</span>
Cette loi ne dépend qu’un seul paramètre réel positif <span class="math inline">\(\lambda\)</span>, avec
l’écriture symbolique <span class="math inline">\(X \sim \mathcal{P}(\lambda)\)</span>.
</div>

<p>Le développement en série entière de l’exponentielle
<span class="math inline">\(e^\lambda=\sum_{k=0}^{+\infty} \frac{\lambda^k}{k!}\)</span> permet de
vérifier qu’il s’agit bien d’une loi de probabilité:
<span class="math display">\[\sum_{k=0}^{\infty} P(X=k)=\sum_{k=0}^{\infty} e^{-\lambda} \frac{\lambda^k}{k!}=e^{-\lambda}\sum_{k=0}^{\infty} \frac{\lambda^k}{k!}=e^{-\lambda}e^{\lambda}=1\]</span></p>
<p><strong>Moments de loi de Poisson</strong></p>
<p>Le calcul de l’espérance mathématique se déduit du développement en
série entière de l’exponentielle: <span class="math display">\[\begin{aligned}
    E(X)&amp;=\sum_{k=0}^{\infty} k P(X=k)=\sum_{k=1}^{\infty} k e^{-\lambda} \frac{\lambda^k}{k!} \\
        &amp;=e^{-\lambda} \sum_{k=1}^{\infty}  \frac{\lambda^k}{(k-1)!}=\lambda e^{-\lambda} \sum_{k=1}^{\infty}  \frac{\lambda^{k-1}}{(k-1)!} \\
        &amp;= \lambda e^{-\lambda} \sum_{j=0}^{\infty}  \frac{\lambda^{j}}{j!}= \lambda e^{-\lambda}  e^{\lambda} \\
        &amp;= \lambda.\end{aligned}\]</span> Pour calculer la variance nous
n’allons pas calculer <span class="math inline">\(E(X^2)\)</span> mais le moment factoriel <span class="math inline">\(E[X(X-1)]\)</span> qui
s’obtient plus facilement, selon la méthode précédente:
<span class="math display">\[\begin{aligned}
    E[X(X-1)] &amp;=\sum_{k=0}^{\infty} k(k-1)P(X=k)=\sum_{k=2}^{\infty} k(k-1)  \,e^{-\lambda} \frac{\lambda^k}{k!} \\
        &amp;=e^{-\lambda} \sum_{k=2}^{\infty}  \frac{\lambda^k}{(k-2)!}=\lambda^2 e^{-\lambda} \sum_{k=2}^{\infty}  \frac{\lambda^{k-2}}{(k-2)!} \\ 
        &amp;= \lambda^2 e^{-\lambda} \sum_{j=0}^{\infty}  \frac{\lambda^{j}}{j!}= \lambda^2 e^{-\lambda}  e^{\lambda} = \lambda^2.\end{aligned}\]</span>
On en déduit: <span class="math display">\[\begin{aligned}
    V(X)&amp;=E(X^2)-E^2(X)=E[X(X-1)]+E(X)-E^2(X) \\
        &amp;=\lambda^2+\lambda-\lambda^2=\lambda.\end{aligned}\]</span></p>

<div class="theorem">
<span id="thm:unnamed-chunk-27" class="theorem"><strong>Théorème 3.2  </strong></span>Si <span class="math inline">\(X\)</span> et <span class="math inline">\(Y\)</span> sont deux variables <strong>indépendantes</strong> suivant des lois de
Poisson
<span class="math display">\[X \sim \mathcal{P}(\lambda) \quad \text{et} \quad Y \sim \mathcal{P}(\mu)\]</span>
alors leur somme suit aussi une loi de Poisson:
<span class="math display">\[X+Y \sim \mathcal{P}(\lambda+\mu).\]</span>
</div>

<p><strong>Exemple:</strong> Soit <span class="math inline">\(X\)</span> la variable aléatoire associée au nombre de micro-ordinateurs
vendus chaque jour dans le magasin. On suppose que <span class="math inline">\(X\)</span> suit une loi de
Poisson de paramètre <span class="math inline">\(\lambda=5\)</span>. On écrit alors
<span class="math inline">\(X \sim \mathcal{P}(5).\)</span><br />
La probabilité associée à la vente de 5 micro-ordinateurs se détermine
par : <span class="math display">\[P(X=5)=e^{-5} \frac{5^5}{5!}=e^{-5}\simeq 0.1755\]</span> La
probabilité de vendre au moins 2 micro-ordinateurs est égal à:
<span class="math display">\[\begin{aligned}
P(X \geq 2)&amp;=1-\left(e^{-5} \frac{5^0}{0!}+e^{-5} \frac{5^1}{1!}\right)\simeq 0.9596\end{aligned}\]</span>
Le nombre moyen de micro-ordinateurs vendus chaque jour dans le magasin
est égal à 5 puisque <span class="math inline">\(E(X)=\lambda=5\)</span>.</p>
</div>
<div id="approximation-dune-loi-binomiale" class="section level2 unnumbered">
<h2>Approximation d’une loi binomiale</h2>
<p>Le théorème de Poisson nous montre que si <span class="math inline">\(n\)</span> est suffisamment grand et
<span class="math inline">\(p\)</span> assez petit, alors on peut approcher la distribution d’une loi
binomiale de paramètres <span class="math inline">\(n\)</span> et <span class="math inline">\(p\)</span> par celle d’une loi de Poisson de
paramètre <span class="math inline">\(\lambda=np\)</span>, en effet
<span class="math display">\[\text{si} \; n \rightarrow \infty \; \text{et}\; p \rightarrow 0 \; \text{alors} \; X: \mathcal{B}(n, p) \rightarrow \mathcal{P}(\lambda).\]</span></p>
<p>Une bonne approximation est obtenue si <span class="math inline">\(n \geq 50\)</span> et <span class="math inline">\(np \leq 5\)</span>.</p>
<p>Dans ce contexte, la loi de Poisson est souvent utilisée pour modéliser
le nombre de succès lorsqu’on répète un très grand nombre de fois une
expérience ayant une chance très faible de réussir par une loi de
Poisson (nombre de personnes dans la population française atteints d’une
maladie rare, par exemple).</p>
<p>On cherche la probabilité de trouver au moins un centenaire parmi 200
personnes dans une population où une personne sur cent est un
centenaire.</p>
<p>La probabilité <span class="math inline">\(p=1/100=0.01\)</span> étant faible et <span class="math inline">\(n=200\)</span> étant suffisamment
grand, on peut modéliser le nombre <span class="math inline">\(X\)</span> de centenaires pris parmi 200
personnes par la loi de Poisson de paramètre
<span class="math inline">\(\lambda=200 \times 0.01=2\)</span>. Donc on a:
<span class="math display">\[P(X\geq 1)=1-P(X=0)=1-e^{-2}\simeq 0.86\]</span></p>
<p>Soit une v.a. <span class="math inline">\(X\)</span> telle que <span class="math inline">\(X \sim \mathcal{B}(100, 0.01)\)</span>, les valeurs
des probabilités pour <span class="math inline">\(k\)</span> de 0 à 5 ainsi que leur approximation à
<span class="math inline">\(10^{-3}\)</span> avec une loi de Poisson de paramètre <span class="math inline">\(\lambda= np =1\)</span> sont
données dans le tableau ci-dessous :</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(k\)</span></th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
<th align="center">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(P(X = k)\)</span></td>
<td align="center">0.366</td>
<td align="center">0.370</td>
<td align="center">0.185</td>
<td align="center">0.061</td>
<td align="center">0.015</td>
<td align="center">0.000</td>
</tr>
<tr class="even">
<td align="center">Approximation</td>
<td align="center">0.368</td>
<td align="center">0.368</td>
<td align="center">0.184</td>
<td align="center">0.061</td>
<td align="center">0.015</td>
<td align="center">0.003</td>
</tr>
</tbody>
</table>
<p>Dans le cas de cet exemple où <span class="math inline">\(n =100\)</span> et <span class="math inline">\(np =1\)</span>, l’approximation de la
loi binomiale par une loi de poisson donne des valeurs de probabilités
identiques à <span class="math inline">\(10^{-3}\)</span> près.</p>
</div>
<div id="loi-géométrique-ou-de-pascal-mathcalgp" class="section level2 unnumbered">
<h2>Loi Géométrique ou de Pascal <span class="math inline">\(\mathcal{G}(p)\)</span></h2>
<p>On effectue des épreuves successives indépendantes jusqu’à la
réalisation d’un événement particulier <span class="math inline">\(A\)</span> de probabilité <span class="math inline">\(p=P(A)\)</span> et on
note <span class="math inline">\(X\)</span> le nombre aléatoire d’épreuves effectuées. On définit ainsi une
v.a. à valeurs entières de loi géométrique, ou de Pascal. A chaque
épreuve est associé l’ensemble fondamental <span class="math inline">\(\Omega=\{A, \bar{A}\}\)</span> et
l’événement <span class="math inline">\(\{X=k\}\)</span> pour <span class="math inline">\(k\in \mathbb{N^*}\)</span> est représenté par une
suite de <span class="math inline">\(k-1\)</span> événements <span class="math inline">\(\bar{A}\)</span>, terminée par l’événement <span class="math inline">\(A\)</span>:
<span class="math display">\[\underbrace{\bar{A}\bar{A}\ldots \bar{A}}_{k-1}A\]</span> D’où:</p>
<p><span class="math display" id="eq:geom">\[\begin{equation}
    P(X=k)=(1-p)^{k-1}p \quad \forall \, k \in \mathbb{N^*}
    \tag{3.3}
\end{equation}\]</span>
Cette loi peut servir à modéliser des temps de vie, ou des temps
d’attente, lorsque le temps est mesuré de manière discrète (nombre de
jours par exemple).</p>
<p>En utilisant la série entière <span class="math display">\[\label{eq:serie_entiere}
        \sum_{k=0}^\infty x^k = 1/(1-x) \quad \text{pour} \quad |x|&lt;1\]</span>
on vérifie bien que c’est une loi de probabilité:</p>
<p><span class="math display">\[\begin{aligned}
\sum_{k=1}^\infty P(X=k)&amp;= \sum_{k=1}^\infty (1-p)^{k-1}p = p \sum_{j=0}^\infty (1-p)^{j} \\
&amp;= p \frac{1}{1-(1-p)}=1\end{aligned}\]</span></p>
<p><strong>Moments de loi Géométrique</strong></p>
<p>En dérivant la série entière
<a href="lois-usuelles-discrètes.html#eq:geom">(3.3)</a> ci-dessus, on obtient
<span class="math inline">\(\sum_{k=1}^\infty k x^{k-1}=1/(1-x)^2\)</span>. Ceci permet d’obtenir
l’espérance:
<span class="math display">\[E(X)=\sum_{k=1}^\infty kp(1-p)^{k-1}=\frac{p}{[1-(1-p)]^2}=\frac{1}{p}\]</span></p>
<ul>
<li>En d’autres termes, si des épreuves indépendantes ayant une
probabilité <span class="math inline">\(p\)</span> d’obtenir un succès sont réalisés jusqu’à ce que le
premier succès se produise, le nombre espéré d’essais nécessaires
est égal à <span class="math inline">\(1/p\)</span>. Par exemple, le nombre espéré de jets d’un dé
équilibré qu’il faut pour obtenir la valeur 1 est 6.</li>
</ul>
<p>Le calcul de la variance se fait à partir du moment factoriel et en
utilisant la dérivée seconde de la série entière
<a href="lois-usuelles-discrètes.html#eq:geom">(3.3)</a>:
<span class="math inline">\(\sum_{k=2}^\infty k(k-1) x^{k-2} = 2/(1-x)^3\)</span>, Donc</p>
<p><span class="math display">\[\begin{aligned}
E[X(X-1)]&amp;=\sum_{k=2}^\infty k(k-1)p(1-p)^{k-1} \\ &amp;= p(1-p)\sum_{k=2}^\infty k(k-1)(1-p)^{k-2} \\
&amp;=  \frac{2p(1-p)}{[1-(1-p)]^3}=\frac{2(1-p)}{p^2}\end{aligned}\]</span> d’où
on déduit: <span class="math display">\[V(X)=E[X(X-1)]+E(X)-E^2(X)=\frac{1-p}{p^2}.\]</span></p>
<p>Si l’on considère la variable aléatoire <span class="math inline">\(X\)</span> “nombre de naissances
observées jusqu’à l’obtention d’une fille” avec p = 1/2 (même
probabilité de naissance d’une fille ou d’un garçon), alors X suit une
loi géométrique et on a pour tout <span class="math inline">\(k\in \mathbb{N^*}\)</span>:
<span class="math display">\[P(X=k)=(1-1/2)^{k-1}(1/2)=1/2^k\]</span> avec <span class="math inline">\(E(X)=2\)</span> et <span class="math inline">\(V(X)=2.\)</span></p>
</div>
<div id="loi-binomiale-négative-mathcalbnrp" class="section level2 unnumbered">
<h2>Loi Binomiale Négative <span class="math inline">\(\mathcal{BN}(r,p)\)</span></h2>
<ul>
<li><p><span class="math inline">\(\varepsilon\)</span>: “On répéte l’épreuve de Bernoulli jusqu’à obtenir
un total de <span class="math inline">\(r\)</span> succès”.</p></li>
<li><p>Exemple avec :
<span class="math display">\[\bar{A} \quad  {A} \quad  \bar{A} \quad  \bar{A} \quad  \bar{A} \quad  {A} \quad \bar{A} \quad  \bar{A} \quad  {A}\]</span>
<span class="math display">\[{E} \quad  {S} \quad  {E} \quad  {E} \quad  {E} \quad  {S} \quad {E} \quad  {E} \quad  {S}\]</span></p></li>
<li><p>Mais on peut obtenir d’autres façons:
<span class="math display">\[{S} \quad  {E} \quad  {E} \quad  {E} \quad  {E} \quad  {E} \quad {S} \quad  {E} \quad  {S}\]</span>
<span class="math display">\[{E} \quad  {E} \quad  {E} \quad  {E} \quad  {S} \quad  {E} \quad {S} \quad  {E} \quad  {S}\]</span></p></li>
<li><p>Chaque épreuve a <span class="math inline">\({p}\)</span> pour probabilité de
succès et <span class="math inline">\({1-p}\)</span> pour probabilité d’échec.</p></li>
<li><p>Désignons <span class="math inline">\(X=\)</span>“le nombre d’épreuves nécessaires pour atteindre ce résultat”.
<span class="math display">\[\underbrace{\overbrace{{E} \quad  {S} \quad  {E} \quad  {E} \quad  {E} \quad  {S} \quad {E} \quad  {E}}^{ {r-1 \, succès}\, et \, {k-r \, échecs}} \quad  {S}}_{X=k}\]</span></p></li>
<li><p><span class="math inline">\(X(\Omega)=\{r,r+1,r+2,\ldots\}\)</span>. On dit <span class="math inline">\(X \sim \mathcal{BN}(r,p)\)</span>.</p></li>
<li><p><span class="math inline">\(\forall \, k \in X(\Omega),\)</span>
<span class="math display">\[P(X=k) = \binom{{k-1}}{{r-1}} {p^r} {(1-p)^{k-r}}\]</span></p></li>
</ul>
<div id="mathcalgpmathcalbn1p" class="section level3 unnumbered">
<h3><span class="math inline">\(\mathcal{G}(p)=\mathcal{BN}(1,p)\)</span></h3>
<ul>
<li><p><span class="math inline">\(\varepsilon\)</span>: “On répéte l’épreuve de Bernoulli jusqu’à obtenir
un total de <span class="math inline">\(r\)</span> succès”.</p></li>
<li><p>Soit,
<span class="math display">\[{E} \quad \ldots \quad {E} \quad {S} \quad  {E} \quad  \ldots \quad  {E} \quad  {S} \ldots \quad {E} \ldots \quad  {E} \quad  {S}\]</span></p></li>
<li><p>Soit, <span class="math inline">\(Y_1\)</span> le nombre d’épreuves nécessaires jusqu’au premier
succès, <span class="math inline">\(Y_2\)</span> le nombre d’épreuves supplémentaires nécessaires pour
obtenir un deuxième succès, <span class="math inline">\(Y_3\)</span> celui menant au 3ème et ainsi de
suite.</p></li>
<li><p>Càd,
<span class="math display">\[\underbrace{{E} \quad \ldots \quad {E} \quad {S}}_{Y_1} \quad  \underbrace{{E} \quad  \ldots \quad  {E} \quad  {S}}_{Y_2} \quad \underbrace{\ldots}_{\ldots} \quad \underbrace{{E} \quad \ldots \quad  {E} \quad  {S}}_{Y_r}\]</span></p></li>
<li><p>Les tirages étants indépendantes et ayant toujours la même
probabilité de succès, chacune des variables <span class="math inline">\(Y_1,Y_2,\ldots,Y_r\)</span>
est géométrique <span class="math inline">\(\mathcal{G}(p)\)</span>.</p></li>
<li><p><span class="math inline">\(X=\)</span>“le nombre d’épreuves nécessaires à l’obtention de <span class="math inline">\(r\)</span>
succès”<span class="math inline">\(=Y_1 + Y_2 + \ldots + Y_r\)</span>.</p></li>
<li><p>Donc,
<span class="math display">\[E(X)= E(Y_1) + E(Y_2) + \ldots + E(Y_r) = \sum_{i=1}^r \frac{1}{p} = \frac{r}{p}\]</span>
et <span class="math display">\[V(X)= \sum_{i=1}^r V(Y_i) = \frac{r(1-p)}{p^2}\]</span> car les <span class="math inline">\(Y_i\)</span>
sont indépendantes.</p></li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="couple-de-variables-aléatoires-discrètes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="feuille-dexercices-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
