[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Overview\nWelcome! In this course you will learn about the state of the art of Machine Learning and also gain practice implementing and deploying machine learning algorithms.\nThis course is destined for students of Data Science Fili√®re in EFREI Paris engineering school. In Data Science Fili√®re there is the following master programs:\nThe aim of Machine Learning is to build computer systems that can adapt to their environments and learn from experience. Learning techniques and methods from this field are successfully applied to a variety of learning tasks in a broad range of areas, including, for example, spam recognition, text classification, gene discovery, financial forecasting. The course will give an overview of many concepts, techniques, and algorithms in machine learning, beginning with topics such as regression and classification. The course will give you the basic ideas and intuition behind these methods, as well as a more formal statistical and computational understanding. You will have an opportunity to experiment with machine learning techniques in Python and apply them to a selected problem."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Machine Learning",
    "section": "Schedule",
    "text": "Schedule\n\n\n\nSession\nTopic\nSlides\nLab\n\n\n\n\n1\nIntroduction to ML  Regression\nüìñ\nüíª\n\n\n2\nClassification: Logistic Regression & Regularization\nüìñ\nüíª\n\n\n3\nDecision Trees & Random Forests\nüìñ\nüíª\n\n\n4\nIntroduction to Neural Networks & Deep Learning\nüìñ\nüíª\n\n\n5\nChallenge\n\nüíª"
  },
  {
    "objectID": "TD1.html#python-environment",
    "href": "TD1.html#python-environment",
    "title": "Lab1: Linear Regression",
    "section": "Python environment",
    "text": "Python environment\n\n\n\n\n\n\nAnaconda\n\n\n\nDuring this course we are going to use Python as programming language. Anaconda is an open-source distribution for Python. It is used for data science, machine learning, deep learning, etc. It comes with more than 300 libraries for data science. Anaconda helps in simplified package management and deployment.\nTo install it, go to Anaconda website.\nRemark: if you have a Mac with M1 ship, you must install the 2022.05 release of Anaconda: (Anaconda Distribution Now Supporting M1).\n\n\n\n\n\n\n\n\nJupyter\n\n\n\nDuring the labs, you must use Jupyter notebooks. The Jupyter Notebook is the original web application for creating and sharing computational documents. It offers a simple, streamlined, document-centric experience. Jupyter is installed by default when you install Anaconda. You can create notebooks using JupyterLab via your browser or using a text editor like VScode."
  },
  {
    "objectID": "TD1.html#predicting-house-value-boston-dataset",
    "href": "TD1.html#predicting-house-value-boston-dataset",
    "title": "Lab1: Linear Regression",
    "section": "Predicting House Value: Boston dataset",
    "text": "Predicting House Value: Boston dataset\nIn this lab we are going to use a dataset called Boston. It records the median value of houses for 506 neighborhoods around Boston. Our task is to predict the median house value.\nLoading Data\n\n\n\n\n\n\nBoston dataset\n\n\n\nThe dataset is available in scikit-learn or also here üîó. Notice that the format/approach is not the same. You are free to use any of them, it is up to you to adapt your codes correctly.\nThere is mainly two approaches you need to know for instance:\n\nThe features and the target variable are in the same dataframe. In this case you can use the argument formula = target ~ features in certain fitting functions (like in ols(), imitating R‚Äôs programming language functions).\nThe features and the target variable are separated in X and y.\n\n\n\n\n1. Load these necessary libraries for this lab (install them if needed).\n\nimport numpy as np\nimport matplotlib.pyplot as plt \n\nimport pandas as pd  \nimport seaborn as sns \n\n# Run the following line to obtain the matplotlib figures in the notebook\n%matplotlib inline\n\n# We will also use sklearn but we will load the necessary modules when needed\n\n2. Load the Boston dataset.\n\nfrom sklearn.datasets import load_boston\nboston_dataset = load_boston()\n\n\n\n\n\n\n\nImportant\n\n\n\nThe Boston housing prices dataset has an ethical problem: as investigated in [1], the authors of this dataset engineered a non-invertible variable ‚ÄúB‚Äù assuming that racial self-segregation had a positive impact on house prices [2]. Furthermore the goal of the research that led to the creation of this dataset was to study the impact of air quality but it did not give adequate demonstration of the validity of this assumption.\nThe scikit-learn maintainers therefore strongly discourage the use of this dataset unless the purpose of the code is to study and educate about ethical issues in data science and machine learning.\nThe dataset is removed from scikit_learn version 1.2. If you want to use it you can install the earlier version of scikit-learn. Run this code from your jupyter notebook:\n\n!pip install scikit-learn==1.1.3\n\n[1] Racist data destruction? M Carlisle.\n[2] Harrison Jr, David, and Daniel L. Rubinfeld. ‚ÄúHedonic housing prices and the demand for clean air.‚Äù Journal of environmental economics and management 5.1 (1978): 81-102.\n\n\n3. Print the value of the boston_dataset to understand what it contains.\n\nprint(boston_dataset.keys())\n\ndict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])\n\n\n\ndata: contains the information for various houses\ntarget: prices of the house\nfeature_names: names of the features\nDESCR: describes the dataset\n\nTo know more about the features run boston_dataset.DESCR.\nThe prices of the house indicated by the variable MEDV is our target variable and the remaining are the feature variables based on which we will predict the median value of houses in a district.\n3. Load the data into a pandas dataframe using pd.DataFrame. Then print the first 5 rows of the data using head().\n\nboston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\nboston.head()\n\n      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n\n[5 rows x 13 columns]\n\n\nWe can see that the target value MEDV is missing from the data. We create a new column of target values and add it to the dataframe.\n\nboston['MEDV'] = boston_dataset.target\n\nRemark: the previous steps were avoidable if we loaded the data from csv given above using pd.read_csv()."
  },
  {
    "objectID": "TD1.html#data-preprocessing",
    "href": "TD1.html#data-preprocessing",
    "title": "Lab1: Linear Regression",
    "section": "Data preprocessing",
    "text": "Data preprocessing\n4. Check if there are any missing values in the data.\nExploratory Data Analysis\nExploratory Data Analysis is a very important step before training the model. In this section, we will use some visualizations to understand the relationship of the target variable with other features.\n5. Plot the distribution of the target variable MEDV. You can use the distplot() function from the seaborn library.\n6. Calculate the correlation matrix and visualize it (you may use heatmap() from seaborn library). Name the features that are highly correlated with the target variable.\n\n\n\n\n\n\nCorrelation\n\n\n\nThe correlation coefficient ranges from -1 to 1. If the value is close to 1, it means that there is a strong positive correlation (linear tendency) between the two variables. When it is close to -1, the variables have a strong negative correlation.\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor a linear regression model, we select the features which have a high correlation with the target variable. Anyway there is some feature selection techniques you may use, one of them is Backward selection:\nBackward selection:\n\nStart with all variables in the model.\nRemove the variable with the largest p-value ‚Äî that is, the variable that is the least statistically significant.\nThe new \\((p ‚àí 1)\\)-variable model is fit, and the variable with the largest p-value is removed.\nContinue until a stopping rule is reached. For instance, we may stop when all remaining variables have a significant p-value defined by some significance threshold.\n\n\n\n7. Check for multi-collinearity between the features. More specifically RAD and TAX.\n\n\n\n\n\n\nTip\n\n\n\nWe should not select collinear features together for training the model. Check this link for one explanation.\n\n\nSplitting the data into training and testing sets\nTrain test split is a model validation procedure that allows you to simulate how a model would perform on new/unseen data. Here is how the procedure works:\n\n8. Split the data into training and testing sets. We are going to train the model with 80% of the samples and test with the remaining 20%. Use train_test_split() function provided by scikit-learn library\n\nfrom sklearn.model_selection import train_test_split\n\n# complete the code\nX = ...\nY = ...\n\nX_train, X_test, Y_train, Y_test = ...(, , test_size = ..., random_state=5)\n\n# print the shapes to verify if the splitting has occured properly\nprint(X_train.shape)\nprint(X_test.shape)\nprint(Y_train.shape)\nprint(Y_test.shape)"
  },
  {
    "objectID": "TD1.html#simple-linear-regression-model",
    "href": "TD1.html#simple-linear-regression-model",
    "title": "Lab1: Linear Regression",
    "section": "\nSimple Linear Regression model",
    "text": "Simple Linear Regression model\nIn this part, we are going to build a simple linear regression model. We will choose LSTAT as a feature.\n9. Plot MEDV in function of LSTAT.\n10. Fit a simple regression model using LinearRegression() from sklearn.linear_model.\n\nfrom sklearn.linear_model import LinearRegression\n\nslm = LinearRegression()\nslm.fit(..., ...)\n\n11. The LinearRegression() module from scikit-learn does not provide a statistical summary of the regression model. To obtain this summary, re-fit a model using ols() from statsmodels. Analyse the p-value from the summary and interpret.\n12. Plot the regression model.\nModel evaluation\n13. Evaluate the model using MSE (Mean Squarred Error) and R2-score.\n\nfrom sklearn.metrics import mean_squared_error\n\n# train error (MSE)\ny_train_predict = slm.predict(...)\nmse_train = ...(..., ...)\n\nprint(\"The model performance for training set\")\n\nprint('MSE is {}'.format(mse_train))\n\n\n# test error\ny_test_predict = slm.predict(...)\nmse_test = mean_squared_error(..., ...)\nr2 = r2_score(..., ...)\n\nprint(\"The model performance for testing set\")\n\nprint('MSE is {}'.format(mse_test))\nprint('R2 score is {}'.format(r2))\n\n14. According to the plot in 9, the relationship between LSTAT and MEDV is not linear. Let‚Äôs try a transformation of our explanatory variable LSTAT. Re-do the steps from 9 to 13 but using the log of LSTAT. Do you obtain a better model?"
  },
  {
    "objectID": "TD1.html#multiple-linear-regression-model",
    "href": "TD1.html#multiple-linear-regression-model",
    "title": "Lab1: Linear Regression",
    "section": "Multiple Linear Regression model",
    "text": "Multiple Linear Regression model\n15. Train a new model using all the variables of the dataset. Evalute the performance of the model.\n16. Which features are significant for the model?\n17. Apply backward selection to fit a model with the best subset of features.\n18. Is the new model better than the last one with all the features?\n19. In the last model we didn‚Äôt transform LSTAT. Re train the model using log(LSTAT) instead of LSTAT. Does this new model performs better?"
  },
  {
    "objectID": "TD1.html#anova-analysis-of-variances",
    "href": "TD1.html#anova-analysis-of-variances",
    "title": "Lab1: Linear Regression",
    "section": "ANOVA (ANalysis Of VAriances)",
    "text": "ANOVA (ANalysis Of VAriances)\nIn this last part we will apply an analysis of variances (ANOVA) in order to test if there is a significant difference of means between two groups \\(i\\) and \\(j\\) (Consider group \\(i\\) is the suburbs bounding the river and \\(j\\) the suburbs which not). The hypotheses are\n\\[ H_0 : \\mu_i = \\mu_j \\]\n\\[ H_1 : \\mu_i \\neq \\mu_j \\]\nWhere \\(\\mu_i\\) is the mean of MEDV in group \\(i\\).\n\n\n\n\n\n\nAnova\n\n\n\nThis analysis can be conducted during the exploratory data analysis part especially when the target is continuous and a feature is discrete.\n\n\n20. In the Boston data set there is a categorical variable CHAS which corresponds to Charles River (= 1 if a suburb bounds the river; 0 otherwise). How many of the suburbs in this data set bound the Charles river?\n21. Create Boxplots of the median value of houses with respect to the variable CHAS. Do we observe some difference between the median value of houses with respect to the neighborhood to Charles River?\n22. Calculate \\(\\mu_i\\) and \\(\\mu_j\\).\n23. Apply an ANOVA test of MEDV with respect to CHAS. What do you conclude ?"
  },
  {
    "objectID": "TD1.html#extra",
    "href": "TD1.html#extra",
    "title": "Lab1: Linear Regression",
    "section": "Extra",
    "text": "Extra\nFit your chosen multiple linear regression model from scratch, using:\n\nNormal equation\nGradient descent\n\nCompare their performance in term of accuracy and speed. Compare them to Scikit-learn‚Äôs algorithm performance."
  },
  {
    "objectID": "TD2.html#introduction",
    "href": "TD2.html#introduction",
    "title": "Lab2: Logistic Regression & Regularization",
    "section": "Introduction",
    "text": "Introduction\nIn this lab, you will implement logistic regression and apply it to two different datasets.\nBefore we begin with the exercises, we need to import all libraries required for this programming exercise. Throughout the course, we will be using numpy for all arrays and matrix operations, and matplotlib for plotting. In this assignment, we will also use scipy, which contains scientific and numerical computation functions and tools.\n\n# Scientific and vector computation for python\nimport numpy as np\n\n# Plotting library\nimport matplotlib.pyplot as plt\n\n# Optimization module in scipy\nfrom scipy import optimize\n\n# do not forget to tell matplotlib to embed plots within the notebook\n%matplotlib inline"
  },
  {
    "objectID": "TD2.html#logistic-regression",
    "href": "TD2.html#logistic-regression",
    "title": "Lab2: Logistic Regression & Regularization",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nIn this part of the exercise, you will build a logistic regression model to predict whether a student gets admitted into a university. Suppose that you are the administrator of a university department and you want to determine each applicant‚Äôs chance of admission based on their results on two exams. You have historical data from previous applicants that you can use as a training set for logistic regression. For each training example, you have the applicant‚Äôs scores on two exams and the admissions decision.\nYour task is to build a classification model that estimates an applicant‚Äôs probability of admission based the scores from those two exams.\n1. Load the data tp2data1.txt from here  using the loadtxt() from numpy. The first two columns contains the exam scores and the third column contains the label. Then separate the features from label. Name the feature matrix X and the label y.\n2. Print the first 5 samples from X and y.\nVisualizing the data\n3. Display the data on a 2-dimensional plot where the axes are the two exam scores, and the positive and negative examples are shown with different colors (or markers).\nYou should produce something like this:\n\n\n\n\n\nImplementation\nSigmoid function\nRecall that the logistic regression hypothesis is defined as:\n\\[ h_\\omega(x) = g(\\omega^T x)\\]\nwhere function \\(g\\) is the sigmoid function. The sigmoid function is defined as:\n\\[g(z) = \\frac{1}{1+e^{-z}}\\]\n4. Implement the sigmoid function so it can be called by the rest of your program. When you are finished, try testing a few values by calling sigmoid(x) in a new cell. For large positive values of x, the sigmoid should be close to 1, while for large negative values, the sigmoid should be close to 0. Evaluating sigmoid(0) should give you exactly 0.5. Your code should also work with vectors and matrices. For a matrix, your function should perform the sigmoid function on every element.\n5. Plot the sigmoid function, like this:\n\n\n\n\n\nCost function and gradient\n6. Before proceeding, add the intercept term to X. (hint: you can use np.concatenate or np.hstack)\n7. Implement the cost function and its gradient for logistic regression.\nRecall that the cost function for logistic regression is\n\\[ J(\\omega) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ -y^{(i)} \\log\\left(h_\\omega\\left( x^{(i)} \\right) \\right) - \\left( 1 - y^{(i)}\\right) \\log \\left( 1 - h_\\omega\\left( x^{(i)} \\right) \\right) \\right]\\]\nRecall that the gradient of the cost is a vector of the same length as \\(\\omega\\) where the \\(j^{th}\\) element (for \\(j = 0, 1, \\cdots , n\\)) is defined as follows:\n\\[ \\frac{\\partial J(\\omega)}{\\partial \\omega_j} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\omega \\left( x^{(i)} \\right) - y^{(i)} \\right) x_j^{(i)} \\]\n8. Call your implemented function using two test cases for \\(\\omega\\). You should see that the cost is about \\(0.693\\) for \\(\\omega = (0,0,0)\\).\nLearning the parameters\nLearning parameters using your implemented Gradient Descent\n9. Implement the gradient descent algorithm for logistic regression: write a cost function and calculate its gradient, then take a gradient descent step accordingly in order to find the optimal parameters. Run it on the training set. Print the results (the parameters values and the cost function).\nLearning parameters using scipy.optimize\nIn this part you will use the scipy.optimize module. SciPy is a numerical computing library for python. It provides an optimization module for root finding and minimization. As of scipy 1.0, the function scipy.optimize.minimize is the method to use for optimization problems(both constrained and unconstrained).\nFor logistic regression, you want to optimize the cost function \\(J(\\omega)\\) with parameters \\(\\omega\\). Concretely, you are going to use optimize.minimize to find the best parameters \\(\\omega\\) for the logistic regression cost function, given a fixed dataset (of X and y values). You will pass to optimize.minimize the following inputs:\n\n\ncostFunction: A cost function that, when given the training set and a particular \\(\\omega\\), computes the logistic regression cost and gradient with respect to \\(\\omega\\) for the dataset (X, y). It is important to note that we only pass the name of the function without the parenthesis. This indicates that we are only providing a reference to this function, and not evaluating the result from this function.\n\ninitial_omega: The initial values of the parameters we are trying to optimize.\n\n(X, y): These are additional arguments to the cost function.\n\njac: Indication if the cost function returns the Jacobian (gradient) along with cost value. (True)\n\nmethod: Optimization method/algorithm to use\n\noptions: Additional options which might be specific to the specific optimization method. In the following, we only tell the algorithm the maximum number of iterations before it terminates.\n\nIf you have calculated the cost function correctly, optimize.minimize will converge on the right optimization parameters and return the final values of the cost and \\(\\omega\\) in a class object. Notice that by using optimize.minimize, you did not have to write any loops yourself, or set a learning rate like you did for gradient descent. This is all done by optimize.minimize: you only needed to provide a function calculating the cost and the gradient.\nIn the following, a code written to call optimize.minimize with the correct arguments.\n\n# set options for optimize.minimize\noptions= {'maxiter': 400}\n\n# see documention for scipy's optimize.minimize  for description about\n# the different parameters\n# The function returns an object `OptimizeResult`\n# We use truncated Newton algorithm for optimization which is \n# equivalent to MATLAB's fminunc\n# See https://stackoverflow.com/questions/18801002/fminunc-alternate-in-numpy\n\n# initial_omega = np.array([0, 0, 0])\n\nres = optimize.minimize(costFunction,\n                        initial_omega,\n                        (X_train, y),\n                        jac=True,\n                        method='TNC',\n                        options=options)\n\n# the fun property of `OptimizeResult` object returns\n# the value of costFunction at optimized omega\ncost = res.fun\n\n# the optimized omega is in the x property\nomega = res.x\n\n# Print omega to screen\nprint('Cost at omega found by optimize.minimize: {:.3f}'.format(cost))\nprint('Expected cost (approx): 0.203\\n');\n\nprint('omega:')\nprint('\\t[{:.3f}, {:.3f}, {:.3f}]'.format(*omega))\nprint('Expected omega (approx):\\n\\t[-25.161, 0.206, 0.201]')\n\n10. Run the code above on your cost function and verify that you obtain the correct (or almost) values.\nPlotting the decision boundary\nSince the decision boundary of logistic regression is a linear (you know that right?) and the dimension of the feature space here is 2, the decision boundary in this 2-dimensional space is a line that separates the predicted classes ‚Äú0‚Äù and ‚Äú1‚Äù.\nFor logistic regression, we predict \\(y=1\\) if \\(\\omega^T X \\geq 0\\) (right side of the line) and \\(y=0\\) if \\(\\omega^T X \\lt 0\\) (left side of the line). Where\n\\[\n\\omega = \\begin{pmatrix} \\omega_0 \\\\ \\omega_1 \\\\ \\omega2 \\end{pmatrix} \\,\\, \\text{and} \\,\\, X = \\begin{pmatrix}\n  1 \\\\\n  X_1 \\\\\n  X_2\n  \\end{pmatrix}\n\\]\nSo we predict \\(y=1\\) if \\(\\omega_0 + \\omega_1 X_1 + \\omega_2 X_2 \\geq 0\\) which means that the equation of the decision boundary (a line here) is \\(X_2 = - \\frac{\\omega_1}{\\omega_2}X_1 - \\frac{\\omega_0}{\\omega_2}\\)\n11. Plot the decision boundary obtained with logistic regression.\nEvaluating logistic regression\n12. After learning the parameters, you can use the model to predict whether a particular student will be admitted. For a student with an Exam 1 score of 45 and an Exam 2 score of 85, you should expect to see an admission probability of 0.776. Another way to evaluate the quality of the parameters we have found is to see how well the learned model predicts on our training set. Write a function predict that will produce ‚Äú1‚Äù or ‚Äú0‚Äù predictions given a dataset and a learned parameter vector \\(\\omega\\).\n13. Calculate the confusion matrix, and use it to calculate the training accuracy of your classifier and the F1 score.\n14. In order to verify that your line (decision boundary) is well plotted, color the points on the last Figure with respect to the predicted response.\n15. Now make the same plot but color the points with respect to their real labels. From this figure, count the number of the false positive predictions.\nplotDecisionBoundary function\nFor the rest, use the following function (or modify it to adapt it) for plotting the decision boundary.\n\ndef plotDecisionBoundary(omega, X, y):\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n                         np.arange(y_min, y_max, 0.1))\n    X_plot = np.c_[xx.ravel(), yy.ravel()]\n    X_plot = np.hstack((np.ones((X_plot.shape[0], 1)), X_plot))\n    y_plot = np.dot(X_plot, omega).reshape(xx.shape)\n    \n    plt.figure()\n    plt.scatter(X[y == 1][:, 0], X[y == 1][:, 1], label=\"Admitted\")\n    plt.scatter(X[y == 0][:, 0], X[y == 0][:, 1], label=\"Not admitted\")\n    plt.contour(xx, yy, y_plot, levels=[0])\n    plt.xlabel(\"Exam 1 score\")\n    plt.ylabel(\"Exam 2 score\")\n    plt.legend()\n    plt.show()\n\n\nplotDecisionBoundary(res.x, X, y)"
  },
  {
    "objectID": "TD2.html#regularized-logistic-regression",
    "href": "TD2.html#regularized-logistic-regression",
    "title": "Lab2: Logistic Regression & Regularization",
    "section": "Regularized logistic regression",
    "text": "Regularized logistic regression\nIn this part of the exercise, you will implement regularized logistic regression to predict whether microchips from a fabrication plant passes quality assurance (QA). During QA, each microchip goes through various tests to ensure it is functioning correctly.\nSuppose you are the product manager of the factory and you have the test results for some microchips on two different tests. From these two tests, you would like to determine whether the microchips should be accepted or rejected. To help you make the decision, you have a dataset of test results on past microchips, from which you can build a logistic regression model.\n2.1. Load the data in file tp2data2.txt from from here . Separate the features from the labels in two differents objects.\n2.2. Visualize the data in a 2-dimensional plot. Color the point with respect to their labels. What do you notice ?\nFeature mapping\nOne way to fit the data better is to create more features from each data point. In the function mapFeature defined below, we will map the features into all polynomial terms of \\(x_1\\) and \\(x_2\\) up to the sixth power.\n\\[\\text{mapFeature}(x) = \\begin{bmatrix} 1 & x_1 & x_2 & x_1^2 & x_1 x_2 & x_2^2 & x_1^3 & \\dots & x_1 x_2^5 & x_2^6 \\end{bmatrix}^T\\]\n\ndef mapFeature(X1, X2, degree=6):\n    \"\"\"\n    Maps the two input features to quadratic features used in the regularization exercise.\n\n    Returns a new feature array with more features, comprising of\n    X1, X2, X1.^2, X2.^2, X1*X2, X1*X2.^2, etc..\n\n    Parameters\n    ----------\n    X1 : array_like\n        A vector of shape (m, 1), containing one feature for all examples.\n\n    X2 : array_like\n        A vector of shape (m, 1), containing a second feature for all examples.\n        Inputs X1, X2 must be the same size.\n\n    degree: int, optional\n        The polynomial degree.\n\n    Returns\n    -------\n    : array_like\n        A matrix of of m rows, and columns depend on the degree of polynomial.\n    \"\"\"\n    if X1.ndim &gt; 0:\n        out = [np.ones(X1.shape[0])]\n    else:\n        out = [np.ones(1)]\n\n    for i in range(1, degree + 1):\n        for j in range(i + 1):\n            out.append((X1 ** (i - j)) * (X2 ** j))\n\n    if X1.ndim &gt; 0:\n        return np.stack(out, axis=1)\n    else:\n        return np.array(out)\n\nAs a result of this mapping, our vector of two features (the scores on two QA tests) has been transformed into a 28-dimensional vector. A logistic regression classifier trained on this higher-dimension feature vector will have a more complex decision boundary and will appear nonlinear when drawn in our 2-dimensional plot.\nWhile the feature mapping allows us to build a more expressive classifier, it also more susceptible to overfitting.\nIn the next parts of the exercise, you will implement regularized logistic regression to fit the data and also see for yourself how regularization can help combat the overfitting problem.\n2.3. Apply the mapFeature() function on the dataset. Verify that you get a 28-dimensional vector.\nCost function and gradient\nRecall that the regularized cost function in logistic regression is\n\\[ J(\\omega) = \\frac{1}{m} \\sum_{i=1}^m \\left[ -y^{(i)}\\log \\left( h_\\omega \\left(x^{(i)} \\right) \\right) - \\left( 1 - y^{(i)} \\right) \\log \\left( 1 - h_\\omega \\left( x^{(i)} \\right) \\right) \\right] + \\frac{\\lambda}{2m} \\sum_{j=1}^n \\omega_j^2 \\]\nNote that we do not regularize the parameters \\(\\omega_0\\). The gradient of the cost function is a vector where the \\(j^{th}\\) element is defined as follows:\n\\[ \\frac{\\partial J(\\omega)}{\\partial \\omega_0} = \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\omega \\left(x^{(i)}\\right) - y^{(i)} \\right) x_j^{(i)} \\qquad \\text{for } j =0 \\]\n\\[ \\frac{\\partial J(\\omega)}{\\partial \\omega_j} = \\left( \\frac{1}{m} \\sum_{i=1}^m \\left( h_\\omega \\left(x^{(i)}\\right) - y^{(i)} \\right) x_j^{(i)} \\right) + \\frac{\\lambda}{m}\\omega_j \\qquad \\text{for } j \\ge 1 \\]\n2.4. Complete the function costFunctionReg() below. This function computes and returns the cost function and gradient for regularized logistic regression.\n\ndef costFunctionReg(omega, X, y, lambda_):\n    \"\"\"\n    Compute cost and gradient for logistic regression with regularization.\n    \n    Parameters\n    ----------\n    omega : array_like\n        Logistic regression parameters. A vector with shape (n, ). n is \n        the number of features including any intercept. If we have mapped\n        our initial features into polynomial features, then n is the total \n        number of polynomial features. \n    \n    X : array_like\n        The data set with shape (m x n). m is the number of examples, and\n        n is the number of features (after feature mapping).\n    \n    y : array_like\n        The data labels. A vector with shape (m, ).\n    \n    lambda_ : float\n        The regularization parameter. \n    \n    Returns\n    -------\n    J : float\n        The computed value for the regularized cost function. \n    \n    grad : array_like\n        A vector of shape (n, ) which is the gradient of the cost\n        function with respect to omega, at the current values of omega.\n    \n    Instructions\n    ------------\n    Compute the cost `J` of a particular choice of omega.\n    Compute the partial derivatives and set `grad` to the partial\n    derivatives of the cost w.r.t. each parameter in omega.\n    \"\"\"\n    # Initialize some useful values\n    m = y.size  # number of training examples\n\n    # You need to return the following variables correctly \n    J = 0\n    grad = np.zeros(omega.shape)\n\n    # ===================== YOUR CODE HERE ======================\n\n    \n    \n    # =============================================================\n    return J, grad\n\n2.5. Once you are done with the costFunctionReg, call it using the initial value of \\(\\omega\\) (initialized to all zeros), and also another test case where \\(\\omega\\) is all ones. The code is given below with the expected values. You should obtain the same values.\n\n# Initialize fitting parameters\n# X here has 28 columns\ninitial_omega = np.zeros(X.shape[1])\n\n# Set regularization parameter lambda to 1\n# DO NOT use `lambda` as a variable name in python\n# because it is a python keyword\nlambda_ = 1\n\n# Compute and display initial cost and gradient for regularized logistic\n# regression\ncost, grad = costFunctionReg(initial_omega, X, y, lambda_)\n\nprint('Cost at initial omega (zeros): {:.3f}'.format(cost))\nprint('Expected cost (approx)       : 0.693\\n')\n\nprint('Gradient at initial omega (zeros) - first five values only:')\nprint('\\t[{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}]'.format(*grad[:5]))\nprint('Expected gradients (approx) - first five values only:')\nprint('\\t[0.0085, 0.0188, 0.0001, 0.0503, 0.0115]\\n')\n\n\n# Compute and display cost and gradient\n# with all-ones omega and lambda = 10\ntest_omega = np.ones(X.shape[1])\ncost, grad = costFunctionReg(test_omega, X, y, 10)\n\nprint('------------------------------\\n')\nprint('Cost at test omega    : {:.2f}'.format(cost))\nprint('Expected cost (approx): 3.16\\n')\n\nprint('Gradient at test omega - first five values only:')\nprint('\\t[{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}]'.format(*grad[:5]))\nprint('Expected gradients (approx) - first five values only:')\nprint('\\t[0.3460, 0.1614, 0.1948, 0.2269, 0.0922]')\n\nLearning parameters using scipy.optimize.minimize\n\n2.6. Use optimize.minimize to learn the optimal parameters \\(\\omega\\).\nPlotting the decision boundary\n2.7. To visualize the model learned by this classifier use the function plotDecisionBoundary to plot the (non-linear) decision boundary that separates the positive and negative examples.\n\nIn plotDecisionBoundary, we plot the non-linear decision boundary by computing the classifier‚Äôs predictions on an evenly spaced grid and then and draw a contour plot where the predictions change from y = 0 to y = 1.\n\nYou should obtain something like this:\n\n\n&lt;string&gt;:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n\n\n\n\n\nExtra\nTry out different regularization parameters for the dataset to understand how regularization prevents overfitting.\nNotice the changes in the decision boundary as you vary \\(\\lambda\\). With a small \\(\\lambda\\), you should find that the classifier gets almost every training example correct, but draws a very complicated boundary, thus overfitting the data.\nCredits\n\nThis lab is hugely inspired from Andrew Ng‚Äôs Machine Learning course. Supplementary material from dibgerge‚Äôs github was used."
  },
  {
    "objectID": "TD3.html#regression-trees",
    "href": "TD3.html#regression-trees",
    "title": "Lab3: Decision Trees and Random Forests",
    "section": "Regression Trees",
    "text": "Regression Trees\nFor building trees for regression we are going to use the Housing dataset, (know also as Boston dataset). In the Housing dataset, there is 13 features and one target variable, described as follows:\n\n\ncrim: per capita crime rate by town.\n\nzn: proportion of residential land zoned for lots over 25,000 sq.ft.\n\nindus: proportion of non-retail business acres per town.\n\nchas: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n\nnox: nitrogen oxides concentration (parts per 10 million).\n\nrm: average number of rooms per dwelling.\n\nage: proportion of owner-occupied units built prior to 1940.\n\ndis: weighted mean of distances to five Boston employment centres.\n\nrad: index of accessibility to radial highways.\n\ntax: full-value property-tax rate per $10,000.\n\nptratio: pupil-teacher ratio by town.\n\nblack: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town.\n\nlstat: lower status of the population (percent).\n\nAnd the target variable:\n\n\nmedv: median value of owner-occupied homes in $1000s.\n\nSingle tree\nTo demonstrate regression trees, we will use the Boston dataset that we used during the first two practical works, from the MASS package. Recall that medv is the response.\n1. Load the dataset and split it randomly in half.\nIn , load it from MASS package.\n\nlibrary(\"MASS\")\nlibrary(\"caTools\")\nset.seed(18)\nBoston_idx = sample(1:nrow(Boston), nrow(Boston) / 2) \n# You don't know what we just did?\n# open the documentation of the function sample by \n# writing ?sample in the R console.\n# Note that this is one of the ways to split it randomly and it is not necessary the best.\nBoston_train = Boston[Boston_idx,]\nBoston_test  = Boston[-Boston_idx,]\n\nIn Python, load it from sklearn‚Äôs datasets.\n\nfrom sklearn import datasets\n\n# Loading the Housing dataset\nboston= datasets.load_boston()\n\n# Create feature matrix\nX = boston.data\nprint(X.shape)\n\n# Create target vector\ny=boston.target\nprint(y.shape)\n\n# Then use train_test_split()\n\n2. Fit a regression tree to the training data using the rpart() function from the rpart package. Name the tree Boston_tree.\n3. Plot the obtained tree using the following code.\n\nplot(Boston_tree)\ntext(Boston_tree, pretty = 0)\ntitle(main = \"Regression Tree\")\n\n\n\n\n4. A better plot can be obtained using the rpart.plot2 package. Re-plot the tree using it. You can use the rpart.plot() function which by default, when the output is continuous, each node shows: the predicted value, and the percentage of observations in the node. You can also use the prp() function.\n\nlibrary(\"rpart.plot\")\nrpart.plot(Boston_tree)\nprp(Boston_tree)\n\n\n\n\n\n\n\n5. Print the obtained tree and print its summary. Between the things that you can see in the summary, the CP (complexity parameter) table and the importance of each variable in the model. Print the CP table using the printcp() function to see the cross validation results. Plot a comparison figure using the plotcp() function.\nYou will notice the obtained tree is pruned. This is because rpart prunes the tree by default by performing 10-fold cross-validation.\n\n\n\n\n\n\nNote\n\n\n\nrpart keeps track of something called the complexity of a tree. The complexity measure is a combination of the size of a tree and the ability of the tree to separate the classes of the target variable. If the next best split in growing a tree does not reduce the tree‚Äôs overall complexity by a certain amount, rpart will terminate the growing process. This amount is specified by the complexity parameter, cp, in the call to rpart(). Setting cp to a negative amount (like -1) ensures that the tree will be fully grown. You can try it and then plot the tree.\nNotice that the default cp value may over prune the tree. As a rule of thumb, it‚Äôs best to prune a decision tree using the cp of smallest tree that is within one standard deviation of the tree with the smallest xerror. In the example above, it‚Äôs maybe best to prune the tree with a cp slightly greater than 0.03.\n\n\nNext we will compare this regression tree to a linear model and will use RMSE as our metric. RMSE is the Root Mean Square Error, which is the square root of the MSE.\n5. Write a function that returns the RMSE of two vectors.\n6. Use the function predict() to predict the response on the test set. Then calculate the RMSE obtained with tree model.\n7. Fit a linear regression model on the training set. Then predict the response on the test set using the linear model. Calculate the RMSE and compare the performance of the tree and the linear regression model.\n\n\n\n\n\n\nNote\n\n\n\nHere the most obvious linear regression beats the tree! We‚Äôll improve on this tree by considering ensembles of trees.\n\n\nYou can visually compare the performance of both models by plotting the Actual (reality) response values against the predicted values. The model with closer points are to the diagonal (y=x) line is the better one. You can try to reproduce the figure below.\n\n\n\n\n\n\n\n\nBy aggregating many decision trees, using methods like bagging, random forests, and boosting, the predictive performance of trees can be substantially improved. We will now use these concepts, called ensemble methods.\nBagging\nBagging, or Bootstrap aggregation, is a general-purpose procedure for reducing the variance of a statistical learning method, it is particularly useful and frequently used in the context of decision trees. The idea is to take many training sets from the population, build a separate prediction model using each training set, and average the resulting predictions. Generally we do not have access to multiple training sets. Instead, we can bootstrap, by taking repeated samples from the (single) training data set.\nTo apply bagging to regression trees, we simply construct \\(B\\) regression trees using B bootstrapped training sets, and average the resulting predictions. These trees are grown deep, and are not pruned. Hence each individual tree has high variance, but low bias. Averaging these \\(B\\) trees reduces the variance.\n8. Fit a bagged model, using the randomForest() function from the randomForest package.\n\n\n\n\n\n\nImportant\n\n\n\nBagging is actually a special case of a random forest where mtry is equal to \\(p\\), the number of predictors.\n\n\n9. Predict the response on the test set using the bagging model. Calculate the RMSE. Is the performance of the model better than linear regression or a simple tree?\nNote that the ‚ÄúMean of squared residuals‚Äù which is output by randomForest() is the Out of Bag3 estimate of the error. Here is its plot:\n\nplot(Boston_bagging, col = \"#cd0050\", lwd = 2, main = \"Bagged Trees: Error vs Number of Trees\")\ngrid()\n\n\n\n\nRandom Forests\nNow try a random forest. For regression, on suggestion is to use mtry equal to \\(p/3\\).4\n10. Fit a random forest on the training set and compare its performance with the previous models by calculating the predictions and the RMSE.\n11. Use the function importance() from the randomForest package to see the most important predictors in the obtained random forest model. What are the three most important predictors? Did you find the same results when you selected the best predictors for the linear regression model during session 2?\n12. Plot the importance of the predictors to the model using the varImpPlot() function.\nBoosting\nLast and not least, let us try a boosted model, which by default will produce a nice variable importance plot as well as plots of the marginal effects of the predictors. To do so, we will use the gbm package5.\n10. Using the gbm() function like following, fit a boosted model on the training set. Then compare its performance with the previous models by calculating the predictions and the RMSE.\n\nxfun::pkg_attach2(\"gbm\")\n\nLoaded gbm 2.1.8.1\n\nBoston_boost = gbm(medv ~ ., data = Boston_train, distribution = \"gaussian\", \n                    n.trees = 5000, interaction.depth = 4, shrinkage = 0.01)\n\n\nBoston_boost_pred = predict(Boston_boost, newdata = Boston_test)\n\nUsing 5000 trees...\n\n\n\nrmse(Boston_boost_pred, Boston_test$medv)\n\n[1] 3.656622\n\n\n11. Show the summary of the boosted model. A figure of the variable importance will be shown.\n\nsummary(Boston_boost)\n\n\n\n\n            var     rel.inf\nlstat     lstat 44.28292729\nrm           rm 26.75013094\ndis         dis  5.69907146\ncrim       crim  4.99715134\nnox         nox  4.80328525\nblack     black  3.72041629\nage         age  3.15666045\nptratio ptratio  2.66396487\ntax         tax  2.11304970\nindus     indus  0.86895517\nrad         rad  0.73545313\nzn           zn  0.16493067\nchas       chas  0.04400344\n\n\nComparison\n12. Reproduce the following comparison: A table in which we show the obtained RMSE with each tested model, you can create a \\(5 \\times 2\\) data.frame in which you put the names of the models and the corresponding RMSE. To visualize the data frame in the compiled html report you can use the kable() function from the knitr package. Or, compare the models by plotting the Actual (reality) response values against the predicted values."
  },
  {
    "objectID": "TD3.html#classification-trees",
    "href": "TD3.html#classification-trees",
    "title": "Lab3: Decision Trees and Random Forests",
    "section": "Classification Trees",
    "text": "Classification Trees\nA classification tree is very similar to a regression tree, except that the classification tree is used to predict a qualitative response rather than a quantitative one. Recall that for a regression tree, the predicted response for an observation is given by the mean response of the training observations that belong to the same terminal node. In contrast, for a classification tree, we predict that each observation belongs to the most commonly occurring class of training observations in the region to which it belongs.\nThe Toy Dataset\nIn order to better understand how a decision tree processes the feature space, we will first work on a simulated dataset.\n\nplt.figure(figsize=(5, 5))\n\nx1 = np.random.multivariate_normal([2,2], [[0.1,0],[0,0.1]], 50)\nx2 = np.random.multivariate_normal([-2,-2], [[0.1,0],[0,0.1]], 50)\nx3 = np.random.multivariate_normal([-3,3], [[0.1,0.1],[0,0.1]], 50)\nX1 = np.concatenate((x1,x2,x3), axis=0)\n\ny1 = np.random.multivariate_normal([-2,2], [[0.1,0],[0,0.1]], 50)\ny2 = np.random.multivariate_normal([2,-2], [[0.1,0],[0,0.1]], 50)\ny3 = np.random.multivariate_normal([-3,-3], [[0.01,0],[0,0.01]], 50)\nX2 = np.concatenate((y1,y2,y3), axis=0)\n\nplt.plot(X1[:,0],X1[:,1], 'x', color='blue', label='class 1')\nplt.plot(X2[:,0], X2[:,1], 'x', color='orange', label='class 2')\n\n\nplt.legend(loc=(0.4, 0.8), fontsize=12)\n\n\nWhat do you expect the decision boudaries to look like ?\nFill-in the following code to train a decision tree on this toy data and visualize it.\n\nChange the splitter to random, meaning that the algorithm will consider the feature along which to split randomly (rather than picking the optimal one), and then select the best among several random splitting point. Run the algorithm several times. What do you observe?\n\n# Training data\nX_demo = np.concatenate((X1, X2), axis=0)\ny_demo = np.concatenate((np.zeros(X1.shape[0]), np.ones(X2.shape[0])))\n\n# Train a DecisionTreeClassifier on the training data\nclf = # TODO\n\n# Create a mesh, i.e. a fine grid of values between the minimum and maximum\n# values of x1 and x2 in the training data\nplot_step = 0.02\nx_min, x_max = X_demo[:, 0].min() - 1, X_demo[:, 0].max() + 1\ny_min, y_max = X_demo[:, 1].min() - 1, X_demo[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n                         np.arange(y_min, y_max, plot_step))\n\n# Label each point of the mesh with the trained DecisionTreeClassifier\nZ = clf.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n# Plot the contours corresponding to these labels \n# (i.e. the decision boundary of the DecisionTreeClassifier)\ncs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n\n# Plot the training data \nplt.plot(X1[:,0], X1[:,1], 'x', label='class 1')\nplt.plot(X2[:,0], X2[:,1], 'x', label='class 2')\nplt.legend()\n\nSpam Dataset\nIn this section, we will use the spam6 dataset, available here . A description of the dataset is given below.\n\n\n\n\n\n\nTODO\n\n\n\nYou must:\n\nImport the spam dataset and explore it. Be aware that it is preferable that the response column is of type factor.\nSplit the dataset into training and test sets (choose your own seed when using set.seed()).\nFit:\n\nA logistic regression model.\nA simple classification tree.\nBagging, Random Forests, and Boosting models.\n\n\nFor each model, predict the response on the test set and evaluate the performance of the model, using the prediction accuracy (create a function that returns the accuracy for two binary vectors).\n\n\n\nThis dataset consists of information from 4601 email messages, in a study to try to predict whether the email was junk email, or ‚Äúspam‚Äù. For all 4601 email messages, the true outcome, spam or not, is available, along with 57 predictors as described below:\n\n48 quantitative predictors: the percentage of words in the email that match a given word. Examples include business, address, internet; etc.\n6 quantitative predictors: the percentage of characters in the email that match a given character. The characters are ; , ( , [ , ! , $ and #.\nThe average length of uninterrupted sequences of capital letters: crl.ave.\nThe length of the longest uninterrupted sequence of capital letters: crl.long.\nThe sum of the length of uninterrupted sequences of capital letters: crl.tot.\n\n\n\n\n\n\n\nImportant\n\n\n\nNote that the spam dataset given here is already treated and ready to be explored. To achieve this stage, some steps are required to treat the raw data, like Tokenization, Stemming, and Lemmatization. In this dataset the most important words are already selected and other variables are added. Curious students can read more about these steps. Two famous  packages for text mining are tm and tidytext.\n\n\nTuning\nSo far in this lab, we fit bagging, boosting and random forest models, but did not tune any of them, we simply used certain, somewhat arbitrary, parameters. Actually, to make these models better the parameters should be tuned. The parameters include:\n\nBagging: Actually just a subset of Random Forest with mtry = \\(p\\).\nRandom Forest: mtry\n\nBoosting: n.trees, interaction.depth, shrinkage, n.minobsinnode\n\n\nThe caret package in R provides excellent functions to accomplish this. Note that with these tree-based ensemble methods there are two resampling solutions for tuning the model:\n\nOut of Bag\nCross-Validation\n\nUsing Out of Bag samples is advantageous with these methods as compared to Cross-Validation since it removes the need to refit the model and is thus much more computationally efficient. Unfortunately OOB methods cannot be used with gbm models. See the caret documentation: Short intro, Long intro for details.\nTumor classification data7\n\nThis data set comes from the world of bioinformatics. In this data set, each observation is a tumor, and it is described by the expression of 3,000 genes. The expression of a gene is a measure of how much of that gene is present in the biological sample. Because this affects how much of the protein this gene codes for is produced, and because proteins dictacte what cells can do, gene expression gives us valuable information about the tumor. In particular, the expression of the same gene in the same individual is different in different tissues (although the DNA is the same): this is why blood cells look different from skin cells. In our data set, there are two types of tumors: endometrium tumors and uterine tumors. Let us see if gene expression can be used to separate them!\nThe dataset is available here .\n\n# load the endometrium vs. uterus tumor data\nendometrium_data = pd.read_csv('datasets/small_Endometrium_Uterus.csv', sep=\",\")  # load data\nendometrium_data.head(n=5)  # adjust n to view more data\n\n   ID_REF  1554530_at  1553185_at  ...  1555097_a_at  1556371_at       Tissue\n0  117722        10.8     13233.7  ...          66.9        50.6  Endometrium\n1   76638        12.6      4986.8  ...           6.4        12.2  Endometrium\n2   88952        16.6      6053.8  ...          33.8        33.4  Endometrium\n3   76632         9.9      6109.1  ...          58.9        15.4  Endometrium\n4   88966        13.1      8430.9  ...          14.1        11.2  Endometrium\n\n[5 rows x 3002 columns]\n\n\n\n# Create the design matrix and target vector\nX = endometrium_data.drop(['ID_REF', 'Tissue'], axis=1).values\ny = pd.get_dummies(endometrium_data['Tissue']).values[:,1]\n\nCross Validation procedures\n\n## make folds\nfrom sklearn import model_selection\nskf = model_selection.StratifiedKFold(n_splits=5)\nskf.get_n_splits(X, y)\n\n5\n\nfolds = [(tr,te) for (tr,te) in skf.split(X, y)]\n\n\ndef cross_validate_clf(design_matrix, labels, classifier, cv_folds):\n    \"\"\" Perform a cross-validation and returns the predictions.\n    \n    Parameters:\n    -----------\n    design_matrix: (n_samples, n_features) np.array\n        Design matrix for the experiment.\n    labels: (n_samples, ) np.array\n        Vector of labels.\n    classifier:  sklearn classifier object\n        Classifier instance; must have the following methods:\n        - fit(X, y) to train the classifier on the data X, y\n        - predict_proba(X) to apply the trained classifier to the data X and return probability estimates \n    cv_folds: sklearn cross-validation object\n        Cross-validation iterator.\n        \n    Return:\n    -------\n    pred: (n_samples, ) np.array\n        Vectors of predictions (same order as labels).\n    \"\"\"\n    pred = np.zeros(labels.shape)\n    for tr, te in cv_folds:\n        classifier.fit(design_matrix[tr,:], labels[tr])\n        pos_idx = list(classifier.classes_).index(1)\n        pred[te] = (classifier.predict_proba(design_matrix[te,:]))[:, pos_idx]\n    return pred\n\n\ndef cross_validate_clf_optimize(design_matrix, labels, classifier, cv_folds):\n    \"\"\" Perform a cross-validation and returns the predictions.\n    \n    Parameters:\n    -----------\n    design_matrix: (n_samples, n_features) np.array\n        Design matrix for the experiment.\n    labels: (n_samples, ) np.array\n        Vector of labels.\n    classifier:  sklearn classifier object\n        Classifier instance; must have the following methods:\n        - fit(X, y) to train the classifier on the data X, y\n        - predict_proba(X) to apply the trained classifier to the data X and return probability estimates \n    cv_folds: sklearn cross-validation object\n        Cross-validation iterator.\n        \n    Return:\n    -------\n    pred: (n_samples, ) np.array\n        Vectors of predictions (same order as labels).\n    \"\"\"\n    pred = np.zeros(labels.shape)\n    for tr, te in cv_folds:\n        classifier.fit(design_matrix[tr,:], labels[tr])\n        print(classifier.best_params_)\n        pos_idx = list(classifier.best_estimator_.classes_).index(1)\n        pred[te] = (classifier.predict_proba(design_matrix[te,:]))[:, pos_idx]\n    return pred\n\n\n\nQuestion: Cross-validate 5 different decision trees (with default parameters) and print out their accuracy. Why do you get different values? Check the documentation for help.\n\n\nfrom sklearn import tree\nfrom sklearn import metrics\n\nypred_dt = [] # will hold the 5 arrays of predictions (1 per tree)\nfor tree_index in range(5):\n    # Initialize a DecisionTreeClassifier\n    clf = # TODO \n    \n    # Cross-validate this DecisionTreeClassifier on the toy data\n    pred_proba = cross_validate_clf(X, y, clf, folds)\n    \n    # Append the prediction to ypred_dt \n    ypred_dt.append(pred_proba)\n    \n    # Print the accuracy of DecisionTreeClassifier\n    print(\"%.3f\" % metrics.accuracy_score(y, np.where(pred_proba &gt; 0.5, 1, 0)))\n\n\n\nQuestion: Compute the mean and standard deviation of the area under the ROC curve of these 5 trees. Plot the ROC curves of these 5 trees.\n\nUse the metrics module of scikit-learn.\n\nfpr_dt = [] # will hold the 5 arrays of false positive rates (1 per tree)\ntpr_dt = [] # will hold the 5 arrays of true positive rates (1 per tree)\nauc_dt = [] # will hold the 5 areas under the ROC curve (1 per tree)\n\nfor tree_index in range(5):\n    # Compute the ROC curve of the current tree\n    fpr_dt_tmp, tpr_dt_tmp, thresholds =  metrics.roc_curve(# TODO\n    # Compute the area under the ROC curve of the current tree\n    auc_dt_tmp = metrics.auc(fpr_dt_tmp, tpr_dt_tmp)\n    fpr_dt.append(fpr_dt_tmp)\n    tpr_dt.append(tpr_dt_tmp)\n    auc_dt.append(auc_dt_tmp)\n\n# Plot the first 4 ROC curves\nfor tree_index in range(4):\n    plt.plot(# TODO\n            \n# Plot the last ROC curve, with a label that gives the mean/std AUC\nplt.plot(fpr_dt[-1], tpr_dt[-1], '-', \n         label='DT (AUC = %0.2f +/- %0.2f)' % (np.mean(auc_dt), np.std(auc_dt)))\n\n# Plot the ROC curve\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curves', fontsize=16)\nplt.legend(loc=\"lower right\")\n\n\n\nQuestion: What parameters of DecisionTreeClassifier can you play with to define trees differently than with the default parameters? Cross-validate these using a grid search with model_selection.GridSearchCV. Plot the optimal decision tree on the previous plot. Did you manage to improve performance?\n\n\nfrom sklearn import model_selection\n\n# Define the grid of parameters to test\nparam_grid = # TODO\n\n# Initialize a GridSearchCV object that will be used to cross-validate\n# a DecisionTreeClassifier with these parameters.\n# What scoring function do you want to use?\nclf = model_selection.GridSearchCV( # TODO\n\n# Cross-validate the GridSearchCV object \nypred_dt_opt = cross_validate_clf_optimize(X, y, clf, folds)\n\n# Compute the ROC curve for the optimized DecisionTreeClassifier\nfpr_dt_opt, tpr_dt_opt, thresholds = metrics.roc_curve(y, ypred_dt_opt, pos_label=1)\nauc_dt_opt = metrics.auc(fpr_dt_opt, tpr_dt_opt)\n\n# Plot the ROC curves of the 5 decision trees from earlier\nfig = plt.figure(figsize=(5, 5))\n\nfor tree_index in range(4):\n    plt.plot(fpr_dt[tree_index], tpr_dt[tree_index], '-', color='blue') \nplt.plot(fpr_dt[-1], tpr_dt[-1], '-', color='blue', \n         label='DT (AUC = %0.2f (+/- %0.2f))' % (np.mean(auc_dt), np.std(auc_dt)))\n\n# Plot the ROC curve of the optimized DecisionTreeClassifier\nplt.plot(fpr_dt_opt, tpr_dt_opt, color='orange', label='DT optimized (AUC=%0.2f)' % auc_dt_opt)\n\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curves', fontsize=16)\nplt.legend(loc=\"lower right\", fontsize=12)\n\nBagging trees\nWe will resort to ensemble methods to try to improve the performance of single decision trees. Let us start with bagging trees: The different trees are to be built using a bootstrap sample of the data, that is to say, a sample built by randomly drawing n points with replacement from the original data, where n is the number of points in the training set.\nBagging is efficient when used with low bias and high variance weak learners. Indeed, by averaging such estimators, we lower the variance by obtaining a smoother estimator, which is still centered around the true density (low bias).\nBagging decision trees hence makes sense, as decision trees have: * low bias: intuitively, the conditions that are checked become multiplicative so the tree is continuously narrowing down on the data (the tree becomes highly tuned to the data present in the training set). * high variance: decision trees are very sensitive to where it splits and how it splits. Therefore, even small changes in input variable values might result in very different tree structure.\nNote: Bagging trees and random forests start being really powerful when using large number of trees (several hundreds). This is computationally more intensive, especially when the number of features is large, as in this lab. For the sake of computational time, we suggeste using small numbers of trees, but you might want to repeat this lab for larger number of trees at home.\n\n\nQuestion Cross-validate a bagging ensemble of 5 decision trees on the data. Plot the resulting ROC curve, compared to the 5 decision trees you trained earlier.\n\nUse ensemble.BaggingClassifier.\n\nfrom sklearn import ensemble\n\n# Initialize a bag of trees\nclf = # TODO\n\n# Cross-validate the bagging trees on the tumor data\nypred_bt = cross_validate_clf(X, y, clf, folds)\n\n# Compute the ROC curve of the bagging trees\nfpr_bt, tpr_bt, thresholds = metrics.roc_curve(y, ypred_bt, pos_label=1)\nauc_bt = metrics.auc(fpr_bt, tpr_bt)\n\n# Plot the ROC curve of the 5 decision trees from earlier\nfig = plt.figure(figsize=(5, 5))\n\nfor tree_index in range(4):\n    plt.plot(fpr_dt[tree_index], tpr_dt[tree_index], '-', color='blue') \nplt.plot(fpr_dt[-1], tpr_dt[-1], '-', color='blue', \n         label='DT (AUC = %0.2f (+/- %0.2f))' % (np.mean(auc_dt), np.std(auc_dt)))\n\n# Plot the ROC curve of the bagging trees\nplt.plot(fpr_bt, tpr_bt, color='orange', label='BT (AUC=%0.2f)' % auc_bt)\n\n\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curves', fontsize=16)\nplt.legend(loc=\"lower right\", fontsize=12)\n\n\nQuestion: How do the bagging trees perform compared to individual trees?\nQuestion Use cross_validate_optimize to optimize the number of decision trees to use in the bagging method. How many trees did you find to be an optimal choice?\n\n\n# Number of trees to use\nlist_n_trees = [5, 10, 20, 50, 80]\n\n# Start a ROC curve plot\nfig = plt.figure(figsize=(5, 5))\n    \nfor idx, n_trees in enumerate(list_n_trees):\n    # Initialize a bag of trees with n_trees trees\n    clf = # TODO\n    \n    # Cross-validate the bagging trees on the tumor data\n    ypred_bt_tmp = cross_validate_clf(X, y, clf, folds)\n    \n    # Compute the ROC curve \n    fpr_bt_tmp, tpr_bt_tmp, thresholds = metrics.roc_curve(y, ypred_bt_tmp, pos_label=1)\n    auc_bt_tmp = metrics.auc(fpr_bt_tmp, tpr_bt_tmp)\n\n    # Plot the ROC curve\n    plt.plot(fpr_bt_tmp, tpr_bt_tmp, '-', \n             label='BT %0.f trees (AUC = %0.2f)' % (n_trees, auc_bt_opt))\n\n# Plot the ROC curve of the optimal decision tree\nplt.plot(fpr_dt_opt, tpr_dt_opt, label='DT optimized (AUC=%0.2f)' % auc_dt_opt)\n\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curves', fontsize=16)\nplt.legend(loc=\"lower right\", fontsize=12)\n\nRandom Forest\nIn practice, simply bagging is typically not enough. In order to get a good reduction in variance, we require that the models being aggregated be uncorrelated, so that they make ‚Äúdifferent errors‚Äù. Bagging will usually get you highly correlated models that will make the same errors, and will therefore not reduce the variance of the combined predictor.\n\nQuestion What is the difference between bagging trees and random forests? How does it intuitively fix the problem of correlations between trees ?\nQuestion Cross-validate a random forest of 5 decision trees on the data. Plot the resulting ROC curve, compared to the bagging tree made of 5 decision trees.\n\nUse ensemble.RandomForestClassifier\n\n# Initialize a random forest with 5 trees\nclf = # TODO\n\n# Cross-validate the random forest on the tumor data\nypred_rf = # TODO\n\n# Compute the ROC curve of the random forest\nfpr_rf, tpr_rf, thresholds = # TODO\nauc_rf = # TODO\n\n# Plot the ROC curve of the 5 decision trees from earlier\nfig = plt.figure(figsize=(5, 5))\n\nfor tree_index in range(4):\n    plt.plot(fpr_dt[tree_index], tpr_dt[tree_index], '-', color='grey') \nplt.plot(fpr_dt[-1], tpr_dt[-1], '-', color='grey', \n         label='DT (AUC = %0.2f (+/- %0.2f))' % (np.mean(auc_dt), np.std(auc_dt)))\n\n# Plot the ROC curve of the bagging trees (5 trees)\nplt.plot(fpr_bt, tpr_bt, label='BT (AUC=%0.2f)' % auc_bt)\n\n# Plot the ROC curve of the random forest (5 trees)\nplt.plot(fpr_rf, tpr_rf, label='BT (AUC=%0.2f)' % auc_bt)\n\n\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curves', fontsize=16)\nplt.legend(loc=\"lower right\", fontsize=12)\n\n\nQuestion What are the main parameters of Random Forest which can be optimized ?\n\nQuestion Use cross_validate_clf_optimize to optimize\n\nthe number of decision trees\nthe number of features to consider at each split.\n\n\n\nHow many trees do you find to be an optimal choice? How does the optimal random forest compare to the optimal bagging trees? How do the training times of the random forest and the bagging trees compare?\n\n# Define the grid of parameters to test\nparam_grid = # TODO\n\n# Initialize a GridSearchCV object that will be used to cross-validate\n# a random forest with these parameters.\n# What scoring function do you want to use?\nclf = grid_search.GridSearchCV(# TODO\n\n# Cross-validate the GridSearchCV object \nypred_rf_opt = cross_validate_clf_optimize(X, y, clf, folds)\n\n# Compute the ROC curve for the optimized random forest\nfpr_rf_opt, tpr_rf_opt, thresholds = metrics.roc_curve(y, ypred_rf_opt, pos_label=1)\nauc_rf_opt = metrics.auc(fpr_rf_opt, tpr_rf_opt)\n\n# Plot the ROC curve of the optimized DecisionTreeClassifier\nfig = plt.figure(figsize=(5, 5))\n\nplt.plot(fpr_dt_opt, tpr_dt_opt, color='grey', \n         label='DT optimized (AUC=%0.2f)' % auc_dt_opt)\n    \n# Plot the ROC curve of the optimized random forest\nplt.plot(fpr_bt_opt, tpr_bt_opt, \n         label='BT optimized (AUC=%0.2f)' % auc_bt_opt)\n\n# Plot the ROC curve of the optimized bagging trees\nplt.plot(fpr_rf_opt, tpr_rf_opt, l\n         abel='RF optimized (AUC = %0.2f' % (auc_rf_opt))\n    \nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curves', fontsize=16)\nplt.legend(loc=\"lower right\", fontsize=12)\n\n\n\nQuestion How do your tree-based classifiers compare to regularized logistic regression models? Plot the corresponding ROC curves.\n\n\nfrom sklearn import linear_model\n\n# Evaluate an optimized l1-regularized logistic regression\nparam_grid = {'C': np.logspace(-3, 3, 7)}\nclf = grid_search.GridSearchCV(linear_model.LogisticRegression(penalty='l1'), \n                               param_grid, scoring='roc_auc')\nypred_l1 = cross_validate_clf_optimize(X, y, clf, folds)\nfpr_l1, tpr_l1, thresholds_l1 = metrics.roc_curve(y, ypred_l1, pos_label=1)\nauc_l1 = metrics.auc(fpr_l1, tpr_l1)\nprint('nb features of best sparse model:', len(np.where(clf.best_estimator_.coef_!=0)[0]))\n\n# Evaluate an optimized l2-regularized logistic regression\nclf = grid_search.GridSearchCV(linear_model.LogisticRegression(penalty='l2'), \n                               param_grid, scoring='roc_auc')\nypred_l2 = cross_validate_clf_optimize(X, y, clf, folds)\nfpr_l2, tpr_l2, thresholds_l2 = metrics.roc_curve(y, ypred_l2, pos_label=1)\nauc_l2 = metrics.auc(fpr_l2, tpr_l2)\n\n\n# Plot the ROC curves\nfig = plt.figure(figsize=(5, 5))\n\nplt.plot(fpr_rf_opt, tpr_rf_opt, \n         label='RF optimized (AUC = %0.2f)' % (auc_rf_opt))\nplt.plot(fpr_bt_opt, tpr_bt_opt, \n         label='BT optimized (AUC = %0.2f)' % (auc_bt_opt))\nplt.plot(fpr_l1, tpr_l1,  \n         label='l1 optimized (AUC = %0.2f)' % (auc_l1))\nplt.plot(fpr_l2, tpr_l2,  \n         label='l2 optimized (AUC = %0.2f)' % (auc_l2))\n\nplt.xlabel('False Positive Rate', fontsize=16)\nplt.ylabel('True Positive Rate', fontsize=16)\nplt.title('ROC curves', fontsize=16)\nplt.legend(loc=\"lower right\", fontsize=12)"
  },
  {
    "objectID": "TD3.html#footnotes",
    "href": "TD3.html#footnotes",
    "title": "Lab3: Decision Trees and Random Forests",
    "section": "",
    "text": "An Introduction to Recursive Partitioning Using the rpart Routines - Details of the rpart package.‚Ü©Ô∏é\nrpart.plot Package - Detailed manual on plotting with rpart using the rpart.plot package.‚Ü©Ô∏é\nRead about OOB error here‚Ü©Ô∏é\nFor classification a suggestion is mtry = \\(\\sqrt{p}\\).‚Ü©Ô∏é\ngeneralized boosted models  package‚Ü©Ô∏é\nSource‚Ü©Ô∏é\nCredits: this part is adopted from Here.‚Ü©Ô∏é"
  },
  {
    "objectID": "TD4.html#image-classification",
    "href": "TD4.html#image-classification",
    "title": "Lab4: Starting with Neural Networks",
    "section": "Image Classification",
    "text": "Image Classification\nIn the set of this exercises we will be using tf.keras (a high-level API to build and train models in TensorFlow) and GoogleColab.\n1. Open a new notebook in GoogleColab for python3. Run the following code for activating tensorflow version 2.0:\n\ntry:\n    # %tensorflow_version only exists in Colab.\n    %tensorflow_version 2.x\nexcept Exception: \n    pass\n\n2. Import tensorflow, keras, numpy and matplot using the following code:\n\nfrom __future__ import absolute_import , division , print_function , unicode_literals\n\n# TensorFlow and tf.keras\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n3. Check your tensorflow version using:\n\nprint(tf.__version__)\n\nThe output should be 2. or higher.\n4. Import the cifra10 data set. The CIFAR-10 dataset consists of 60000 32 √ó 32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images: cifar10\n\ndata = keras.datasets.cifar10 \ncifar10_data = data.load_data()\n\n5. Before using a dataset, the datatype should be checked. Test type(cifar10 data) for verifying the variable type. len(cifar10 data) is another command for checking the data size.\n6. Load train and test images and labels with:\n\n(train_images , train_labels),(test_images , test_labels) =\ncifar10_data\n\nLoading the dataset returns four NumPy arrays:\n\nThe train_images and train_labels arrays are the training set, the data the model uses to learn.\nThe model is tested against the test set, the test_images, and test_labels arrays.\n\n7. The images are 32 √ó 32 NumPy arrays, with pixel values ranging from 0 to 255. You can check an example with:\n\nprint(train_images[0]) \nprint(train_images[0].shape)\n\nThe labels are an array of integers, ranging from 0 to 9. Check it with your own code. Each image is mapped to a single label. Since the class names are not included with the dataset, store them here to use later when plotting the images: (check the dataset link for more detailed information: cifar)\n\n class_names = [ 'airplane' , 'automobile' , 'bird' , 'cat' , 'deer' , 'dog' , 'frog' , 'horse' , 'ship' , 'truck']\n\n8. Before training the model, explore the datasets. Number of train and test points, their array size and etc.\n9. An interesting fact about the image is that you can plot the image. It is possible using the following:\n\nindex = 8 \nplt.figure()\nplt.imshow(train_images[index]) \nplt.colorbar()\nplt.grid(False) \nplt.show()\n\ntrain_labels[index]\n\n10. To verify that the data is in the correct format and that you‚Äôre ready to build and train the network, let‚Äôs display the first 25 images from the training set and display the class name below each image. To do so use the following commands:\n\nplt.subplot() \nplt.xticks([])\nplt.yticks([]) \nplt.imshow()\nplt.xlabel()\n\n11. You can check various images by changing the index value, or by calling test_images. You can see that the pixel values fall in the range of 0 to 255. normalise train and test sets using the following code:\n\ntrain_images = train_images / 255.0\n\nBuilding a neural network in general requires configuring the layers of the model, then compiling the model. The basic building block of a neural network is the layer. Layers extract representations from the data fed into them. Hopefully, these representations are meaningful for the problem at hand. Most of deep learning consists of chaining together simple layers. Most layers, such as tf.keras.layers.Dense, have parameters that are learned during training.\n12. First neural network definition with three layers and two activation functions\n\nmodel = keras.Sequential([ \n    keras.layers.Flatten(input_shape=(32, 32, 3)),\n    keras.layers.Dense(128, activation=‚Äôrelu‚Äô), \n    keras.layers.Dense(10, activation=‚Äôsoftmax‚Äô)])\n\n\n\n\n\n\n\nFor more information on the keras code check keras website here\n\n\n\nThe first layer in this network, tf.keras.layers.Flatten, transforms the format of the images from a two-dimensional array (of 32 by 32 pixels) to a one- dimensional array (of 32 √ó 32 = 1024 pixels). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data.\nAfter the pixels are flattened, the network consists of a sequence of two tf.keras.layers.Dense layers. These are densely connected, or fully con- nected, neural layers. The first Dense layer has 128 nodes (or neurons). The second (and last) layer is a 10-node softmax layer that returns an array of 10 probability scores that sum to 1. Each node contains a score that indicates the probability that the current image belongs to one of the 10 classes. In this exercise, we don‚Äôt explain the reasons of defining a neural network with this structure. For defining a network compatible with our data, we should define an input layer with the same size as the input data (images size) and an output corresponding the out put data (image labels).\n13. Before the model is ready for training, it needs a few more settings. These are added during the model‚Äôs compile step:\n\nLoss function: This measures how accurate the model is during training. You want to minimize this function to ‚Äùsteer‚Äù the model in the right direction.\nOptimizer: This is how the model is updated based on the data it sees and its loss function.\nMetrics: Used to monitor the training and testing steps. The following example uses accuracy, the fraction of the images that are correctly classified.\n\n14. Training the neural network model requires the following steps:\n\nFeed the training data to the model. In this example, the training data is in the train images and train labels arrays.\nThe model learns to associate images and labels.\nYou ask the model to make predictions about a test set, in this example, the test images array. Verify that the predictions match the labels from the test labels array.\n\n\nmodel.compile(optimizer='adam',\n                loss='sparse_categorical_crossentropy',\n                metrics=['accuracy'])\n\nTo start training, call the model.fit method, so called because it ‚Äúfits‚Äù the model to the training data:\n\nmodel.fit(train_images , train_labels , epochs=10)\n\n15. It is the moment for checking the model performance on the test dataset.\n\ntest_loss , test_acc = model.evaluate(test_images , test_labels ,\nverbose =2)\n\nCheck the test loss and accuracy in your code.\n16. With the model trained, we can use it to make predictions about some images.\n\npredictions = model.predict(test_images)\n\nThe model predicts a label for each image in the testing set. Print the first, second and third element of the predicted test sets. You can see that each element contains 10 values indicating a probability of each label. Choose the maximum one using np.argmax() function. Compare the predicted label of the first three elements with their predicted labels. How many are correct?\n17. Write a function for checking the predicted labels. The result should be similar to the Figure below with a label indicating the probability of the predicted label with blue color if the prediction is correct otherwise in the red color?\n\n18. Grab a single element from the test set such as test_images[5]. Send it to the model.predict() and check what will happen. Why? Correct it by your modification. (hint: you can use expand_dims())\n19. Respecting input and output sizes, try to change your model structure in exercises 12 and 13 and observe their affections on prediction precision.\n\n\n\n\n\n\nTip\n\n\n\nYou can choose another image classification dataset from Tensorflow available datasets https://www.tensorflow.org/datasets/catalog/overview and predict a classification function for it."
  },
  {
    "objectID": "TD4.html#sentiment-analysis",
    "href": "TD4.html#sentiment-analysis",
    "title": "Lab4: Starting with Neural Networks",
    "section": "Sentiment Analysis",
    "text": "Sentiment Analysis\nIn this exercise, you‚Äôll build a neural network using Keras to classify texts into ones with positive and negative sentiments; sentiment analysis.\nImport the necessary Libraries\n\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.datasets import imdb\n\n1. Load the IMDB dataset\n\n(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\ndata = np.concatenate((training_data, testing_data), axis=0)\ntargets = np.concatenate((training_targets, testing_targets), axis=0)\n\n2. Take only the first 10000 words from each data sample. This reduces the size of our final model during training.\n3. Build your Neural Network model\n4. Compile your model\n5. Fit your model, and get its final accuracy"
  },
  {
    "objectID": "TD4.html#regression",
    "href": "TD4.html#regression",
    "title": "Lab4: Starting with Neural Networks",
    "section": "Regression",
    "text": "Regression\nIn this exercise, you will create a regressor on the Boston housing Dataset, a task that you‚Äôve previously accomplished using linear regression and decision trees. only this time, you‚Äôll accomplish it using Keras neural networks.\nImport the Boston Housing dataset.\n1. Visualize each feature and label in your data using a scatterplot. This will help in finding which features, if any, contain outliers. It will also assist in finding potential strong correlations between features.\n2. Split your data into training and testing\n3. Normalize your training and testing subsets\n4. Build your keras neural network model. Create a Sequential model, and make it only with 3 layers: an input (Dense) layer with 128 neurons, a hidden (Dense) layer with 64 neurons, both using a ReLU (Rectified Linear Unit) activation function, and a dense layer with a linear activation will be used as output layer.\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n#model =\n\n5. Compile your model and view its summary.\nTo compile your model, use the adam opimizer, and the mse (mean-squared-error) loss function, and the mae (mean average error) metric to report its performance.\n\nmodel.compile(optimizer='adam', loss='mse', metrics=['mae'])\nmodel.summary()\n\n6. Train your model\n7. Evaluate your model using model.evaluate\n\nmse_nn, mae_nn = model.evaluate(X_test, y_test)\nprint('Mean squared error on test data: ', mse_nn)\nprint('Mean absolute error on test data: ', mae_nn)\n\n8. Compare your model‚Äôs performance vs that of an sklearn Linear Regression model"
  },
  {
    "objectID": "TD4.html#case-study",
    "href": "TD4.html#case-study",
    "title": "Lab4: Starting with Neural Networks",
    "section": "Case study",
    "text": "Case study\nThis case study is from this course.\nTable of Contents:\n\nGenerating some data\n\nTraining a Softmax Linear Classifier\n\nInitialize the parameters\nCompute the class scores\nCompute the loss\nComputing the analytic gradient with backpropagation\nPerforming a parameter update\nPutting it all together: Training a Softmax Classifier\n\n\nTraining a Neural Network\nSummary\n\nIn this section we‚Äôll walk through a complete implementation of a toy Neural Network in 2 dimensions. We‚Äôll first implement a simple linear classifier and then extend the code to a 2-layer Neural Network. As we‚Äôll see, this extension is surprisingly simple and very few changes are necessary.\n\nGenerating some data\nLets generate a classification dataset that is not easily linearly separable. Our favorite example is the spiral dataset, which can be generated as follows:\n\nN = 100 # number of points per class\nD = 2 # dimensionality\nK = 3 # number of classes\nX = np.zeros((N*K,D)) # data matrix (each row = single example)\ny = np.zeros(N*K, dtype='uint8') # class labels\nfor j in range(K):\n  ix = range(N*j,N*(j+1))\n  r = np.linspace(0.0,1,N) # radius\n  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n  y[ix] = j\n# lets visualize the data:\nplt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\nplt.show()\n\n\n\nThe toy spiral data consists of three classes (blue, red, yellow) that are not linearly separable.\n\n\nNormally we would want to preprocess the dataset so that each feature has zero mean and unit standard deviation, but in this case the features are already in a nice range from -1 to 1, so we skip this step.\n\nTraining a Softmax Linear Classifier\n\nInitialize the parameters\nLets first train a Softmax classifier on this classification dataset. As we saw in the previous sections, the Softmax classifier has a linear score function and uses the cross-entropy loss. The parameters of the linear classifier consist of a weight matrix W and a bias vector b for each class. Lets first initialize these parameters to be random numbers:\n\n# initialize parameters randomly\nW = 0.01 * np.random.randn(D,K)\nb = np.zeros((1,K))\n\nRecall that we D = 2 is the dimensionality and K = 3 is the number of classes.\n\nCompute the class scores\nSince this is a linear classifier, we can compute all class scores very simply in parallel with a single matrix multiplication:\n\n# compute class scores for a linear classifier\nscores = np.dot(X, W) + b\n\nIn this example we have 300 2-D points, so after this multiplication the array scores will have size [300 x 3], where each row gives the class scores corresponding to the 3 classes (blue, red, yellow).\n\nCompute the loss\nThe second key ingredient we need is a loss function, which is a differentiable objective that quantifies our unhappiness with the computed class scores. Intuitively, we want the correct class to have a higher score than the other classes. When this is the case, the loss should be low and otherwise the loss should be high. There are many ways to quantify this intuition, but in this example lets use the cross-entropy loss that is associated with the Softmax classifier. Recall that if \\(f\\) is the array of class scores for a single example (e.g.¬†array of 3 numbers here), then the Softmax classifier computes the loss for that example as:\n\\[\nL_i = -\\log\\left(\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }\\right)\n\\]\nWe can see that the Softmax classifier interprets every element of \\(f\\) as holding the (unnormalized) log probabilities of the three classes. We exponentiate these to get (unnormalized) probabilities, and then normalize them to get probabilites. Therefore, the expression inside the log is the normalized probability of the correct class. Note how this expression works: this quantity is always between 0 and 1. When the probability of the correct class is very small (near 0), the loss will go towards (positive) infinity. Conversely, when the correct class probability goes towards 1, the loss will go towards zero because \\(log(1) = 0\\). Hence, the expression for \\(L_i\\) is low when the correct class probability is high, and it‚Äôs very high when it is low.\nRecall also that the full Softmax classifier loss is then defined as the average cross-entropy loss over the training examples and the regularization:\n\\[\nL =  \\underbrace{ \\frac{1}{N} \\sum_i L_i }_\\text{data loss} + \\underbrace{ \\frac{1}{2} \\lambda \\sum_k\\sum_l W_{k,l}^2 }_\\text{regularization loss} \\\\\\\\\n\\]\nGiven the array of scores we‚Äôve computed above, we can compute the loss. First, the way to obtain the probabilities is straight forward:\n\nnum_examples = X.shape[0]\n# get unnormalized probabilities\nexp_scores = np.exp(scores)\n# normalize them for each example\nprobs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n\nWe now have an array probs of size [300 x 3], where each row now contains the class probabilities. In particular, since we‚Äôve normalized them every row now sums to one. We can now query for the log probabilities assigned to the correct classes in each example:\n\ncorrect_logprobs = -np.log(probs[range(num_examples),y])\n\nThe array correct_logprobs is a 1D array of just the probabilities assigned to the correct classes for each example. The full loss is then the average of these log probabilities and the regularization loss:\n\n# compute the loss: average cross-entropy loss and regularization\ndata_loss = np.sum(correct_logprobs)/num_examples\nreg_loss = 0.5*reg*np.sum(W*W)\nloss = data_loss + reg_loss\n\nIn this code, the regularization strength \\(\\) is stored inside the reg. The convenience factor of 0.5 multiplying the regularization will become clear in a second. Evaluating this in the beginning (with random parameters) might give us loss = 1.1, which is -np.log(1.0/3), since with small initial random weights all probabilities assigned to all classes are about one third. We now want to make the loss as low as possible, with loss = 0 as the absolute lower bound. But the lower the loss is, the higher are the probabilities assigned to the correct classes for all examples.\n\nComputing the Analytic Gradient with Backpropagation\nWe have a way of evaluating the loss, and now we have to minimize it. We‚Äôll do so with gradient descent. That is, we start with random parameters (as shown above), and evaluate the gradient of the loss function with respect to the parameters, so that we know how we should change the parameters to decrease the loss. Lets introduce the intermediate variable \\(p\\), which is a vector of the (normalized) probabilities. The loss for one example is:\n\\[\np_k = \\frac{e^{f_k}}{ \\sum_j e^{f_j} } \\hspace{1in} L_i =-\\log\\left(p_{y_i}\\right)\n\\]\nWe now wish to understand how the computed scores inside \\(f\\) should change to decrease the loss \\(L_i\\) that this example contributes to the full objective. In other words, we want to derive the gradient \\( L_i / f_k \\). The loss \\(L_i\\) is computed from \\(p\\), which in turn depends on \\(f\\). It‚Äôs a fun exercise to the reader to use the chain rule to derive the gradient, but it turns out to be extremely simple and interpretible in the end, after a lot of things cancel out:\n\\[\n\\frac{\\partial L_i }{ \\partial f_k } = p_k - \\mathbb{1}(y_i = k)\n\\]\nNotice how elegant and simple this expression is. Suppose the probabilities we computed were p = [0.2, 0.3, 0.5], and that the correct class was the middle one (with probability 0.3). According to this derivation the gradient on the scores would be df = [0.2, -0.7, 0.5]. Recalling what the interpretation of the gradient, we see that this result is highly intuitive: increasing the first or last element of the score vector f (the scores of the incorrect classes) leads to an increased loss (due to the positive signs +0.2 and +0.5) - and increasing the loss is bad, as expected. However, increasing the score of the correct class has negative influence on the loss. The gradient of -0.7 is telling us that increasing the correct class score would lead to a decrease of the loss \\(L_i\\), which makes sense.\nAll of this boils down to the following code. Recall that probs stores the probabilities of all classes (as rows) for each example. To get the gradient on the scores, which we call dscores, we proceed as follows:\n\ndscores = probs\ndscores[range(num_examples),y] -= 1\ndscores /= num_examples\n\nLastly, we had that scores = np.dot(X, W) + b, so armed with the gradient on scores (stored in dscores), we can now backpropagate into W and b:\n\ndW = np.dot(X.T, dscores)\ndb = np.sum(dscores, axis=0, keepdims=True)\ndW += reg*W # don't forget the regularization gradient\n\nWhere we see that we have backpropped through the matrix multiply operation, and also added the contribution from the regularization. Note that the regularization gradient has the very simple form reg*W since we used the constant 0.5 for its loss contribution (i.e.¬†\\( ( w^2) = w\\). This is a common convenience trick that simplifies the gradient expression.\n\nPerforming a parameter update\nNow that we‚Äôve evaluated the gradient we know how every parameter influences the loss function. We will now perform a parameter update in the negative gradient direction to decrease the loss:\n\n# perform a parameter update\nW += -step_size * dW\nb += -step_size * db\n\n\nPutting it all together: Training a Softmax Classifier\nPutting all of this together, here is the full code for training a Softmax classifier with Gradient descent:\n\n#Train a Linear Classifier\n\n# initialize parameters randomly\nW = 0.01 * np.random.randn(D,K)\nb = np.zeros((1,K))\n\n# some hyperparameters\nstep_size = 1e-0\nreg = 1e-3 # regularization strength\n\n# gradient descent loop\nnum_examples = X.shape[0]\nfor i in range(200):\n\n  # evaluate class scores, [N x K]\n  scores = np.dot(X, W) + b\n\n  # compute the class probabilities\n  exp_scores = np.exp(scores)\n  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n\n  # compute the loss: average cross-entropy loss and regularization\n  correct_logprobs = -np.log(probs[range(num_examples),y])\n  data_loss = np.sum(correct_logprobs)/num_examples\n  reg_loss = 0.5*reg*np.sum(W*W)\n  loss = data_loss + reg_loss\n  if i % 10 == 0:\n    print \"iteration %d: loss %f\" % (i, loss)\n  \n  # compute the gradient on scores\n  dscores = probs\n  dscores[range(num_examples),y] -= 1\n  dscores /= num_examples\n\n  # backpropate the gradient to the parameters (W,b)\n  dW = np.dot(X.T, dscores)\n  db = np.sum(dscores, axis=0, keepdims=True)\n\n  dW += reg*W # regularization gradient\n\n  # perform a parameter update\n  W += -step_size * dW\n  b += -step_size * db\n\nRunning this prints the output:\niteration 0: loss 1.096956\niteration 10: loss 0.917265\niteration 20: loss 0.851503\niteration 30: loss 0.822336\niteration 40: loss 0.807586\niteration 50: loss 0.799448\niteration 60: loss 0.794681\niteration 70: loss 0.791764\niteration 80: loss 0.789920\niteration 90: loss 0.788726\niteration 100: loss 0.787938\niteration 110: loss 0.787409\niteration 120: loss 0.787049\niteration 130: loss 0.786803\niteration 140: loss 0.786633\niteration 150: loss 0.786514\niteration 160: loss 0.786431\niteration 170: loss 0.786373\niteration 180: loss 0.786331\niteration 190: loss 0.786302\nWe see that we‚Äôve converged to something after about 190 iterations. We can evaluate the training set accuracy:\n\n# evaluate training set accuracy\nscores = np.dot(X, W) + b\npredicted_class = np.argmax(scores, axis=1)\nprint 'training accuracy: %.2f' % (np.mean(predicted_class == y))\n\nThis prints 49%. Not very good at all, but also not surprising given that the dataset is constructed so it is not linearly separable. We can also plot the learned decision boundaries:\n\n\nLinear classifier fails to learn the toy spiral dataset.\n\n\n\nTraining a Neural Network\nClearly, a linear classifier is inadequate for this dataset and we would like to use a Neural Network. One additional hidden layer will suffice for this toy data. We will now need two sets of weights and biases (for the first and second layers):\n\n# initialize parameters randomly\nh = 100 # size of hidden layer\nW = 0.01 * np.random.randn(D,h)\nb = np.zeros((1,h))\nW2 = 0.01 * np.random.randn(h,K)\nb2 = np.zeros((1,K))\n\nThe forward pass to compute scores now changes form:\n\n# evaluate class scores with a 2-layer Neural Network\nhidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation\nscores = np.dot(hidden_layer, W2) + b2\n\nNotice that the only change from before is one extra line of code, where we first compute the hidden layer representation and then the scores based on this hidden layer. Crucially, we‚Äôve also added a non-linearity, which in this case is simple ReLU that thresholds the activations on the hidden layer at zero.\nEverything else remains the same. We compute the loss based on the scores exactly as before, and get the gradient for the scores dscores exactly as before. However, the way we backpropagate that gradient into the model parameters now changes form, of course. First lets backpropagate the second layer of the Neural Network. This looks identical to the code we had for the Softmax classifier, except we‚Äôre replacing X (the raw data), with the variable hidden_layer):\n\n# backpropate the gradient to the parameters\n# first backprop into parameters W2 and b2\ndW2 = np.dot(hidden_layer.T, dscores)\ndb2 = np.sum(dscores, axis=0, keepdims=True)\n\nHowever, unlike before we are not yet done, because hidden_layer is itself a function of other parameters and the data! We need to continue backpropagation through this variable. Its gradient can be computed as:\n\ndhidden = np.dot(dscores, W2.T)\n\nNow we have the gradient on the outputs of the hidden layer. Next, we have to backpropagate the ReLU non-linearity. This turns out to be easy because ReLU during the backward pass is effectively a switch. Since \\(r = max(0, x)\\), we have that \\( = 1(x &gt; 0) \\). Combined with the chain rule, we see that the ReLU unit lets the gradient pass through unchanged if its input was greater than 0, but kills it if its input was less than zero during the forward pass. Hence, we can backpropagate the ReLU in place simply with:\n\n# backprop the ReLU non-linearity\ndhidden[hidden_layer &lt;= 0] = 0\n\nAnd now we finally continue to the first layer weights and biases:\n\n# finally into W,b\ndW = np.dot(X.T, dhidden)\ndb = np.sum(dhidden, axis=0, keepdims=True)\n\nWe‚Äôre done! We have the gradients dW,db,dW2,db2 and can perform the parameter update. Everything else remains unchanged. The full code looks very similar:\n\n# initialize parameters randomly\nh = 100 # size of hidden layer\nW = 0.01 * np.random.randn(D,h)\nb = np.zeros((1,h))\nW2 = 0.01 * np.random.randn(h,K)\nb2 = np.zeros((1,K))\n\n# some hyperparameters\nstep_size = 1e-0\nreg = 1e-3 # regularization strength\n\n# gradient descent loop\nnum_examples = X.shape[0]\nfor i in range(10000):\n\n  # evaluate class scores, [N x K]\n  hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation\n  scores = np.dot(hidden_layer, W2) + b2\n\n  # compute the class probabilities\n  exp_scores = np.exp(scores)\n  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n\n  # compute the loss: average cross-entropy loss and regularization\n  correct_logprobs = -np.log(probs[range(num_examples),y])\n  data_loss = np.sum(correct_logprobs)/num_examples\n  reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)\n  loss = data_loss + reg_loss\n  if i % 1000 == 0:\n    print \"iteration %d: loss %f\" % (i, loss)\n\n  # compute the gradient on scores\n  dscores = probs\n  dscores[range(num_examples),y] -= 1\n  dscores /= num_examples\n\n  # backpropate the gradient to the parameters\n  # first backprop into parameters W2 and b2\n  dW2 = np.dot(hidden_layer.T, dscores)\n  db2 = np.sum(dscores, axis=0, keepdims=True)\n  # next backprop into hidden layer\n  dhidden = np.dot(dscores, W2.T)\n  # backprop the ReLU non-linearity\n  dhidden[hidden_layer &lt;= 0] = 0\n  # finally into W,b\n  dW = np.dot(X.T, dhidden)\n  db = np.sum(dhidden, axis=0, keepdims=True)\n\n  # add regularization gradient contribution\n  dW2 += reg * W2\n  dW += reg * W\n\n  # perform a parameter update\n  W += -step_size * dW\n  b += -step_size * db\n  W2 += -step_size * dW2\n  b2 += -step_size * db2\n\nThis prints:\niteration 0: loss 1.098744\niteration 1000: loss 0.294946\niteration 2000: loss 0.259301\niteration 3000: loss 0.248310\niteration 4000: loss 0.246170\niteration 5000: loss 0.245649\niteration 6000: loss 0.245491\niteration 7000: loss 0.245400\niteration 8000: loss 0.245335\niteration 9000: loss 0.245292\nThe training accuracy is now:\n\n# evaluate training set accuracy\nhidden_layer = np.maximum(0, np.dot(X, W) + b)\nscores = np.dot(hidden_layer, W2) + b2\npredicted_class = np.argmax(scores, axis=1)\nprint 'training accuracy: %.2f' % (np.mean(predicted_class == y))\n\nWhich prints 98%!. We can also visualize the decision boundaries:\n\n\nNeural Network classifier crushes the spiral dataset.\n\n\nSummary\nWe‚Äôve worked with a toy 2D dataset and trained both a linear network and a 2-layer Neural Network. We saw that the change from a linear classifier to a Neural Network involves very few changes in the code. The score function changes its form (1 line of code difference), and the backpropagation changes its form (we have to perform one more round of backprop through the hidden layer to the first layer of the network)."
  }
]